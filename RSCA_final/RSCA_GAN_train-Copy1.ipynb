{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99fcbe8-0239-44af-85a7-c0cb61a98928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5af170-8ce2-4dff-ac57-1ab6779cd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6ffe70-b539-4142-8c65-9ff52a03f2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og_mask shape: (1, 1, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "mask = np.load(r\"C:\\Users\\DU\\aman_fastmri\\Data\\mask_4x_320_random.npy\")  # Shape: (1, 320, 320)\n",
    "#C:\\Users\\DU\\aman_fastmri\\Data\n",
    "print(\"og_mask shape:\", mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702599fa-f70d-481b-b0be-83f6a995b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MRISliceGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, file_list, batch_size=4, shuffle=True):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Open files once (important for stability & speed)\n",
    "        self.files = [h5py.File(fp, 'r') for fp in self.file_list]\n",
    "\n",
    "        self.slice_index_map = []\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        for file_idx, f in enumerate(self.files):\n",
    "            num_slices = f['image_under'].shape[0]\n",
    "            for slice_idx in range(num_slices):\n",
    "                self.slice_index_map.append((file_idx, slice_idx))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.slice_index_map) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        batch_map = self.slice_index_map[\n",
    "            index * self.batch_size:(index + 1) * self.batch_size\n",
    "        ]\n",
    "\n",
    "        SZF_batch = []\n",
    "        SGT_batch = []\n",
    "\n",
    "        for file_idx, slice_idx in batch_map:\n",
    "            f = self.files[file_idx]\n",
    "\n",
    "            # Shape: (H, W, 2)  -> (real, imag)\n",
    "            SZF_batch.append(f['image_under'][slice_idx])\n",
    "            SGT_batch.append(f['image_full'][slice_idx])\n",
    "\n",
    "        SZF_batch = np.stack(SZF_batch).astype(np.float32)\n",
    "        SGT_batch = np.stack(SGT_batch).astype(np.float32)\n",
    "\n",
    "        return SZF_batch, SGT_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.slice_index_map)\n",
    "\n",
    "    def __del__(self):\n",
    "        for f in self.files:\n",
    "            try:\n",
    "                f.close()\n",
    "            except Exception:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d51b92-04f8-47c8-a643-4e5e852508e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MRISliceValGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, file_list, batch_size=4, shuffle=False):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Open files once\n",
    "        self.files = [h5py.File(fp, 'r') for fp in self.file_list]\n",
    "\n",
    "        self.slice_index_map = []\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        for file_idx, f in enumerate(self.files):\n",
    "            num_slices = f['image_under'].shape[0]\n",
    "            for slice_idx in range(num_slices):\n",
    "                self.slice_index_map.append((file_idx, slice_idx))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.slice_index_map) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        batch_map = self.slice_index_map[\n",
    "            index * self.batch_size:(index + 1) * self.batch_size\n",
    "        ]\n",
    "\n",
    "        SZF_batch = []\n",
    "        SGT_batch = []\n",
    "        MAXV_batch = []\n",
    "\n",
    "        for file_idx, slice_idx in batch_map:\n",
    "            f = self.files[file_idx]\n",
    "\n",
    "            # Complex images (H, W, 2)\n",
    "            SZF_batch.append(f['image_under'][slice_idx])\n",
    "            SGT_batch.append(f['image_full'][slice_idx])\n",
    "\n",
    "            # Volume-level max (same for all slices of that volume)\n",
    "            MAXV_batch.append(f['max_val_full_image'][0])\n",
    "\n",
    "        SZF_batch = np.stack(SZF_batch).astype(np.float32)\n",
    "        SGT_batch = np.stack(SGT_batch).astype(np.float32)\n",
    "        MAXV_batch = np.array(MAXV_batch).astype(np.float32)\n",
    "\n",
    "        return SZF_batch, SGT_batch, MAXV_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.slice_index_map)\n",
    "\n",
    "    def __del__(self):\n",
    "        for f in self.files:\n",
    "            try:\n",
    "                f.close()\n",
    "            except Exception:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6184ae5a-cc65-4235-b6fe-99d648fce837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\train_norm\"\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e38064f-86ae-4409-a9fb-2aa0ec8f28d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17349\n",
      "7135\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "kspace_files_list_train = sorted(glob.glob(os.path.join(train_folder, \"*.h5\")))\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "\n",
    "# half_train = 20\n",
    "# half_val = 10\n",
    "half_train = len(kspace_files_list_train) \n",
    "half_val = len(kspace_files_list_val) \n",
    "# print(\"half_train\",half_train)\n",
    "# print(\"half_val\",half_val)\n",
    "kspace_files_list_train = kspace_files_list_train[:]\n",
    "kspace_files_list_val = kspace_files_list_val[:]\n",
    "\n",
    "# # Create generators\n",
    "# train_gen = MRISliceGenerator(kspace_files_list_train,batch_size=16, shuffle=True,mask=mask)\n",
    "# val_gen = MRISliceGenerator(kspace_files_list_val, batch_size=4, shuffle=False,mask=mask)\n",
    "train_gen = MRISliceGenerator(kspace_files_list_train,batch_size=2, shuffle=True)\n",
    "val_gen = MRISliceValGenerator(kspace_files_list_val, batch_size=1, shuffle=False)\n",
    "\n",
    "print(len(train_gen))  \n",
    "print(len(val_gen))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9011c807-2ba3-4ce8-b0f5-a4e31032783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1044012f-af86-4419-a4dc-53f367022ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RSCAGAN(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, base_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\keras\\engine\\training.py:3214\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   3185\u001b[0m \n\u001b[0;32m   3186\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   3212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 3214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3218\u001b[0m     )\n\u001b[0;32m   3219\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[0;32m   3220\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3221\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3226\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[0;32m   3227\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model = RSCAGAN(in_channels=2, base_channels=32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5c29ce-b949-4c9f-9ace-7b162f9791a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Total parameters:       0.000 M\n",
      "Trainable parameters:   0.000 M\n",
      "Non-trainable params:   0.000 M\n",
      "========================================\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\DU\\AppData\\Local\\Temp\\ipykernel_23596\\915890014.py\", line 31, in forward  *\n        return model(x)\n    File \"C:\\Users\\DU\\anaconda3\\envs\\WNet\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer \"RSCA_GAN\" \"                 f\"(type RSCAGAN).\n    \n    in user code:\n    \n        File \"C:\\Users\\DU\\AppData\\Local\\Temp\\ipykernel_23596\\1834071404.py\", line 33, in call  *\n            SZF, SGT = inputs\n    \n        OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n    \n    \n    Call arguments received by layer \"RSCA_GAN\" \"                 f\"(type RSCAGAN):\n      â€¢ inputs=tf.Tensor(shape=(1, 1, 320, 320, 2), dtype=float32)\n      â€¢ training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Example: infer H, W from your data or define explicitly\u001b[39;00m\n\u001b[0;32m     55\u001b[0m H, W \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m320\u001b[39m,\u001b[38;5;241m320\u001b[39m\n\u001b[1;32m---> 57\u001b[0m flops \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_flops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOPs (single forward pass): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflops\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e9\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GFLOPs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m, in \u001b[0;36mcompute_flops\u001b[1;34m(model, input_shape)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(x):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model(x)\n\u001b[1;32m---> 33\u001b[0m concrete_func \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m frozen_func \u001b[38;5;241m=\u001b[39m convert_variables_to_constants_v2(concrete_func)\n\u001b[0;32m     38\u001b[0m graph_def \u001b[38;5;241m=\u001b[39m frozen_func\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mas_graph_def()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1239\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1238\u001b[0m   \u001b[38;5;66;03m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1240\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1219\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1223\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1233\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1234\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"C:\\Users\\DU\\AppData\\Local\\Temp\\ipykernel_23596\\915890014.py\", line 31, in forward  *\n        return model(x)\n    File \"C:\\Users\\DU\\anaconda3\\envs\\WNet\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer \"RSCA_GAN\" \"                 f\"(type RSCAGAN).\n    \n    in user code:\n    \n        File \"C:\\Users\\DU\\AppData\\Local\\Temp\\ipykernel_23596\\1834071404.py\", line 33, in call  *\n            SZF, SGT = inputs\n    \n        OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n    \n    \n    Call arguments received by layer \"RSCA_GAN\" \"                 f\"(type RSCAGAN):\n      â€¢ inputs=tf.Tensor(shape=(1, 1, 320, 320, 2), dtype=float32)\n      â€¢ training=False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def count_parameters_millions(model):\n",
    "    trainable = np.sum([np.prod(v.shape) for v in model.trainable_variables])\n",
    "    non_trainable = np.sum([np.prod(v.shape) for v in model.non_trainable_variables])\n",
    "    total = trainable + non_trainable\n",
    "    return (\n",
    "        total / 1e6,\n",
    "        trainable / 1e6,\n",
    "        non_trainable / 1e6\n",
    "    )\n",
    "\n",
    "total_M, trainable_M, non_trainable_M = count_parameters_millions(model)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"Total parameters:       {total_M:.3f} M\")\n",
    "print(f\"Trainable parameters:   {trainable_M:.3f} M\")\n",
    "print(f\"Non-trainable params:   {non_trainable_M:.3f} M\")\n",
    "print(\"=\" * 40)\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "def compute_flops(model, input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: tuple, e.g. (1, H, W, 2)\n",
    "    returns FLOPs (float operations) for one forward pass\n",
    "    \"\"\"\n",
    "\n",
    "    @tf.function\n",
    "    def forward(x):\n",
    "        return model(x)\n",
    "\n",
    "    concrete_func = forward.get_concrete_function(\n",
    "        tf.TensorSpec(input_shape, tf.float32)\n",
    "    )\n",
    "\n",
    "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=graph,\n",
    "            run_meta=run_meta,\n",
    "            cmd=\"op\",\n",
    "            options=opts\n",
    "        )\n",
    "\n",
    "    return flops.total_float_ops\n",
    "# Example: infer H, W from your data or define explicitly\n",
    "H, W = 320,320\n",
    "\n",
    "flops = compute_flops(model, input_shape=(1,1, H, W, 2))\n",
    "\n",
    "print(f\"FLOPs (single forward pass): {flops / 1e9:.2f} GFLOPs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b98b7e9-e93b-4b85-a84b-6120542bb6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ”§ RSCA-GAN TRAINING CONFIGURATION (Paper-Aligned)\n",
      "============================================================\n",
      " Save Directory:       ./SavedModels_RSCA_GAN_full_2\n",
      " Image Size:           320 x 320\n",
      " Batch Size:           8\n",
      " Learning Rate:        0.0001\n",
      " Adam Betas:           (0.9, 0.999)\n",
      " Epochs:               50\n",
      " Generator Ckpt:       ./SavedModels_RSCA_GAN_full_2\\RSCA_GAN_Generator\n",
      " Discriminator Ckpt:   ./SavedModels_RSCA_GAN_full_2\\RSCA_GAN_Discriminator\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Directory Setup\n",
    "# --------------------------------------------------\n",
    "save_dir = \"./SavedModels_RSCA_GAN_full_2\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Configuration (PAPER-FAITHFUL)\n",
    "# --------------------------------------------------\n",
    "H, W = 320, 320        # paper resizes all images to 256x256\n",
    "\n",
    "BATCH_SIZE     = 8   # ðŸ”‘ paper value\n",
    "LEARNING_RATE  = 1e-4  # ðŸ”‘ paper value\n",
    "BETA_1         = 0.9\n",
    "BETA_2         = 0.999\n",
    "\n",
    "EPOCHS         = 50   # ðŸ”‘ paper uses epochs\n",
    "\n",
    "GEN_CKPT_PATH  = os.path.join(save_dir, \"RSCA_GAN_Generator\")\n",
    "DISC_CKPT_PATH = os.path.join(save_dir, \"RSCA_GAN_Discriminator\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ”§ RSCA-GAN TRAINING CONFIGURATION (Paper-Aligned)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\" Save Directory:       {save_dir}\")\n",
    "print(f\" Image Size:           {H} x {W}\")\n",
    "print(f\" Batch Size:           {BATCH_SIZE}\")\n",
    "print(f\" Learning Rate:        {LEARNING_RATE}\")\n",
    "print(f\" Adam Betas:           ({BETA_1}, {BETA_2})\")\n",
    "print(f\" Epochs:               {EPOCHS}\")\n",
    "print(f\" Generator Ckpt:       {GEN_CKPT_PATH}\")\n",
    "print(f\" Discriminator Ckpt:   {DISC_CKPT_PATH}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc606841-0bc1-4de3-880f-39ef341d5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RSCAGAN(in_channels=2, base_channels=32)\n",
    "\n",
    "generator = model.generator\n",
    "discriminator = model.discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c8b488e-f3d3-4629-8bad-cc40cca722b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    # clipnorm=1.0\n",
    ")\n",
    "\n",
    "\"\"\"disc_optimizer = Adam(\n",
    "    #learning_rate=LEARNING_RATE,\n",
    "    learning_rate=8e-5,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    clipnorm=1.0\n",
    ")\"\"\"\n",
    "disc_optimizer = Adam(\n",
    "    learning_rate=8e-5,   \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263331f5-c75b-4856-8361-7067194efef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(D_real, D_fake):\n",
    "   # real_loss = bce(tf.ones_like(D_real), D_real)\n",
    "   # fake_loss = bce(tf.zeros_like(D_fake), D_fake)\n",
    "    real_labels = tf.ones_like(D_real) * 0.9\n",
    "    fake_labels = tf.zeros_like(D_fake) + 0.1\n",
    "\n",
    "    real_loss = bce(real_labels, D_real)\n",
    "    fake_loss = bce(fake_labels, D_fake)\n",
    "\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_adversarial_loss(D_fake):\n",
    "    return bce(tf.ones_like(D_fake), D_fake)\n",
    "\n",
    "def image_l1_loss(SGT, SRE):\n",
    "    return tf.reduce_mean(tf.abs(SGT - SRE))\n",
    "\n",
    "def frequency_l1_loss(SGT, SRE, mask):\n",
    "    r_gt  = fft2c_tf(SGT)\n",
    "    r_rec = fft2c_tf(SRE)\n",
    "    return tf.reduce_mean(tf.abs(r_gt * mask - r_rec * mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27178df2-b123-4d07-b46d-a473e42cce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_nmse(gt, pred):\n",
    "#     return tf.reduce_sum(tf.square(gt - pred)) / tf.reduce_sum(tf.square(gt))\n",
    "\n",
    "# def compute_psnr(gt, pred):\n",
    "#     return tf.reduce_mean(tf.image.psnr(gt, pred, max_val=1.0))\n",
    "\n",
    "\n",
    "# def compute_ssim(gt, pred):\n",
    "#     return tf.reduce_mean(\n",
    "#         tf.image.ssim(gt, pred, max_val=1.0)\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f412683-4dcf-4569-9867-622de56e177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(SZF, SGT, mask):\n",
    "\n",
    "    # ======================\n",
    "    # Train Discriminator\n",
    "    # ======================\n",
    "    with tf.GradientTape() as d_tape:\n",
    "        SRE = generator(SZF, training=True)\n",
    "\n",
    "        D_real = discriminator(SGT, training=True)\n",
    "        D_fake = discriminator(tf.stop_gradient(SRE), training=True)\n",
    "\n",
    "        d_loss = discriminator_loss(D_real, D_fake)\n",
    "\n",
    "    d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(\n",
    "        zip(d_grads, discriminator.trainable_variables)\n",
    "    )\n",
    "\n",
    "    # ======================\n",
    "    # Train Generator\n",
    "    # ======================\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        SRE = generator(SZF, training=True)\n",
    "\n",
    "        D_fake = discriminator(SRE, training=True)\n",
    "\n",
    "        adv_loss  = generator_adversarial_loss(D_fake)\n",
    "        img_loss  = image_l1_loss(SGT, SRE)\n",
    "        freq_loss = frequency_l1_loss(SGT, SRE, mask)\n",
    "\n",
    "        g_loss = 0.001 * adv_loss + freq_loss + 10.0 * img_loss\n",
    "\n",
    "    g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(\n",
    "        zip(g_grads, generator.trainable_variables)\n",
    "    )\n",
    "\n",
    "    return d_loss, g_loss, adv_loss, freq_loss, img_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cbfe2d2-4481-41e7-9a5c-ca72684f195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_mag(x):\n",
    "    return tf.sqrt(x[..., 0]**2 + x[..., 1]**2 + 1e-8)\n",
    "@tf.function\n",
    "def validation_step(SZF, SGT, mask, MAXV):\n",
    "\n",
    "    # Generator inference\n",
    "    SRE = generator(SZF, training=False)\n",
    "\n",
    "    # ======================\n",
    "    # Reconstruction loss (NO adversarial)\n",
    "    # ======================\n",
    "    img_loss  = image_l1_loss(SGT, SRE)\n",
    "    freq_loss = frequency_l1_loss(SGT, SRE, mask)\n",
    "\n",
    "    total_loss = freq_loss + 10.0 * img_loss\n",
    "\n",
    "    # ======================\n",
    "    # Metrics (magnitude domain)\n",
    "    # ======================\n",
    "    gt_mag  = complex_to_mag(SGT)\n",
    "    rec_mag = complex_to_mag(SRE)\n",
    "    print(\"gt_mag\",gt_mag.shape)\n",
    "    print(\"rec_mag\",rec_mag.shape)\n",
    "    \n",
    "\n",
    "    # Denormalize using volume-level MAXV\n",
    "    MAXV = tf.reshape(MAXV, (-1, 1, 1))\n",
    "    gt_mag  = gt_mag * MAXV\n",
    "    rec_mag = rec_mag * MAXV\n",
    "    gt_mag  = tf.expand_dims(gt_mag, axis=-1)   # [B,H,W,1]\n",
    "    rec_mag = tf.expand_dims(rec_mag, axis=-1)  # [B,H,W,1]\n",
    "\n",
    "\n",
    "    psnr = tf.reduce_mean(\n",
    "        tf.image.psnr(gt_mag, rec_mag, max_val=MAXV)\n",
    "    )\n",
    "\n",
    "    ssim = tf.reduce_mean(\n",
    "        tf.image.ssim(gt_mag, rec_mag, max_val=MAXV)\n",
    "    )\n",
    "\n",
    "    nmse = tf.reduce_sum(\n",
    "        tf.square(gt_mag - rec_mag)\n",
    "    ) / tf.reduce_sum(tf.square(gt_mag))\n",
    "\n",
    "    return total_loss, psnr, ssim, nmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c32ed4c-8e21-4338-b397-5c088530ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(val_gen, mask):\n",
    "    val_loss = []\n",
    "    val_psnr = []\n",
    "    val_ssim = []\n",
    "    val_nmse = []\n",
    "\n",
    "    for SZF, SGT, MAXV in val_gen:\n",
    "        loss, psnr, ssim, nmse = validation_step(SZF, SGT, mask, MAXV)\n",
    "\n",
    "\n",
    "        val_loss.append(loss)\n",
    "        val_psnr.append(psnr)\n",
    "        val_ssim.append(ssim)\n",
    "        val_nmse.append(nmse)\n",
    "\n",
    "    return (\n",
    "        tf.reduce_mean(val_loss),\n",
    "        tf.reduce_mean(val_psnr),\n",
    "        tf.reduce_mean(val_ssim),\n",
    "        tf.reduce_mean(val_nmse)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d573afc1-5ca3-4d92-8686-73d9a3c347a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> ADD <<<\n",
    "epoch_counter = tf.Variable(0, dtype=tf.int64)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=gen_optimizer,\n",
    "    disc_optimizer=disc_optimizer,\n",
    "    epoch=epoch_counter\n",
    ")\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt,\n",
    "    directory=save_dir,\n",
    "    max_to_keep=5\n",
    ")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "468c09bb-d6f1-4240-8532-e055514f7cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ†• Training from scratch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "    start_epoch = int(epoch_counter.numpy())\n",
    "    print(f\"âœ… Resuming from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print(\"ðŸ†• Training from scratch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56426213-12bb-4974-b497-a0f2fc06db83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/50 =====\n",
      "[Train 0] D: 0.8204 | G: 0.2787 | Adv: 1.4261 | F: 0.0043 | I: 0.0273\n",
      "[Train 1000] D: 0.8385 | G: 0.2041 | Adv: 2.0108 | F: 0.0032 | I: 0.0199\n",
      "[Train 2000] D: 0.9586 | G: 0.1808 | Adv: 1.5680 | F: 0.0028 | I: 0.0176\n",
      "[Train 3000] D: 1.0475 | G: 0.1058 | Adv: 2.0778 | F: 0.0017 | I: 0.0102\n",
      "[Train 4000] D: 0.8246 | G: 0.2453 | Adv: 1.1141 | F: 0.0039 | I: 0.0240\n",
      "[Train 5000] D: 1.0908 | G: 0.1162 | Adv: 1.9670 | F: 0.0018 | I: 0.0112\n",
      "[Train 6000] D: 0.8894 | G: 0.2364 | Adv: 1.2889 | F: 0.0039 | I: 0.0231\n",
      "[Train 7000] D: 1.0552 | G: 0.1453 | Adv: 2.0084 | F: 0.0023 | I: 0.0141\n",
      "[Train 8000] D: 0.8295 | G: 0.1948 | Adv: 1.3593 | F: 0.0032 | I: 0.0190\n",
      "[Train 9000] D: 0.9029 | G: 0.1836 | Adv: 2.4953 | F: 0.0029 | I: 0.0178\n",
      "[Train 10000] D: 2.2569 | G: 0.1257 | Adv: 2.8443 | F: 0.0021 | I: 0.0121\n",
      "[Train 11000] D: 0.9070 | G: 0.1613 | Adv: 1.4189 | F: 0.0026 | I: 0.0157\n",
      "[Train 12000] D: 0.8209 | G: 0.1533 | Adv: 1.8302 | F: 0.0024 | I: 0.0149\n",
      "[Train 13000] D: 0.8183 | G: 0.1935 | Adv: 1.6060 | F: 0.0032 | I: 0.0189\n",
      "[Train 14000] D: 0.7905 | G: 0.1998 | Adv: 1.8287 | F: 0.0033 | I: 0.0195\n",
      "[Train 15000] D: 0.8803 | G: 0.1686 | Adv: 1.9393 | F: 0.0027 | I: 0.0164\n",
      "[Train 16000] D: 0.9932 | G: 0.2088 | Adv: 1.3500 | F: 0.0036 | I: 0.0204\n",
      "[Train 17000] D: 1.1631 | G: 0.1297 | Adv: 0.9737 | F: 0.0021 | I: 0.0127\n",
      "gt_mag (1, 320, 320)\n",
      "rec_mag (1, 320, 320)\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.2029\n",
      " Val PSNR : 33.45\n",
      " Val SSIM : 0.7750\n",
      " Val NMSE : 0.0361\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.2029)\n",
      "\n",
      "===== Epoch 2/50 =====\n",
      "[Train 0] D: 0.7620 | G: 0.2749 | Adv: 1.5471 | F: 0.0045 | I: 0.0269\n",
      "[Train 1000] D: 0.8611 | G: 0.2002 | Adv: 1.9338 | F: 0.0033 | I: 0.0195\n",
      "[Train 2000] D: 0.8634 | G: 0.1727 | Adv: 1.3666 | F: 0.0028 | I: 0.0169\n",
      "[Train 3000] D: 0.9856 | G: 0.1038 | Adv: 2.1210 | F: 0.0017 | I: 0.0100\n",
      "[Train 4000] D: 0.8677 | G: 0.2385 | Adv: 1.3698 | F: 0.0040 | I: 0.0233\n",
      "[Train 5000] D: 1.0128 | G: 0.1130 | Adv: 2.0664 | F: 0.0018 | I: 0.0109\n",
      "[Train 6000] D: 0.8845 | G: 0.2332 | Adv: 1.2820 | F: 0.0040 | I: 0.0228\n",
      "[Train 7000] D: 1.0624 | G: 0.1435 | Adv: 2.1196 | F: 0.0023 | I: 0.0139\n",
      "[Train 8000] D: 0.8348 | G: 0.1893 | Adv: 1.4869 | F: 0.0031 | I: 0.0185\n",
      "[Train 9000] D: 1.0086 | G: 0.1829 | Adv: 2.5016 | F: 0.0030 | I: 0.0177\n",
      "[Train 10000] D: 2.0954 | G: 0.1239 | Adv: 2.3504 | F: 0.0020 | I: 0.0120\n",
      "[Train 11000] D: 0.8750 | G: 0.1592 | Adv: 1.5598 | F: 0.0027 | I: 0.0155\n",
      "[Train 12000] D: 0.7862 | G: 0.1520 | Adv: 1.7464 | F: 0.0024 | I: 0.0148\n",
      "[Train 13000] D: 0.7806 | G: 0.1928 | Adv: 1.6456 | F: 0.0032 | I: 0.0188\n",
      "[Train 14000] D: 0.7606 | G: 0.1969 | Adv: 2.0444 | F: 0.0032 | I: 0.0192\n",
      "[Train 15000] D: 0.9554 | G: 0.1653 | Adv: 2.1222 | F: 0.0028 | I: 0.0160\n",
      "[Train 16000] D: 1.0209 | G: 0.2067 | Adv: 1.3897 | F: 0.0036 | I: 0.0202\n",
      "[Train 17000] D: 1.1325 | G: 0.1293 | Adv: 1.0851 | F: 0.0021 | I: 0.0126\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.2012\n",
      " Val PSNR : 33.71\n",
      " Val SSIM : 0.7822\n",
      " Val NMSE : 0.0339\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.2012)\n",
      "\n",
      "===== Epoch 3/50 =====\n",
      "[Train 0] D: 0.7694 | G: 0.2743 | Adv: 1.8674 | F: 0.0045 | I: 0.0268\n",
      "[Train 1000] D: 0.9171 | G: 0.1986 | Adv: 1.7827 | F: 0.0033 | I: 0.0193\n",
      "[Train 2000] D: 0.8999 | G: 0.1709 | Adv: 1.2500 | F: 0.0028 | I: 0.0167\n",
      "[Train 3000] D: 1.0229 | G: 0.1030 | Adv: 2.3819 | F: 0.0017 | I: 0.0099\n",
      "[Train 4000] D: 0.8455 | G: 0.2368 | Adv: 1.3576 | F: 0.0040 | I: 0.0231\n",
      "[Train 5000] D: 1.1091 | G: 0.1125 | Adv: 2.1310 | F: 0.0018 | I: 0.0109\n",
      "[Train 6000] D: 0.8302 | G: 0.2322 | Adv: 1.4148 | F: 0.0040 | I: 0.0227\n",
      "[Train 7000] D: 1.0660 | G: 0.1430 | Adv: 2.3304 | F: 0.0023 | I: 0.0138\n",
      "[Train 8000] D: 0.8177 | G: 0.1872 | Adv: 1.7077 | F: 0.0031 | I: 0.0182\n",
      "[Train 9000] D: 0.9166 | G: 0.1820 | Adv: 2.3003 | F: 0.0029 | I: 0.0177\n",
      "[Train 10000] D: 1.9211 | G: 0.1233 | Adv: 2.1786 | F: 0.0021 | I: 0.0119\n",
      "[Train 11000] D: 0.8874 | G: 0.1584 | Adv: 1.4741 | F: 0.0027 | I: 0.0154\n",
      "[Train 12000] D: 0.8152 | G: 0.1515 | Adv: 1.6238 | F: 0.0024 | I: 0.0147\n",
      "[Train 13000] D: 0.8231 | G: 0.1925 | Adv: 1.4628 | F: 0.0032 | I: 0.0188\n",
      "[Train 14000] D: 0.8072 | G: 0.1963 | Adv: 2.0306 | F: 0.0033 | I: 0.0191\n",
      "[Train 15000] D: 0.9557 | G: 0.1635 | Adv: 2.2071 | F: 0.0027 | I: 0.0159\n",
      "[Train 16000] D: 0.9314 | G: 0.2059 | Adv: 1.5969 | F: 0.0036 | I: 0.0201\n",
      "[Train 17000] D: 1.1030 | G: 0.1288 | Adv: 1.1362 | F: 0.0021 | I: 0.0126\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.2001\n",
      " Val PSNR : 33.81\n",
      " Val SSIM : 0.7840\n",
      " Val NMSE : 0.0333\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.2001)\n",
      "\n",
      "===== Epoch 4/50 =====\n",
      "[Train 0] D: 0.7495 | G: 0.2740 | Adv: 1.9309 | F: 0.0045 | I: 0.0268\n",
      "[Train 1000] D: 0.9096 | G: 0.1974 | Adv: 1.7407 | F: 0.0033 | I: 0.0192\n",
      "[Train 2000] D: 1.0767 | G: 0.1702 | Adv: 1.0575 | F: 0.0028 | I: 0.0166\n",
      "[Train 3000] D: 1.0520 | G: 0.1025 | Adv: 2.4148 | F: 0.0017 | I: 0.0098\n",
      "[Train 4000] D: 0.8423 | G: 0.2360 | Adv: 1.4136 | F: 0.0040 | I: 0.0231\n",
      "[Train 5000] D: 1.1140 | G: 0.1120 | Adv: 2.2610 | F: 0.0018 | I: 0.0108\n",
      "[Train 6000] D: 0.7795 | G: 0.2317 | Adv: 1.6851 | F: 0.0039 | I: 0.0226\n",
      "[Train 7000] D: 1.0535 | G: 0.1420 | Adv: 2.2113 | F: 0.0022 | I: 0.0138\n",
      "[Train 8000] D: 0.8307 | G: 0.1848 | Adv: 1.7176 | F: 0.0030 | I: 0.0180\n",
      "[Train 9000] D: 0.8885 | G: 0.1813 | Adv: 2.0016 | F: 0.0029 | I: 0.0176\n",
      "[Train 10000] D: 1.6572 | G: 0.1224 | Adv: 2.1242 | F: 0.0020 | I: 0.0118\n",
      "[Train 11000] D: 0.8779 | G: 0.1575 | Adv: 1.6920 | F: 0.0026 | I: 0.0153\n",
      "[Train 12000] D: 0.8462 | G: 0.1511 | Adv: 1.5799 | F: 0.0024 | I: 0.0147\n",
      "[Train 13000] D: 0.8830 | G: 0.1921 | Adv: 1.2965 | F: 0.0032 | I: 0.0188\n",
      "[Train 14000] D: 0.7072 | G: 0.1942 | Adv: 2.0581 | F: 0.0031 | I: 0.0189\n",
      "[Train 15000] D: 0.7157 | G: 0.1608 | Adv: 2.2898 | F: 0.0025 | I: 0.0156\n",
      "[Train 16000] D: 0.6615 | G: 0.2025 | Adv: 2.4772 | F: 0.0031 | I: 0.0197\n",
      "[Train 17000] D: 0.6720 | G: 0.1273 | Adv: 2.3120 | F: 0.0019 | I: 0.0123\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1972\n",
      " Val PSNR : 33.91\n",
      " Val SSIM : 0.7886\n",
      " Val NMSE : 0.0327\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1972)\n",
      "\n",
      "===== Epoch 5/50 =====\n",
      "[Train 0] D: 0.6587 | G: 0.2702 | Adv: 2.3563 | F: 0.0041 | I: 0.0264\n",
      "[Train 1000] D: 0.6794 | G: 0.1951 | Adv: 2.5785 | F: 0.0030 | I: 0.0190\n",
      "[Train 2000] D: 0.7270 | G: 0.1680 | Adv: 1.9635 | F: 0.0025 | I: 0.0164\n",
      "[Train 3000] D: 0.6640 | G: 0.1008 | Adv: 2.3772 | F: 0.0015 | I: 0.0097\n",
      "[Train 4000] D: 0.6769 | G: 0.2339 | Adv: 2.2610 | F: 0.0036 | I: 0.0228\n",
      "[Train 5000] D: 0.6665 | G: 0.1096 | Adv: 2.2731 | F: 0.0016 | I: 0.0106\n",
      "[Train 6000] D: 0.6576 | G: 0.2281 | Adv: 2.3358 | F: 0.0034 | I: 0.0222\n",
      "[Train 7000] D: 0.6728 | G: 0.1400 | Adv: 2.3750 | F: 0.0019 | I: 0.0136\n",
      "[Train 8000] D: 0.7082 | G: 0.1818 | Adv: 1.9207 | F: 0.0027 | I: 0.0177\n",
      "[Train 9000] D: 0.6614 | G: 0.1777 | Adv: 2.4220 | F: 0.0025 | I: 0.0173\n",
      "[Train 10000] D: 1.3310 | G: 0.1203 | Adv: 2.0917 | F: 0.0018 | I: 0.0116\n",
      "[Train 11000] D: 0.6532 | G: 0.1551 | Adv: 2.3444 | F: 0.0022 | I: 0.0151\n",
      "[Train 12000] D: 0.7997 | G: 0.1498 | Adv: 1.9387 | F: 0.0022 | I: 0.0146\n",
      "[Train 13000] D: 0.6526 | G: 0.1888 | Adv: 2.2197 | F: 0.0028 | I: 0.0184\n",
      "[Train 14000] D: 0.6531 | G: 0.1923 | Adv: 2.3642 | F: 0.0028 | I: 0.0187\n",
      "[Train 15000] D: 0.6838 | G: 0.1594 | Adv: 2.2439 | F: 0.0024 | I: 0.0155\n",
      "[Train 16000] D: 0.6526 | G: 0.2013 | Adv: 2.3680 | F: 0.0030 | I: 0.0196\n",
      "[Train 17000] D: 0.6558 | G: 0.1268 | Adv: 2.2968 | F: 0.0019 | I: 0.0123\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1962\n",
      " Val PSNR : 33.97\n",
      " Val SSIM : 0.7902\n",
      " Val NMSE : 0.0325\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1962)\n",
      "\n",
      "===== Epoch 6/50 =====\n",
      "[Train 0] D: 0.6531 | G: 0.2693 | Adv: 2.3139 | F: 0.0041 | I: 0.0263\n",
      "[Train 1000] D: 0.6524 | G: 0.1935 | Adv: 2.2817 | F: 0.0029 | I: 0.0188\n",
      "[Train 2000] D: 0.6721 | G: 0.1664 | Adv: 2.1135 | F: 0.0025 | I: 0.0162\n",
      "[Train 3000] D: 0.6525 | G: 0.1001 | Adv: 2.3425 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6588 | G: 0.2326 | Adv: 2.2427 | F: 0.0035 | I: 0.0227\n",
      "[Train 5000] D: 0.6572 | G: 0.1089 | Adv: 2.3214 | F: 0.0015 | I: 0.0105\n",
      "[Train 6000] D: 0.6546 | G: 0.2274 | Adv: 2.2768 | F: 0.0034 | I: 0.0222\n",
      "[Train 7000] D: 0.6608 | G: 0.1394 | Adv: 2.3218 | F: 0.0019 | I: 0.0135\n",
      "[Train 8000] D: 0.6672 | G: 0.1807 | Adv: 2.1626 | F: 0.0027 | I: 0.0176\n",
      "[Train 9000] D: 0.6527 | G: 0.1771 | Adv: 2.2965 | F: 0.0025 | I: 0.0172\n",
      "[Train 10000] D: 0.7312 | G: 0.1199 | Adv: 2.1102 | F: 0.0018 | I: 0.0116\n",
      "[Train 11000] D: 0.6513 | G: 0.1547 | Adv: 2.2905 | F: 0.0022 | I: 0.0150\n",
      "[Train 12000] D: 0.6931 | G: 0.1490 | Adv: 2.1379 | F: 0.0022 | I: 0.0145\n",
      "[Train 13000] D: 0.6513 | G: 0.1887 | Adv: 2.2740 | F: 0.0029 | I: 0.0184\n",
      "[Train 14000] D: 0.6520 | G: 0.1919 | Adv: 2.3306 | F: 0.0028 | I: 0.0187\n",
      "[Train 15000] D: 0.6697 | G: 0.1589 | Adv: 2.3113 | F: 0.0024 | I: 0.0154\n",
      "[Train 16000] D: 0.6514 | G: 0.2008 | Adv: 2.2948 | F: 0.0030 | I: 0.0196\n",
      "[Train 17000] D: 0.6547 | G: 0.1268 | Adv: 2.3140 | F: 0.0019 | I: 0.0123\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1959\n",
      " Val PSNR : 33.99\n",
      " Val SSIM : 0.7903\n",
      " Val NMSE : 0.0325\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1959)\n",
      "\n",
      "===== Epoch 7/50 =====\n",
      "[Train 0] D: 0.6519 | G: 0.2690 | Adv: 2.3109 | F: 0.0041 | I: 0.0263\n",
      "[Train 1000] D: 0.6517 | G: 0.1932 | Adv: 2.2844 | F: 0.0028 | I: 0.0188\n",
      "[Train 2000] D: 0.6582 | G: 0.1660 | Adv: 2.1925 | F: 0.0025 | I: 0.0161\n",
      "[Train 3000] D: 0.6520 | G: 0.0999 | Adv: 2.3324 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6574 | G: 0.2323 | Adv: 2.4354 | F: 0.0035 | I: 0.0226\n",
      "[Train 5000] D: 0.6552 | G: 0.1085 | Adv: 2.3246 | F: 0.0015 | I: 0.0105\n",
      "[Train 6000] D: 0.6590 | G: 0.2273 | Adv: 2.1860 | F: 0.0034 | I: 0.0222\n",
      "[Train 7000] D: 0.6547 | G: 0.1393 | Adv: 2.3063 | F: 0.0019 | I: 0.0135\n",
      "[Train 8000] D: 0.6598 | G: 0.1800 | Adv: 2.2340 | F: 0.0027 | I: 0.0175\n",
      "[Train 9000] D: 0.6515 | G: 0.1769 | Adv: 2.2744 | F: 0.0025 | I: 0.0172\n",
      "[Train 10000] D: 0.7486 | G: 0.1197 | Adv: 2.1453 | F: 0.0018 | I: 0.0116\n",
      "[Train 11000] D: 0.6510 | G: 0.1545 | Adv: 2.2914 | F: 0.0022 | I: 0.0150\n",
      "[Train 12000] D: 0.6523 | G: 0.1489 | Adv: 2.3319 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6509 | G: 0.1885 | Adv: 2.2963 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6513 | G: 0.1914 | Adv: 2.3052 | F: 0.0028 | I: 0.0186\n",
      "[Train 15000] D: 0.6554 | G: 0.1578 | Adv: 2.3665 | F: 0.0023 | I: 0.0153\n",
      "[Train 16000] D: 0.6510 | G: 0.2006 | Adv: 2.2995 | F: 0.0030 | I: 0.0195\n",
      "[Train 17000] D: 0.6528 | G: 0.1266 | Adv: 2.3002 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1957\n",
      " Val PSNR : 34.01\n",
      " Val SSIM : 0.7912\n",
      " Val NMSE : 0.0323\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1957)\n",
      "\n",
      "===== Epoch 8/50 =====\n",
      "[Train 0] D: 0.6514 | G: 0.2688 | Adv: 2.2964 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6516 | G: 0.1927 | Adv: 2.2845 | F: 0.0028 | I: 0.0188\n",
      "[Train 2000] D: 0.6535 | G: 0.1655 | Adv: 2.2402 | F: 0.0025 | I: 0.0161\n",
      "[Train 3000] D: 0.6512 | G: 0.0999 | Adv: 2.3196 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6522 | G: 0.2317 | Adv: 2.3237 | F: 0.0035 | I: 0.0226\n",
      "[Train 5000] D: 0.6527 | G: 0.1082 | Adv: 2.2914 | F: 0.0015 | I: 0.0104\n",
      "[Train 6000] D: 0.6517 | G: 0.2269 | Adv: 2.2990 | F: 0.0035 | I: 0.0221\n",
      "[Train 7000] D: 0.6519 | G: 0.1389 | Adv: 2.2994 | F: 0.0019 | I: 0.0135\n",
      "[Train 8000] D: 0.6528 | G: 0.1798 | Adv: 2.3546 | F: 0.0027 | I: 0.0175\n",
      "[Train 9000] D: 0.6514 | G: 0.1767 | Adv: 2.2732 | F: 0.0025 | I: 0.0172\n",
      "[Train 10000] D: 0.6641 | G: 0.1194 | Adv: 2.1447 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6509 | G: 0.1543 | Adv: 2.2969 | F: 0.0022 | I: 0.0150\n",
      "[Train 12000] D: 0.6582 | G: 0.1488 | Adv: 2.2677 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6507 | G: 0.1885 | Adv: 2.2968 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6508 | G: 0.1914 | Adv: 2.3079 | F: 0.0028 | I: 0.0186\n",
      "[Train 15000] D: 0.6569 | G: 0.1572 | Adv: 2.3193 | F: 0.0023 | I: 0.0153\n",
      "[Train 16000] D: 0.6514 | G: 0.2001 | Adv: 2.2643 | F: 0.0030 | I: 0.0195\n",
      "[Train 17000] D: 0.6531 | G: 0.1266 | Adv: 2.3310 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1956\n",
      " Val PSNR : 34.03\n",
      " Val SSIM : 0.7919\n",
      " Val NMSE : 0.0322\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1956)\n",
      "\n",
      "===== Epoch 9/50 =====\n",
      "[Train 0] D: 0.6513 | G: 0.2687 | Adv: 2.2985 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6511 | G: 0.1924 | Adv: 2.2894 | F: 0.0028 | I: 0.0187\n",
      "[Train 2000] D: 0.6517 | G: 0.1648 | Adv: 2.2632 | F: 0.0024 | I: 0.0160\n",
      "[Train 3000] D: 0.6513 | G: 0.0998 | Adv: 2.3238 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6552 | G: 0.2316 | Adv: 2.2753 | F: 0.0035 | I: 0.0226\n",
      "[Train 5000] D: 0.6536 | G: 0.1082 | Adv: 2.2893 | F: 0.0015 | I: 0.0104\n",
      "[Train 6000] D: 0.6515 | G: 0.2269 | Adv: 2.2847 | F: 0.0034 | I: 0.0221\n",
      "[Train 7000] D: 0.6514 | G: 0.1389 | Adv: 2.2995 | F: 0.0019 | I: 0.0135\n",
      "[Train 8000] D: 0.6530 | G: 0.1788 | Adv: 2.2798 | F: 0.0026 | I: 0.0174\n",
      "[Train 9000] D: 0.6510 | G: 0.1765 | Adv: 2.2955 | F: 0.0024 | I: 0.0172\n",
      "[Train 10000] D: 0.6596 | G: 0.1194 | Adv: 2.2286 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6507 | G: 0.1542 | Adv: 2.2999 | F: 0.0022 | I: 0.0150\n",
      "[Train 12000] D: 0.6518 | G: 0.1488 | Adv: 2.3251 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6506 | G: 0.1884 | Adv: 2.3033 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6507 | G: 0.1909 | Adv: 2.3055 | F: 0.0028 | I: 0.0186\n",
      "[Train 15000] D: 0.6536 | G: 0.1573 | Adv: 2.3111 | F: 0.0023 | I: 0.0153\n",
      "[Train 16000] D: 0.6510 | G: 0.1998 | Adv: 2.2630 | F: 0.0030 | I: 0.0195\n",
      "[Train 17000] D: 0.6526 | G: 0.1267 | Adv: 2.3410 | F: 0.0020 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1955\n",
      " Val PSNR : 33.99\n",
      " Val SSIM : 0.7901\n",
      " Val NMSE : 0.0328\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1955)\n",
      "\n",
      "===== Epoch 10/50 =====\n",
      "[Train 0] D: 0.6510 | G: 0.2686 | Adv: 2.2998 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6525 | G: 0.1921 | Adv: 2.2796 | F: 0.0028 | I: 0.0187\n",
      "[Train 2000] D: 0.6510 | G: 0.1646 | Adv: 2.2857 | F: 0.0024 | I: 0.0160\n",
      "[Train 3000] D: 0.6509 | G: 0.0997 | Adv: 2.3152 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6524 | G: 0.2313 | Adv: 2.2700 | F: 0.0035 | I: 0.0226\n",
      "[Train 5000] D: 0.6512 | G: 0.1077 | Adv: 2.3004 | F: 0.0015 | I: 0.0104\n",
      "[Train 6000] D: 0.6510 | G: 0.2263 | Adv: 2.2873 | F: 0.0035 | I: 0.0221\n",
      "[Train 7000] D: 0.6512 | G: 0.1386 | Adv: 2.3017 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6557 | G: 0.1786 | Adv: 2.3053 | F: 0.0026 | I: 0.0174\n",
      "[Train 9000] D: 0.6511 | G: 0.1764 | Adv: 2.3316 | F: 0.0024 | I: 0.0172\n",
      "[Train 10000] D: 0.6590 | G: 0.1192 | Adv: 2.2160 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6506 | G: 0.1541 | Adv: 2.2966 | F: 0.0022 | I: 0.0150\n",
      "[Train 12000] D: 0.6515 | G: 0.1487 | Adv: 2.3228 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6506 | G: 0.1883 | Adv: 2.3122 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6506 | G: 0.1907 | Adv: 2.2908 | F: 0.0028 | I: 0.0186\n",
      "[Train 15000] D: 0.6530 | G: 0.1568 | Adv: 2.2891 | F: 0.0023 | I: 0.0152\n",
      "[Train 16000] D: 0.6508 | G: 0.1996 | Adv: 2.2821 | F: 0.0030 | I: 0.0194\n",
      "[Train 17000] D: 0.6518 | G: 0.1265 | Adv: 2.3133 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1954\n",
      " Val PSNR : 34.04\n",
      " Val SSIM : 0.7921\n",
      " Val NMSE : 0.0323\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1954)\n",
      "\n",
      "===== Epoch 11/50 =====\n",
      "[Train 0] D: 0.6510 | G: 0.2685 | Adv: 2.2963 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6514 | G: 0.1918 | Adv: 2.2901 | F: 0.0028 | I: 0.0187\n",
      "[Train 2000] D: 0.6508 | G: 0.1650 | Adv: 2.2935 | F: 0.0025 | I: 0.0160\n",
      "[Train 3000] D: 0.6510 | G: 0.0995 | Adv: 2.3184 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6515 | G: 0.2310 | Adv: 2.2941 | F: 0.0034 | I: 0.0225\n",
      "[Train 5000] D: 0.6512 | G: 0.1076 | Adv: 2.2994 | F: 0.0015 | I: 0.0104\n",
      "[Train 6000] D: 0.6509 | G: 0.2262 | Adv: 2.2907 | F: 0.0034 | I: 0.0220\n",
      "[Train 7000] D: 0.6509 | G: 0.1386 | Adv: 2.3028 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6531 | G: 0.1782 | Adv: 2.3090 | F: 0.0026 | I: 0.0173\n",
      "[Train 9000] D: 0.6511 | G: 0.1763 | Adv: 2.3149 | F: 0.0024 | I: 0.0172\n",
      "[Train 10000] D: 0.6673 | G: 0.1191 | Adv: 2.2159 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6504 | G: 0.1539 | Adv: 2.2960 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6535 | G: 0.1487 | Adv: 2.3542 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6504 | G: 0.1883 | Adv: 2.2966 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6506 | G: 0.1904 | Adv: 2.3111 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6553 | G: 0.1565 | Adv: 2.3117 | F: 0.0023 | I: 0.0152\n",
      "[Train 16000] D: 0.6507 | G: 0.1995 | Adv: 2.2860 | F: 0.0030 | I: 0.0194\n",
      "[Train 17000] D: 0.6514 | G: 0.1264 | Adv: 2.3170 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1954\n",
      " Val PSNR : 34.05\n",
      " Val SSIM : 0.7927\n",
      " Val NMSE : 0.0321\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1954)\n",
      "\n",
      "===== Epoch 12/50 =====\n",
      "[Train 0] D: 0.6511 | G: 0.2685 | Adv: 2.2938 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6506 | G: 0.1913 | Adv: 2.2956 | F: 0.0028 | I: 0.0186\n",
      "[Train 2000] D: 0.6506 | G: 0.1642 | Adv: 2.2983 | F: 0.0024 | I: 0.0160\n",
      "[Train 3000] D: 0.6507 | G: 0.0996 | Adv: 2.3173 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6507 | G: 0.2309 | Adv: 2.3039 | F: 0.0035 | I: 0.0225\n",
      "[Train 5000] D: 0.6508 | G: 0.1073 | Adv: 2.2956 | F: 0.0015 | I: 0.0103\n",
      "[Train 6000] D: 0.6507 | G: 0.2261 | Adv: 2.3051 | F: 0.0035 | I: 0.0220\n",
      "[Train 7000] D: 0.6507 | G: 0.1385 | Adv: 2.2951 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6535 | G: 0.1780 | Adv: 2.3035 | F: 0.0026 | I: 0.0173\n",
      "[Train 9000] D: 0.6507 | G: 0.1761 | Adv: 2.3026 | F: 0.0024 | I: 0.0171\n",
      "[Train 10000] D: 0.6591 | G: 0.1191 | Adv: 2.2244 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6504 | G: 0.1538 | Adv: 2.2998 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6506 | G: 0.1486 | Adv: 2.3069 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6505 | G: 0.1883 | Adv: 2.3096 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6504 | G: 0.1904 | Adv: 2.3008 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6581 | G: 0.1566 | Adv: 2.2780 | F: 0.0023 | I: 0.0152\n",
      "[Train 16000] D: 0.6505 | G: 0.1993 | Adv: 2.3084 | F: 0.0030 | I: 0.0194\n",
      "[Train 17000] D: 0.6510 | G: 0.1265 | Adv: 2.3303 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1955\n",
      " Val PSNR : 34.04\n",
      " Val SSIM : 0.7929\n",
      " Val NMSE : 0.0319\n",
      "\n",
      "===== Epoch 13/50 =====\n",
      "[Train 0] D: 0.6507 | G: 0.2686 | Adv: 2.2996 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6508 | G: 0.1914 | Adv: 2.2914 | F: 0.0028 | I: 0.0186\n",
      "[Train 2000] D: 0.6506 | G: 0.1647 | Adv: 2.3005 | F: 0.0025 | I: 0.0160\n",
      "[Train 3000] D: 0.6505 | G: 0.0995 | Adv: 2.3121 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6512 | G: 0.2307 | Adv: 2.3235 | F: 0.0034 | I: 0.0225\n",
      "[Train 5000] D: 0.6510 | G: 0.1073 | Adv: 2.2882 | F: 0.0015 | I: 0.0104\n",
      "[Train 6000] D: 0.6508 | G: 0.2260 | Adv: 2.2994 | F: 0.0034 | I: 0.0220\n",
      "[Train 7000] D: 0.6506 | G: 0.1385 | Adv: 2.2969 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6513 | G: 0.1776 | Adv: 2.2493 | F: 0.0026 | I: 0.0173\n",
      "[Train 9000] D: 0.6505 | G: 0.1761 | Adv: 2.2958 | F: 0.0024 | I: 0.0171\n",
      "[Train 10000] D: 0.6647 | G: 0.1190 | Adv: 2.2340 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6504 | G: 0.1537 | Adv: 2.3001 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6508 | G: 0.1485 | Adv: 2.2968 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6504 | G: 0.1882 | Adv: 2.3084 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6504 | G: 0.1902 | Adv: 2.3096 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6554 | G: 0.1561 | Adv: 2.2453 | F: 0.0023 | I: 0.0152\n",
      "[Train 16000] D: 0.6505 | G: 0.1991 | Adv: 2.2887 | F: 0.0030 | I: 0.0194\n",
      "[Train 17000] D: 0.6513 | G: 0.1264 | Adv: 2.2862 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1953\n",
      " Val PSNR : 34.03\n",
      " Val SSIM : 0.7920\n",
      " Val NMSE : 0.0324\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1953)\n",
      "\n",
      "===== Epoch 14/50 =====\n",
      "[Train 0] D: 0.6509 | G: 0.2683 | Adv: 2.2855 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6505 | G: 0.1912 | Adv: 2.2968 | F: 0.0028 | I: 0.0186\n",
      "[Train 2000] D: 0.6505 | G: 0.1643 | Adv: 2.2935 | F: 0.0024 | I: 0.0160\n",
      "[Train 3000] D: 0.6505 | G: 0.0995 | Adv: 2.3190 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6507 | G: 0.2306 | Adv: 2.2867 | F: 0.0034 | I: 0.0225\n",
      "[Train 5000] D: 0.6506 | G: 0.1072 | Adv: 2.3108 | F: 0.0015 | I: 0.0103\n",
      "[Train 6000] D: 0.6506 | G: 0.2261 | Adv: 2.3001 | F: 0.0034 | I: 0.0220\n",
      "[Train 7000] D: 0.6505 | G: 0.1384 | Adv: 2.2972 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6545 | G: 0.1775 | Adv: 2.2908 | F: 0.0026 | I: 0.0173\n",
      "[Train 9000] D: 0.6504 | G: 0.1761 | Adv: 2.3040 | F: 0.0024 | I: 0.0171\n",
      "[Train 10000] D: 0.6556 | G: 0.1190 | Adv: 2.3081 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6503 | G: 0.1534 | Adv: 2.3063 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6631 | G: 0.1485 | Adv: 2.2448 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6503 | G: 0.1882 | Adv: 2.3045 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6504 | G: 0.1899 | Adv: 2.2833 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6552 | G: 0.1561 | Adv: 2.2944 | F: 0.0023 | I: 0.0151\n",
      "[Train 16000] D: 0.6504 | G: 0.1991 | Adv: 2.3322 | F: 0.0030 | I: 0.0194\n",
      "[Train 17000] D: 0.6506 | G: 0.1264 | Adv: 2.3073 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1954\n",
      " Val PSNR : 34.03\n",
      " Val SSIM : 0.7911\n",
      " Val NMSE : 0.0323\n",
      "\n",
      "===== Epoch 15/50 =====\n",
      "[Train 0] D: 0.6505 | G: 0.2683 | Adv: 2.3007 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6504 | G: 0.1907 | Adv: 2.3001 | F: 0.0028 | I: 0.0186\n",
      "[Train 2000] D: 0.6504 | G: 0.1641 | Adv: 2.3095 | F: 0.0024 | I: 0.0159\n",
      "[Train 3000] D: 0.6505 | G: 0.0994 | Adv: 2.3014 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6506 | G: 0.2304 | Adv: 2.3042 | F: 0.0034 | I: 0.0225\n",
      "[Train 5000] D: 0.6505 | G: 0.1068 | Adv: 2.3055 | F: 0.0015 | I: 0.0103\n",
      "[Train 6000] D: 0.6504 | G: 0.2258 | Adv: 2.2978 | F: 0.0034 | I: 0.0220\n",
      "[Train 7000] D: 0.6504 | G: 0.1383 | Adv: 2.3006 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6519 | G: 0.1771 | Adv: 2.3214 | F: 0.0026 | I: 0.0172\n",
      "[Train 9000] D: 0.6505 | G: 0.1758 | Adv: 2.3058 | F: 0.0024 | I: 0.0171\n",
      "[Train 10000] D: 0.6576 | G: 0.1190 | Adv: 2.3077 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6503 | G: 0.1536 | Adv: 2.3045 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6505 | G: 0.1485 | Adv: 2.2979 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6503 | G: 0.1882 | Adv: 2.3123 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6504 | G: 0.1898 | Adv: 2.3018 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6528 | G: 0.1558 | Adv: 2.2675 | F: 0.0023 | I: 0.0151\n",
      "[Train 16000] D: 0.6503 | G: 0.1990 | Adv: 2.3035 | F: 0.0030 | I: 0.0194\n",
      "[Train 17000] D: 0.6510 | G: 0.1264 | Adv: 2.2996 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1952\n",
      " Val PSNR : 34.06\n",
      " Val SSIM : 0.7928\n",
      " Val NMSE : 0.0320\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1952)\n",
      "\n",
      "===== Epoch 16/50 =====\n",
      "[Train 0] D: 0.6505 | G: 0.2682 | Adv: 2.2977 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6504 | G: 0.1907 | Adv: 2.3040 | F: 0.0028 | I: 0.0186\n",
      "[Train 2000] D: 0.6509 | G: 0.1634 | Adv: 2.2865 | F: 0.0024 | I: 0.0159\n",
      "[Train 3000] D: 0.6504 | G: 0.0994 | Adv: 2.3144 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6508 | G: 0.2303 | Adv: 2.2490 | F: 0.0034 | I: 0.0225\n",
      "[Train 5000] D: 0.6505 | G: 0.1069 | Adv: 2.3079 | F: 0.0015 | I: 0.0103\n",
      "[Train 6000] D: 0.6504 | G: 0.2257 | Adv: 2.3003 | F: 0.0034 | I: 0.0220\n",
      "[Train 7000] D: 0.6504 | G: 0.1382 | Adv: 2.2957 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6511 | G: 0.1765 | Adv: 2.2357 | F: 0.0026 | I: 0.0172\n",
      "[Train 9000] D: 0.6503 | G: 0.1758 | Adv: 2.3102 | F: 0.0024 | I: 0.0171\n",
      "[Train 10000] D: 0.6591 | G: 0.1188 | Adv: 2.2865 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6503 | G: 0.1534 | Adv: 2.3012 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6505 | G: 0.1485 | Adv: 2.2976 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6503 | G: 0.1881 | Adv: 2.3092 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6503 | G: 0.1896 | Adv: 2.3013 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6518 | G: 0.1561 | Adv: 2.2749 | F: 0.0023 | I: 0.0151\n",
      "[Train 16000] D: 0.6504 | G: 0.1988 | Adv: 2.2902 | F: 0.0030 | I: 0.0193\n",
      "[Train 17000] D: 0.6507 | G: 0.1263 | Adv: 2.2921 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1953\n",
      " Val PSNR : 34.07\n",
      " Val SSIM : 0.7931\n",
      " Val NMSE : 0.0319\n",
      "\n",
      "===== Epoch 17/50 =====\n",
      "[Train 0] D: 0.6506 | G: 0.2682 | Adv: 2.2943 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6504 | G: 0.1904 | Adv: 2.3041 | F: 0.0028 | I: 0.0185\n",
      "[Train 2000] D: 0.6504 | G: 0.1638 | Adv: 2.3084 | F: 0.0024 | I: 0.0159\n",
      "[Train 3000] D: 0.6503 | G: 0.0994 | Adv: 2.3140 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6505 | G: 0.2301 | Adv: 2.2784 | F: 0.0034 | I: 0.0224\n",
      "[Train 5000] D: 0.6504 | G: 0.1067 | Adv: 2.3106 | F: 0.0015 | I: 0.0103\n",
      "[Train 6000] D: 0.6505 | G: 0.2259 | Adv: 2.2960 | F: 0.0034 | I: 0.0220\n",
      "[Train 7000] D: 0.6504 | G: 0.1381 | Adv: 2.2984 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6506 | G: 0.1764 | Adv: 2.3205 | F: 0.0026 | I: 0.0171\n",
      "[Train 9000] D: 0.6504 | G: 0.1757 | Adv: 2.3047 | F: 0.0024 | I: 0.0171\n",
      "[Train 10000] D: 0.6567 | G: 0.1190 | Adv: 2.2972 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6503 | G: 0.1533 | Adv: 2.3053 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6504 | G: 0.1485 | Adv: 2.3104 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6503 | G: 0.1881 | Adv: 2.3071 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6503 | G: 0.1896 | Adv: 2.2996 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6514 | G: 0.1558 | Adv: 2.2964 | F: 0.0023 | I: 0.0151\n",
      "[Train 16000] D: 0.6503 | G: 0.1986 | Adv: 2.2935 | F: 0.0030 | I: 0.0193\n",
      "[Train 17000] D: 0.6505 | G: 0.1263 | Adv: 2.2949 | F: 0.0019 | I: 0.0122\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      " Val Loss : 0.1952\n",
      " Val PSNR : 34.07\n",
      " Val SSIM : 0.7933\n",
      " Val NMSE : 0.0319\n",
      "ðŸ”¥ Saved BEST model (Val Loss = 0.1952)\n",
      "\n",
      "===== Epoch 18/50 =====\n",
      "[Train 0] D: 0.6504 | G: 0.2682 | Adv: 2.2950 | F: 0.0041 | I: 0.0262\n",
      "[Train 1000] D: 0.6503 | G: 0.1902 | Adv: 2.3044 | F: 0.0028 | I: 0.0185\n",
      "[Train 2000] D: 0.6508 | G: 0.1634 | Adv: 2.3029 | F: 0.0024 | I: 0.0159\n",
      "[Train 3000] D: 0.6503 | G: 0.0993 | Adv: 2.3085 | F: 0.0014 | I: 0.0096\n",
      "[Train 4000] D: 0.6503 | G: 0.2301 | Adv: 2.3050 | F: 0.0034 | I: 0.0224\n",
      "[Train 5000] D: 0.6503 | G: 0.1066 | Adv: 2.3093 | F: 0.0015 | I: 0.0103\n",
      "[Train 6000] D: 0.6503 | G: 0.2256 | Adv: 2.3010 | F: 0.0034 | I: 0.0220\n",
      "[Train 7000] D: 0.6503 | G: 0.1381 | Adv: 2.3023 | F: 0.0018 | I: 0.0134\n",
      "[Train 8000] D: 0.6507 | G: 0.1760 | Adv: 2.2864 | F: 0.0026 | I: 0.0171\n",
      "[Train 9000] D: 0.6503 | G: 0.1757 | Adv: 2.3113 | F: 0.0024 | I: 0.0171\n",
      "[Train 10000] D: 0.6533 | G: 0.1187 | Adv: 2.2975 | F: 0.0018 | I: 0.0115\n",
      "[Train 11000] D: 0.6503 | G: 0.1531 | Adv: 2.3015 | F: 0.0022 | I: 0.0149\n",
      "[Train 12000] D: 0.6504 | G: 0.1485 | Adv: 2.3004 | F: 0.0022 | I: 0.0144\n",
      "[Train 13000] D: 0.6504 | G: 0.1881 | Adv: 2.3130 | F: 0.0029 | I: 0.0183\n",
      "[Train 14000] D: 0.6503 | G: 0.1896 | Adv: 2.3056 | F: 0.0028 | I: 0.0185\n",
      "[Train 15000] D: 0.6524 | G: 0.1552 | Adv: 2.2886 | F: 0.0023 | I: 0.0151\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ======================\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ======================\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (SZF, SGT) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_gen):\n\u001b[1;32m----> 9\u001b[0m     d_loss, g_loss, adv, freq, img \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSZF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSGT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    print(f\"\\n===== Epoch {epoch+1}/{EPOCHS} =====\")\n",
    "\n",
    "    # ======================\n",
    "    # Training\n",
    "    # ======================\n",
    "    for step, (SZF, SGT) in enumerate(train_gen):\n",
    "\n",
    "        d_loss, g_loss, adv, freq, img = train_step(\n",
    "            SZF, SGT, mask\n",
    "        )\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                f\"[Train {step}] \"\n",
    "                f\"D: {d_loss:.4f} | \"\n",
    "                f\"G: {g_loss:.4f} | \"\n",
    "                f\"Adv: {adv:.4f} | \"\n",
    "                f\"F: {freq:.4f} | \"\n",
    "                f\"I: {img:.4f}\"\n",
    "            )\n",
    "\n",
    "    # ======================\n",
    "    # Validation\n",
    "    # ======================\n",
    "    val_loss, val_psnr, val_ssim, val_nmse = run_validation(val_gen, mask)\n",
    "\n",
    "    print(\"\\nðŸ“Š Validation Results\")\n",
    "    print(f\" Val Loss : {val_loss:.4f}\")\n",
    "    print(f\" Val PSNR : {val_psnr:.2f}\")\n",
    "    print(f\" Val SSIM : {val_ssim:.4f}\")\n",
    "    print(f\" Val NMSE : {val_nmse:.4f}\")\n",
    "\n",
    "    # Save epoch counter\n",
    "    epoch_counter.assign(epoch + 1)\n",
    "\n",
    "    # ======================\n",
    "    # Save BEST model\n",
    "    # ======================\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        ckpt_manager.save()\n",
    "        print(f\"ðŸ”¥ Saved BEST model (Val Loss = {val_loss:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872be032-895e-4ab2-9c4e-b1cedf3f1ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5137c-70b7-4b5e-bab6-8c7eb321cfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593d619-4163-457d-b937-fd4d1708838b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
