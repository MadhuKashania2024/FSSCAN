{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b599972a-142f-494d-8eca-eb3938efa8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d390713c-efa0-4dea-baad-0200941d05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fb8655-f83f-4619-b22a-92a477b50570",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = \"./SavedModels_RSCA_GAN_full_2\"\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "TEST_FILES = sorted(\n",
    "    glob.glob(os.path.join(val_folder, \"*.h5\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac8e421e-e772-43c9-a578-458801f691a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD volumes: 100\n",
      "PDFS volumes: 99\n"
     ]
    }
   ],
   "source": [
    "pd_files = []\n",
    "pdfs_files = []\n",
    "\n",
    "for f in TEST_FILES:\n",
    "    if \"PDFS\" in f:\n",
    "        pdfs_files.append(f)\n",
    "    else:\n",
    "        pd_files.append(f)\n",
    "\n",
    "print(f\"PD volumes: {len(pd_files)}\")\n",
    "print(f\"PDFS volumes: {len(pdfs_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbebbacf-3eaf-4444-8b6a-6dc29c9da56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9061123-c6ca-447f-829d-e090c0560418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded checkpoint: ./SavedModels_RSCA_GAN_full_2\\ckpt-14\n"
     ]
    }
   ],
   "source": [
    "model = RSCAGAN(in_channels=2, base_channels=32)\n",
    "generator = model.generator\n",
    "discriminator = model.discriminator  # required for ckpt restore\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator\n",
    ")\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt,\n",
    "    directory=CKPT_DIR,\n",
    "    max_to_keep=5\n",
    ")\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "    print(f\"‚úÖ Loaded checkpoint: {ckpt_manager.latest_checkpoint}\")\n",
    "else:\n",
    "    raise RuntimeError(\"‚ùå No checkpoint found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9ab6ab-9232-44d5-bdf9-f64bfa26a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_mag_np(x):\n",
    "    return np.sqrt(x[..., 0]**2 + x[..., 1]**2 + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52ac726-c463-4549-9620-6943d7f21c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(gt, pred):\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + 1e-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d7d3cd-d8b7-489e-8f85-49b59d3e9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05da1508-6c4a-460a-ba92-97ddeeff1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def inference_step(SZF):\n",
    "    return generator(SZF, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a285a98-7b9f-461a-a091-c1746b684087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_inference_and_save(test_files, out_dir=\"./Metrics\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # -------------------------\n",
    "    # Containers for Excel\n",
    "    # -------------------------\n",
    "    volume_rows = []   # per-volume metrics\n",
    "    slice_rows  = []   # slice-wise SSIM\n",
    "\n",
    "    for file_path in tqdm(test_files, desc=\"Inference (per-volume)\"):\n",
    "        volume_id = os.path.basename(file_path)\n",
    "\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            SZF  = f[\"image_under\"][:]            # (N,H,W,2)\n",
    "            SGT  = f[\"image_full\"][:]             # (N,H,W,2)\n",
    "            MAXV = f[\"max_val_full_image\"][0]     # scalar\n",
    "\n",
    "        slice_psnr = []\n",
    "        slice_ssim = []\n",
    "        slice_nmse = []\n",
    "\n",
    "        slice_counter = 0\n",
    "\n",
    "        for i in range(0, SZF.shape[0], BATCH_SIZE):\n",
    "            SZF_batch = SZF[i:i+BATCH_SIZE]\n",
    "            SGT_batch = SGT[i:i+BATCH_SIZE]\n",
    "\n",
    "            SRE_batch = inference_step(\n",
    "                tf.convert_to_tensor(SZF_batch, tf.float32)\n",
    "            ).numpy()\n",
    "\n",
    "            # -------------------------\n",
    "            # Magnitude + denormalize\n",
    "            # -------------------------\n",
    "            gt_mag  = complex_to_mag_np(SGT_batch) * MAXV\n",
    "            rec_mag = complex_to_mag_np(SRE_batch) * MAXV\n",
    "\n",
    "            for b in range(gt_mag.shape[0]):\n",
    "                gt  = gt_mag[b]\n",
    "                rec = rec_mag[b]\n",
    "\n",
    "                # PSNR\n",
    "                psnr_val = tf.image.psnr(\n",
    "                    gt[..., None], rec[..., None], max_val=MAXV\n",
    "                ).numpy()\n",
    "                slice_psnr.append(psnr_val)\n",
    "\n",
    "                # SSIM\n",
    "                ssim_val = compute_ssim(gt, rec, max_val=MAXV)\n",
    "                slice_ssim.append(ssim_val)\n",
    "\n",
    "                # NMSE\n",
    "                nmse_val = nmse(gt, rec)\n",
    "                slice_nmse.append(nmse_val)\n",
    "\n",
    "                # -------------------------\n",
    "                # Save slice-wise SSIM row\n",
    "                # -------------------------\n",
    "                slice_rows.append({\n",
    "                    \"volume_id\": volume_id,\n",
    "                    \"slice_id\": slice_counter,\n",
    "                    \"SSIM\": float(ssim_val)\n",
    "                })\n",
    "\n",
    "                slice_counter += 1\n",
    "\n",
    "        # -------------------------\n",
    "        # Per-volume aggregation\n",
    "        # -------------------------\n",
    "        volume_rows.append({\n",
    "            \"volume_id\": volume_id,\n",
    "            \"PSNR\": float(np.mean(slice_psnr)),\n",
    "            \"NMSE\": float(np.mean(slice_nmse)),\n",
    "            \"SSIM_mean\": float(np.mean(slice_ssim)),\n",
    "        })\n",
    "\n",
    "    # =========================\n",
    "    # Save Excel files\n",
    "    # =========================\n",
    "    df_volume = pd.DataFrame(volume_rows)\n",
    "    df_slice  = pd.DataFrame(slice_rows)\n",
    "\n",
    "    volume_excel_path = os.path.join(out_dir, \"RSCA_per_volume_metrics.xlsx\")\n",
    "    slice_excel_path  = os.path.join(out_dir, \"RSCA_slice_wise_ssim.xlsx\")\n",
    "\n",
    "    df_volume.to_excel(volume_excel_path, index=False)\n",
    "    df_slice.to_excel(slice_excel_path, index=False)\n",
    "\n",
    "    print(f\"Saved per-volume metrics to: {volume_excel_path}\")\n",
    "    print(f\"Saved slice-wise SSIM to:   {slice_excel_path}\")\n",
    "\n",
    "    return df_volume, df_slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68dbfdfd-5507-49dc-a48f-06a92fa43d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference (per-volume): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [05:36<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-volume metrics to: ./Metrics\\RSCA_per_volume_metrics.xlsx\n",
      "Saved slice-wise SSIM to:   ./Metrics\\RSCA_slice_wise_ssim.xlsx\n",
      "\n",
      "üìä RSCA-GAN INFERENCE RESULTS (Per-Volume)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m _,_  \u001b[38;5;241m=\u001b[39m run_inference_and_save(TEST_FILES)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä RSCA-GAN INFERENCE RESULTS (Per-Volume)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m PSNR : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSNR_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ¬± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSNR_std\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m SSIM : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSIM_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ¬± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSIM_std\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m NMSE : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNMSE_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ¬± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNMSE_std\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "_,_  = run_inference_and_save(TEST_FILES)\n",
    "\n",
    "print(\"\\nüìä RSCA-GAN INFERENCE RESULTS (Per-Volume)\")\n",
    "print(f\" PSNR : {results['PSNR_mean']:.2f} ¬± {results['PSNR_std']:.2f}\")\n",
    "print(f\" SSIM : {results['SSIM_mean']:.4f} ¬± {results['SSIM_std']:.4f}\")\n",
    "print(f\" NMSE : {results['NMSE_mean']:.6f} ¬± {results['NMSE_std']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c183600-1887-43a6-a179-3578fe4b41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(test_files):\n",
    "    vol_psnr = []\n",
    "    vol_ssim = []\n",
    "    vol_nmse = []\n",
    "\n",
    "    for file_path in tqdm(test_files, desc=\"Inference (per-volume)\"):\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            SZF  = f[\"image_under\"][:]            # (N,H,W,2)\n",
    "            SGT  = f[\"image_full\"][:]             # (N,H,W,2)\n",
    "            MAXV = f[\"max_val_full_image\"][0]     # scalar\n",
    "\n",
    "        slice_psnr = []\n",
    "        slice_ssim = []\n",
    "        slice_nmse = []\n",
    "\n",
    "        for i in range(0, SZF.shape[0], BATCH_SIZE):\n",
    "            SZF_batch = SZF[i:i+BATCH_SIZE]\n",
    "            SGT_batch = SGT[i:i+BATCH_SIZE]\n",
    "\n",
    "            SRE_batch = inference_step(\n",
    "                tf.convert_to_tensor(SZF_batch, tf.float32)\n",
    "            ).numpy()\n",
    "\n",
    "            # -------------------------\n",
    "            # Magnitude + denormalize\n",
    "            # -------------------------\n",
    "            gt_mag  = complex_to_mag_np(SGT_batch) * MAXV\n",
    "            rec_mag = complex_to_mag_np(SRE_batch) * MAXV\n",
    "\n",
    "            for b in range(gt_mag.shape[0]):\n",
    "                gt  = gt_mag[b]\n",
    "                rec = rec_mag[b]\n",
    "\n",
    "                # PSNR\n",
    "                slice_psnr.append(\n",
    "                    tf.image.psnr(\n",
    "                        gt[..., None], rec[..., None], max_val=MAXV\n",
    "                    ).numpy()\n",
    "                )\n",
    "\n",
    "                # SSIM (your implementation)\n",
    "                slice_ssim.append(\n",
    "                    compute_ssim(gt, rec, max_val=MAXV)\n",
    "                )\n",
    "\n",
    "                # NMSE (your implementation)\n",
    "                slice_nmse.append(\n",
    "                    nmse(gt, rec)\n",
    "                )\n",
    "\n",
    "        # -------------------------\n",
    "        # Per-volume aggregation\n",
    "        # -------------------------\n",
    "        vol_psnr.append(np.mean(slice_psnr))\n",
    "        vol_ssim.append(np.mean(slice_ssim))\n",
    "        vol_nmse.append(np.mean(slice_nmse))\n",
    "\n",
    "    return {\n",
    "        \"PSNR_mean\": float(np.mean(vol_psnr)),\n",
    "        \"PSNR_std\":  float(np.std(vol_psnr)),\n",
    "        \"SSIM_mean\": float(np.mean(vol_ssim)),\n",
    "        \"SSIM_std\":  float(np.std(vol_ssim)),\n",
    "        \"NMSE_mean\": float(np.mean(vol_nmse)),\n",
    "        \"NMSE_std\":  float(np.std(vol_nmse)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "330f7c44-2768-4da1-a689-0e50f7b8b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference (per-volume): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [02:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RSCA-GAN INFERENCE RESULTS (Per-Volume)\n",
      " PSNR : 33.09 ¬± 2.75\n",
      " SSIM : 0.7771 ¬± 0.0795\n",
      " NMSE : 0.040090 ¬± 0.016491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = run_inference(pdfs_files)\n",
    "\n",
    "print(\"\\nüìä RSCA-GAN INFERENCE RESULTS (Per-Volume)\")\n",
    "print(f\" PSNR : {results['PSNR_mean']:.2f} ¬± {results['PSNR_std']:.2f}\")\n",
    "print(f\" SSIM : {results['SSIM_mean']:.4f} ¬± {results['SSIM_std']:.4f}\")\n",
    "print(f\" NMSE : {results['NMSE_mean']:.6f} ¬± {results['NMSE_std']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbf7bb19-6c32-4ffb-aa84-b9d07fac2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded checkpoint: ./SavedModels_RSCA_GAN_full_2\\ckpt-14\n",
      "WARNING:tensorflow:From C:\\Users\\DU\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5250: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timing on /CPU:0:   1%|‚ñã                                                              | 2/199 [01:33<2:33:43, 46.82s/it]\n",
      "Timing on /GPU:0:   1%|‚ñã                                                                | 2/199 [00:04<06:41,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RSCA-GAN GENERATOR ‚Äî EFFICIENCY REPORT (BATCH SIZE = 1)\n",
      "======================================================================\n",
      "Parameters (Generator): 30.00 M\n",
      "FLOPs (per slice):      147.86 GFLOPs\n",
      "\n",
      "--- CPU Inference ---\n",
      "Latency:     0.94 s / slice\n",
      "Throughput:  1.069 slices/sec\n",
      "Memory:      246.88 MB\n",
      "\n",
      "--- GPU Inference ---\n",
      "GPU:         NVIDIA RTX A5000\n",
      "Latency:     0.04 s / slice\n",
      "Throughput:  27.816 slices/sec\n",
      "Peak VRAM:   235.01 MB\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import psutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras_flops import get_flops\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "VAL_FOLDER = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "CKPT_DIR   = r\"./SavedModels_RSCA_GAN_full_2\"   # üî¥ CHANGE THIS\n",
    "IMG_H, IMG_W = 320, 320                 # FastMRI resolution\n",
    "WARMUP_SLICES = 10\n",
    "NUM_TIMING_SLICES = 100                 # fixed slice budget\n",
    "\n",
    "# ============================================================\n",
    "# FILE LIST\n",
    "# ============================================================\n",
    "file_paths = sorted(glob.glob(os.path.join(VAL_FOLDER, \"*.h5\")))\n",
    "\n",
    "# ============================================================\n",
    "# LOAD RSCA-GAN MODEL\n",
    "# ============================================================\n",
    "model = RSCAGAN(in_channels=2, base_channels=32)\n",
    "generator = model.generator\n",
    "discriminator = model.discriminator  # required only for checkpoint restore\n",
    "\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator\n",
    ")\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt,\n",
    "    directory=CKPT_DIR,\n",
    "    max_to_keep=5\n",
    ")\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "    print(f\"‚úÖ Loaded checkpoint: {ckpt_manager.latest_checkpoint}\")\n",
    "else:\n",
    "    raise RuntimeError(\"‚ùå No checkpoint found\")\n",
    "\n",
    "# ============================================================\n",
    "# BUILD GENERATOR (REQUIRED FOR SUBCLASSED MODELS)\n",
    "# ============================================================\n",
    "dummy_input = tf.zeros((1, IMG_H, IMG_W, 2), dtype=tf.float32)\n",
    "_ = generator(dummy_input, training=False)\n",
    "\n",
    "# ============================================================\n",
    "# PARAMETER COUNT (GENERATOR ONLY)\n",
    "# ============================================================\n",
    "num_params = generator.count_params()\n",
    "\n",
    "# ============================================================\n",
    "# FLOPs (GENERATOR ONLY, PER SLICE)\n",
    "# Workaround for subclassed models\n",
    "# ============================================================\n",
    "def build_functional_generator(gen, input_shape):\n",
    "    inp = tf.keras.Input(shape=input_shape)\n",
    "    out = gen(inp, training=False)\n",
    "    return tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "gen_for_flops = build_functional_generator(\n",
    "    generator,\n",
    "    input_shape=(IMG_H, IMG_W, 2)\n",
    ")\n",
    "\n",
    "flops = get_flops(gen_for_flops, batch_size=1)\n",
    "\n",
    "# ============================================================\n",
    "# INFERENCE FUNCTION (DEPLOYMENT PATH)\n",
    "# ============================================================\n",
    "@tf.function\n",
    "def inference_step(x):\n",
    "    return generator(x, training=False)\n",
    "\n",
    "# ============================================================\n",
    "# MEMORY HELPERS\n",
    "# ============================================================\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "def cpu_memory_mb():\n",
    "    return process.memory_info().rss / (1024 ** 2)\n",
    "\n",
    "def gpu_memory_mb():\n",
    "    info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "    return info[\"peak\"] / (1024 ** 2)\n",
    "\n",
    "# ============================================================\n",
    "# LATENCY / THROUGHPUT MEASUREMENT\n",
    "# ============================================================\n",
    "def measure_latency(device):\n",
    "\n",
    "    latencies = []\n",
    "\n",
    "    with tf.device(device):\n",
    "\n",
    "        # -----------------------------\n",
    "        # WARM-UP\n",
    "        # -----------------------------\n",
    "        for file in file_paths[:1]:\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(min(WARMUP_SLICES, image_under.shape[0])):\n",
    "                x = tf.convert_to_tensor(image_under[s:s+1], tf.float32)\n",
    "                _ = inference_step(x)\n",
    "\n",
    "        # -----------------------------\n",
    "        # TIMED INFERENCE\n",
    "        # -----------------------------\n",
    "        count = 0\n",
    "        for file in tqdm(file_paths, desc=f\"Timing on {device}\", ncols=120):\n",
    "\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(image_under.shape[0]):\n",
    "\n",
    "                if count >= NUM_TIMING_SLICES:\n",
    "                    break\n",
    "\n",
    "                x = tf.convert_to_tensor(image_under[s:s+1], tf.float32)\n",
    "                assert x.shape[0] == 1\n",
    "\n",
    "                start = time.perf_counter()\n",
    "                _ = inference_step(x)\n",
    "\n",
    "                # üîë GPU synchronization\n",
    "                if \"GPU\" in device:\n",
    "                    tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "\n",
    "                end = time.perf_counter()\n",
    "\n",
    "                latencies.append(end - start)\n",
    "                count += 1\n",
    "\n",
    "            if count >= NUM_TIMING_SLICES:\n",
    "                break\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "    mean_s = latencies.mean()\n",
    "\n",
    "    return {\n",
    "        \"mean_s\": mean_s,\n",
    "        \"std_s\": latencies.std(),\n",
    "        \"slices_per_sec\": 1.0 / mean_s\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# CPU BENCHMARK\n",
    "# ============================================================\n",
    "cpu_mem_before = cpu_memory_mb()\n",
    "cpu_latency = measure_latency(\"/CPU:0\")\n",
    "cpu_mem_after = cpu_memory_mb()\n",
    "cpu_mem_peak = cpu_mem_after - cpu_mem_before\n",
    "\n",
    "# ============================================================\n",
    "# GPU BENCHMARK (IF AVAILABLE)\n",
    "# ============================================================\n",
    "gpu_latency = None\n",
    "gpu_mem_peak = None\n",
    "gpu_name = None\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    gpu_name = tf.config.experimental.get_device_details(gpus[0])[\"device_name\"]\n",
    "    gpu_latency = measure_latency(\"/GPU:0\")\n",
    "    gpu_mem_peak = gpu_memory_mb()\n",
    "\n",
    "# ============================================================\n",
    "# FINAL REPORT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RSCA-GAN GENERATOR ‚Äî EFFICIENCY REPORT (BATCH SIZE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Parameters (Generator): {num_params / 1e6:.2f} M\")\n",
    "print(f\"FLOPs (per slice):      {flops / 1e9:.2f} GFLOPs\")\n",
    "\n",
    "print(\"\\n--- CPU Inference ---\")\n",
    "print(f\"Latency:     {cpu_latency['mean_s']:.2f} s / slice\")\n",
    "print(f\"Throughput:  {cpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "print(f\"Memory:      {cpu_mem_peak:.2f} MB\")\n",
    "\n",
    "if gpu_latency:\n",
    "    print(\"\\n--- GPU Inference ---\")\n",
    "    print(f\"GPU:         {gpu_name}\")\n",
    "    print(f\"Latency:     {gpu_latency['mean_s']:.2f} s / slice\")\n",
    "    print(f\"Throughput:  {gpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "    print(f\"Peak VRAM:   {gpu_mem_peak:.2f} MB\")\n",
    "else:\n",
    "    print(\"\\nGPU not available.\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222a145-071b-44be-aeaa-3e7350a9062e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
