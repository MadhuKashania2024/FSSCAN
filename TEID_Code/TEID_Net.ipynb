{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff0ee3d-0e89-4d6f-9cd2-74672e207c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"C:\\Users\\DU\\aman_fastmri\\activation.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "445ca9d2-2e83-40fc-8a59-9a5c4e7a8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"C:\\Users\\DU\\aman_fastmri\\layer.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "491d3bd7-8256-4516-9810-e5e8f54682af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"C:\\Users\\DU\\aman_fastmri\\fft.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5df29e1-965d-4e49-9a30-e3e783772b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class TAM(Layer):\n",
    "    \"\"\"\n",
    "    Texture Attention Module (TAM)\n",
    "    Paper-faithful implementation for TEID-Net.\n",
    "\n",
    "    Complex representation:\n",
    "        Channels are concatenated:\n",
    "        - first C/2 : real\n",
    "        - last  C/2 : imaginary\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        assert channels % 4 == 0, \"Channels must be divisible by 4\"\n",
    "        self.channels = channels\n",
    "        self.half_channels = channels // 2\n",
    "\n",
    "        # Two sequential CConv3x3 + CLReLU\n",
    "        # NOTE: filters = channels (complex channels)\n",
    "        self.conv1 = complex_Conv2D(\n",
    "            filters=channels,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.conv2 = complex_Conv2D(\n",
    "            filters=channels,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "    def adaptive_avg_pool(self, x, target):\n",
    "        \"\"\"\n",
    "        Adaptive average pooling using resize.\n",
    "        Low-frequency branch is treated as a non-learnable statistic.\n",
    "        \"\"\"\n",
    "        h, w = tf.shape(x)[1], tf.shape(x)[2]\n",
    "    \n",
    "        # Low-pass filtering (NO gradients here)\n",
    "        x_low = tf.image.resize(x, (target, target), method=\"area\")\n",
    "        x_low = tf.stop_gradient(x_low)  # ðŸ”’ critical fix\n",
    "    \n",
    "        # Restore spatial resolution\n",
    "        x_low = tf.image.resize(x_low, (h, w), method=\"bilinear\")\n",
    "        return x_low\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, H, W, C)\n",
    "        \"\"\"\n",
    "        # ----------------------------------\n",
    "        # Split into real / imaginary\n",
    "        # ----------------------------------\n",
    "        real = x[..., :self.half_channels]     # (B,H,W,C/2)\n",
    "        imag = x[..., self.half_channels:]     # (B,H,W,C/2)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Split channels into 4 groups\n",
    "        # ----------------------------------\n",
    "        real_groups = tf.split(real, 4, axis=-1)\n",
    "        imag_groups = tf.split(imag, 4, axis=-1)\n",
    "\n",
    "        pool_sizes = [1, 2, 4, 8]\n",
    "        tex_real_groups = []\n",
    "        tex_imag_groups = []\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Multi-scale texture extraction\n",
    "        # ----------------------------------\n",
    "        for r, i, p in zip(real_groups, imag_groups, pool_sizes):\n",
    "            r_low = self.adaptive_avg_pool(r, p)\n",
    "            i_low = self.adaptive_avg_pool(i, p)\n",
    "\n",
    "            tex_real_groups.append(r - r_low)\n",
    "            tex_imag_groups.append(i - i_low)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Concatenate texture features\n",
    "        # ----------------------------------\n",
    "        tex_real = tf.concat(tex_real_groups, axis=-1)  # (B,H,W,C/2)\n",
    "        tex_imag = tf.concat(tex_imag_groups, axis=-1)  # (B,H,W,C/2)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Texture filtering (CCB part)\n",
    "        # ----------------------------------\n",
    "        tex_real, tex_imag = self.conv1(tex_real, tex_imag)\n",
    "        tex_real, tex_imag = CLeaky_ReLU(tex_real, tex_imag)\n",
    "\n",
    "        tex_real, tex_imag = self.conv2(tex_real, tex_imag)\n",
    "        tex_real, tex_imag = CLeaky_ReLU(tex_real, tex_imag)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Texture attention map\n",
    "        # ----------------------------------\n",
    "        attn_real = tf.sigmoid(tex_real)\n",
    "        attn_imag = tf.sigmoid(tex_imag)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Residual texture attention\n",
    "        # F_out = F_in + F_in âŠ— M_t\n",
    "        # ----------------------------------\n",
    "        out_real = real + real * attn_real\n",
    "        out_imag = imag + imag * attn_imag\n",
    "\n",
    "        # ----------------------------------\n",
    "        # Re-concatenate real & imag\n",
    "        # ----------------------------------\n",
    "        return tf.concat([out_real, out_imag], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8ea3a37-56e8-4a85-ad1b-db80ffe54f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class TEM(Layer):\n",
    "    \"\"\"\n",
    "    Texture Enhancement Module (TEM)\n",
    "    Section 2.2.1, Fig. 1(d) of TEID-Net.\n",
    "\n",
    "    Input / Output:\n",
    "        (B, H, W, C)\n",
    "    Complex representation:\n",
    "        first C/2 channels  -> real\n",
    "        last  C/2 channels  -> imaginary\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        # Texture Attention Module\n",
    "        self.tam = TAM(channels)\n",
    "\n",
    "        # Complex Convolutional Block (CCB)\n",
    "        self.conv1 = complex_Conv2D(\n",
    "            filters=channels,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.conv2 = complex_Conv2D(\n",
    "            filters=channels,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.conv3 = complex_Conv2D(\n",
    "            filters=channels,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, H, W, C)\n",
    "        \"\"\"\n",
    "        # -----------------------------\n",
    "        # Texture attention\n",
    "        # -----------------------------\n",
    "        x_t = self.tam(x)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Split real / imag\n",
    "        # -----------------------------\n",
    "        C = self.channels // 2\n",
    "        real = x_t[..., :C]\n",
    "        imag = x_t[..., C:]\n",
    "\n",
    "        # -----------------------------\n",
    "        # Complex Convolutional Block\n",
    "        # -----------------------------\n",
    "        real, imag = self.conv1(real, imag)\n",
    "        real, imag = CLeaky_ReLU(real, imag)\n",
    "\n",
    "        real, imag = self.conv2(real, imag)\n",
    "        real, imag = CLeaky_ReLU(real, imag)\n",
    "\n",
    "        real, imag = self.conv3(real, imag)\n",
    "        real, imag = CLeaky_ReLU(real, imag)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Re-concatenate\n",
    "        # -----------------------------\n",
    "        return tf.concat([real, imag], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a446382a-5f2c-48db-92ad-7bbf38f4b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class TENet(Layer):\n",
    "    \"\"\"\n",
    "    Texture Enhancement Network (TE-Net)\n",
    "    Paper-faithful implementation using:\n",
    "    - fft2c_tf / ifft2c_tf\n",
    "    - channel-wise complex representation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Feature lifting: 1 complex â†’ 32 complex\n",
    "        self.conv_in = complex_Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=1,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "\n",
    "        # Three residual TEM blocks\n",
    "        self.tem1 = TEM(channels=32)\n",
    "        self.tem2 = TEM(channels=32)\n",
    "        self.tem3 = TEM(channels=32)\n",
    "\n",
    "        # Feature fusion\n",
    "        self.fuse_conv = complex_Conv2D(\n",
    "            filters=2,\n",
    "            kernel_size=1,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "\n",
    "        self.out_conv = complex_Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=1,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "\n",
    "    def call(self, kspace):\n",
    "        \"\"\"\n",
    "        kspace: (B, H, W, 2)  # real, imag\n",
    "        returns: (B, H, W, 64)  # 32 complex channels\n",
    "        \"\"\"\n",
    "\n",
    "        # ----------------------------------\n",
    "        # 1) k-space â†’ image domain\n",
    "        # ----------------------------------\n",
    "        x = ifft2c_tf(kspace)          # (B,H,W,2)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # 2) Initial CConv1Ã—1 (1 â†’ 32 complex)\n",
    "        # ----------------------------------\n",
    "        real = x[..., 0:1]\n",
    "        imag = x[..., 1:2]\n",
    "\n",
    "        real, imag = self.conv_in(real, imag)\n",
    "        real, imag = CLeaky_ReLU(real, imag)\n",
    "\n",
    "        x = tf.concat([real, imag], axis=-1)  # (B,H,W,64)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # 3) Residual TEMs\n",
    "        # ----------------------------------\n",
    "        t1 = self.tem1(x)\n",
    "        x1 = x + t1\n",
    "\n",
    "        t2 = self.tem2(x1)\n",
    "        x2 = x1 + t2\n",
    "\n",
    "        t3 = self.tem3(x2)\n",
    "        x3 = x2 + t3\n",
    "\n",
    "        # ----------------------------------\n",
    "        # 4) Concatenate TEM outputs\n",
    "        # ----------------------------------\n",
    "        x_cat = tf.concat([t1, t2, t3], axis=-1)  # (B,H,W,192)\n",
    "        #print(\"x_cat\",x_cat.shape)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # 5) Feature fusion\n",
    "        # ----------------------------------\n",
    "        C = x_cat.shape[-1] // 2\n",
    "        #print(\"C\",C)\n",
    "        real = x_cat[..., :C]\n",
    "        imag = x_cat[..., C:]\n",
    "\n",
    "        real, imag = self.fuse_conv(real, imag)\n",
    "        real, imag = CLeaky_ReLU(real, imag)\n",
    "\n",
    "        # real, imag = self.out_conv(real, imag)\n",
    "        # real, imag = CLeaky_ReLU(real, imag)\n",
    "\n",
    "        return tf.concat([real, imag], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cab5f9a-1944-4620-b393-4f5222db8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifft1d_H_tf(x):\n",
    "    \"\"\"\n",
    "    1-D IFFT along H (axis=-3)\n",
    "    x : (B, H, W, 2)\n",
    "    \"\"\"\n",
    "    # move H to last spatial axis\n",
    "    x_perm = tf.transpose(x, [0, 2, 1, 3])   # (B, W, H, 2)\n",
    "    x_ifft = ifft2c_tf(x_perm)               # uses your verified impl\n",
    "    return tf.transpose(x_ifft, [0, 2, 1, 3])\n",
    "def ifft1d_W_tf(x):\n",
    "    \"\"\"\n",
    "    1-D IFFT along W (axis=-2)\n",
    "    x : (B, H, W, 2)\n",
    "    \"\"\"\n",
    "    return ifft2c_tf(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ed553f9-3056-4d6a-bd4b-0e09b81aede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDM(tf.keras.layers.Layer):\n",
    "    def __init__(self, channels=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1Ã—1 expansion\n",
    "        self.expand = complex_Conv2D(channels, kernel_size=1, padding=\"same\")\n",
    "\n",
    "        # 1-D global convolutions (via transpose)\n",
    "        self.conv1 = complex_Conv2D(320*2, kernel_size=1, padding=\"same\")\n",
    "        self.conv2 = complex_Conv2D(320*2, kernel_size=1, padding=\"same\")\n",
    "\n",
    "        # 3Ã—3 complex convolutions after residual fusion\n",
    "        self.conv3 = complex_Conv2D(32, kernel_size=3, padding=\"same\")\n",
    "        self.conv4 = complex_Conv2D(32, kernel_size=3, padding=\"same\")\n",
    "\n",
    "        # Final channel fusion\n",
    "        self.fuse = complex_Conv2D(2, kernel_size=1, padding=\"same\")\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x : (B, H, W, 2)   # 1 complex channel (real, imag)\n",
    "        \n",
    "        \"\"\"\n",
    "        #print(\"Input after IDIFT height\",x.shape)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Split real / imag (MANDATORY)\n",
    "        # --------------------------------------------------\n",
    "        input_real = x[..., 0:1]\n",
    "        input_imag = x[..., 1:2]\n",
    "        #print(\"input_real\",input_real.shape,\"input_imag\",input_imag.shape)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # (1) Channel expansion (z1)\n",
    "        # --------------------------------------------------\n",
    "        real1_conv1, imag1_conv1 = self.expand(input_real, input_imag)\n",
    "        real1_conv1, imag1_conv1 = CLeaky_ReLU(real1_conv1, imag1_conv1)\n",
    "        #print(\"Output after 1st conv1*1 real1_conv1\",real1_conv1.shape,\"imag1_conv1\",imag1_conv1.shape)\n",
    "        \n",
    "        # z1 : (B, H, W, C)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # (2) Transpose â†’ 1-D global convolution\n",
    "        # --------------------------------------------------\n",
    "        real_t = tf.transpose(real1_conv1, [0, 1, 3, 2])   # (B,H,C,W)\n",
    "        imag_t = tf.transpose(imag1_conv1, [0, 1, 3, 2])\n",
    "        #print(\"After ist transpose real_t\",real_t.shape,\"imag_t\",imag_t.shape)\n",
    "        \n",
    "        # --------------------------------------------------\n",
    "        # (3) Two complex convs + CLReLU (z2)\n",
    "        # --------------------------------------------------\n",
    "        real2, imag2 = self.conv1(real_t, imag_t)\n",
    "        real2, imag2 = CLeaky_ReLU(real2, imag2)\n",
    "        # print(\"real2\",real2.shape)\n",
    "        # print(\"imag2\",imag2.shape)\n",
    "\n",
    "        real2, imag2 = self.conv2(real2, imag2)\n",
    "        real2_conv2, imag2_conv2 = CLeaky_ReLU(real2, imag2)\n",
    "        #print(\"After 2 intermediate 1*1 conv ::real2\",real2_conv2.shape,\"imag2\",imag2_conv2.shape)\n",
    "        \n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # (4) Transpose back\n",
    "        # --------------------------------------------------\n",
    "        real_trans2 = tf.transpose(real2_conv2, [0, 1, 3, 2])    # (B,H,W,C)\n",
    "        imag2_trans2  = tf.transpose(imag2_conv2, [0, 1, 3, 2])\n",
    "        #print(\"After 2nd transpose::Real \",real_trans2.shape,\"imag\",imag2_trans2.shape)\n",
    "        \n",
    "        \n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # (5) Residual fusion (z1 + z2)\n",
    "        # --------------------------------------------------\n",
    "        real_res_fusion = real1_conv1 + real_trans2\n",
    "        imag_res_fusion = imag1_conv1 + imag2_trans2\n",
    "        #print(\"After residual fusion::Real \",real_res_fusion.shape,\"imag\",imag_res_fusion.shape)\n",
    "        # --------------------------------------------------\n",
    "        # (6) Two 3Ã—3 complex convolutions + CLReLU\n",
    "        # --------------------------------------------------\n",
    "        real, imag = self.conv3(real_res_fusion, imag_res_fusion)\n",
    "        real, imag = CLeaky_ReLU(real, imag)\n",
    "\n",
    "        real, imag = self.conv4(real, imag)\n",
    "        real_conv3, imag_conv3 = CLeaky_ReLU(real, imag)\n",
    "        #print(\"After 2 3*3 conv ::Real \",real_conv3.shape,\"imag\",imag_conv3.shape)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # (7) Final 1Ã—1 fusion â†’ 1 complex channel\n",
    "        # --------------------------------------------------\n",
    "        real, imag = self.fuse(real_conv3, imag_conv3)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Output as (real, imag)\n",
    "        # --------------------------------------------------\n",
    "        return tf.concat([real, imag], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9cb733e-e517-4021-a3bc-27e0a38295ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDNet(tf.keras.Model):\n",
    "    def __init__(self, channels=64):\n",
    "        super().__init__()\n",
    "        self.idm = IDM(channels)\n",
    "\n",
    "    def call(self, x_u):\n",
    "        \"\"\"\n",
    "        x_u : (B,H,W,2) undersampled k-space\n",
    "        \"\"\"\n",
    "\n",
    "        # 1-D IFT along H (frequency-encoding direction)\n",
    "        #print(\"x_u\",x_u.shape)\n",
    "        z_Hu = ifft1d_H_tf(x_u)\n",
    "        #print(\"z_Hu\",z_Hu.shape)\n",
    "\n",
    "        # Intermediate-domain recovery\n",
    "        z_H = self.idm(z_Hu)\n",
    "        ##print(\"z_H\",z_H.shape)\n",
    "        # 1-D IFT along W (phase-encoding direction)\n",
    "        y_hat = ifft1d_W_tf(z_H)\n",
    "        #print(\"y_hat\",y_hat.shape)\n",
    "\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a33f6ed7-c11c-4960-bdd4-58a9ff99a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, channels=32):\n",
    "        super().__init__()\n",
    "\n",
    "        assert channels % 4 == 0, \"Channels must be divisible by 4\"\n",
    "        self.channels = channels\n",
    "        self.group_channels = channels // 4\n",
    "\n",
    "        # Channel alignment\n",
    "        self.align_te = complex_Conv2D(channels, kernel_size=1, padding=\"same\")\n",
    "        self.align_id = complex_Conv2D(channels, kernel_size=1, padding=\"same\")\n",
    "\n",
    "        # Dilated convolutions for 4 scales\n",
    "        self.dilated_convs = []\n",
    "        for rate in [1, 2, 3, 4]:\n",
    "            self.dilated_convs.append(\n",
    "                complex_Conv2D(\n",
    "                    self.group_channels,\n",
    "                    kernel_size=3,\n",
    "                    padding=\"same\",\n",
    "                    dilation_rate=rate\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Final fusion\n",
    "        self.fuse = complex_Conv2D(2, kernel_size=1, padding=\"same\")\n",
    "\n",
    "    def call(self, x_te, x_id):\n",
    "        \"\"\"\n",
    "        x_te, x_id : (B, H, W, 2C)  packed complex\n",
    "        returns    : (B, H, W, 2C)\n",
    "        \"\"\"\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Split real / imag ONCE\n",
    "        # --------------------------------------------------\n",
    "        te_r = x_te[..., 0:1]\n",
    "        te_i = x_te[..., 1:2]\n",
    "        \n",
    "        id_r = x_id[..., 0:1]\n",
    "        id_i = x_id[..., 1:2]\n",
    "\n",
    "        # te_r = x_te[..., :self.channels]\n",
    "        # te_i = x_te[..., self.channels:]\n",
    "\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 1Ã—1 channel alignment\n",
    "        # --------------------------------------------------\n",
    "        te_r, te_i = self.align_te(te_r, te_i)\n",
    "        id_r, id_i = self.align_id(id_r, id_i)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Split into 4 channel groups\n",
    "        # --------------------------------------------------\n",
    "        te_r_groups = tf.split(te_r, 4, axis=-1)\n",
    "        te_i_groups = tf.split(te_i, 4, axis=-1)\n",
    "        id_r_groups = tf.split(id_r, 4, axis=-1)\n",
    "        id_i_groups = tf.split(id_i, 4, axis=-1)\n",
    "\n",
    "        fused_r = []\n",
    "        fused_i = []\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Cross-fusion + multi-scale dilated conv\n",
    "        # --------------------------------------------------\n",
    "        for k in range(4):\n",
    "            r = tf.concat([te_r_groups[k], id_r_groups[k]], axis=-1)\n",
    "            i = tf.concat([te_i_groups[k], id_i_groups[k]], axis=-1)\n",
    "\n",
    "            r, i = self.dilated_convs[k](r, i)\n",
    "            r, i = CLeaky_ReLU(r, i)\n",
    "\n",
    "            fused_r.append(r)\n",
    "            fused_i.append(i)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Concatenate all scales\n",
    "        # --------------------------------------------------\n",
    "        r = tf.concat(fused_r, axis=-1)\n",
    "        i = tf.concat(fused_i, axis=-1)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Final 1Ã—1 fusion (NO activation here)\n",
    "        # --------------------------------------------------\n",
    "        r, i = self.fuse(r, i)\n",
    "\n",
    "        return tf.concat([r, i], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21a43cdf-9ce1-4810-b248-fd84ab6d9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataConsistency(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Soft data consistency layer for single-coil MRI\n",
    "    with 1D Cartesian sampling mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, init_lambda=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Learnable balance parameter (Î» > 0)\n",
    "        self.lambda_dc = tf.Variable(\n",
    "            initial_value=init_lambda,\n",
    "            trainable=True,\n",
    "            dtype=tf.float32,\n",
    "            name=\"lambda_dc\"\n",
    "        )\n",
    "\n",
    "    def call(self, x_img, k_us, mask):\n",
    "        \"\"\"\n",
    "        x_img : (B, H, W, 2)  image-domain prediction\n",
    "        k_us  : (B, H, W, 2)  undersampled k-space\n",
    "        mask  : (1, 1, W, 1)  1D Cartesian sampling mask\n",
    "        \"\"\"\n",
    "\n",
    "        # Image â†’ k-space\n",
    "        k_pred = fft2c_tf(x_img)   # (B,H,W,2)\n",
    "\n",
    "        # Ensure type consistency\n",
    "        mask = tf.cast(mask, k_pred.dtype)\n",
    "        lam  = tf.cast(self.lambda_dc, k_pred.dtype)\n",
    "\n",
    "        # Soft data consistency\n",
    "        k_dc = (\n",
    "            (1.0 - mask) * k_pred +\n",
    "            mask * (k_us + lam * k_pred) / (1.0 + lam)\n",
    "        )\n",
    "\n",
    "\n",
    "        return k_dc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e7a01c-d8a6-4e9b-911e-31760341b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEIDBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    One TEID block:\n",
    "    k-space -> TE/ID internal processing -> fusion -> DC -> k-space\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.te_net = TENet()\n",
    "        self.id_net = IDNet(channels=channels)\n",
    "        self.fm     = FusionModule(channels=channels)\n",
    "        self.dc     = DataConsistency()\n",
    "\n",
    "    def call(self, k_in, k_us, mask):\n",
    "        \"\"\"\n",
    "        k_in : (B, H, W, 2)  k-space from previous cascade\n",
    "        k_us : (B, H, W, 2)  zero-filled undersampled k-space (K^0)\n",
    "        mask : (1, 1, W, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # TE-Net and ID-Net both take k-space as input\n",
    "        x_te = self.te_net(k_in)   # image-domain output\n",
    "        x_id = self.id_net(k_in)   # image-domain output\n",
    "\n",
    "        # Fusion in image domain\n",
    "        x_fused = self.fm(x_te, x_id)\n",
    "\n",
    "        # Data consistency (returns k-space)\n",
    "        k_out = self.dc(x_fused, k_us, mask)\n",
    "\n",
    "        return k_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcd45ce0-ff73-4380-ab62-ee76aadbeabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadedTEIDNet(tf.keras.Model):\n",
    "    def __init__(self, num_cascades=5, channels=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = [\n",
    "            TEIDBlock(channels=channels)\n",
    "            for _ in range(num_cascades)\n",
    "        ]\n",
    "\n",
    "    def call(self, k_us, mask):\n",
    "        \"\"\"\n",
    "        k_us : (B, H, W, 2) undersampled k-space\n",
    "        mask : (1, 1, W, 1)\n",
    "        \"\"\"\n",
    "        #print(\"mask\",mask.shape)\n",
    "\n",
    "        k = k_us  # K^(0)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            k = block(k, k_us, mask)\n",
    "\n",
    "        # Final reconstruction (only once)\n",
    "        x_rec = ifft2c_tf(k)\n",
    "\n",
    "        return x_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e374971-8880-4fa1-8ef1-4291f331096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_cascaded_teid_model(\n",
    "    H=320,\n",
    "    W=320,\n",
    "    num_cascades=5,\n",
    "    channels=64\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds a Keras Model wrapper for CascadedTEIDNet\n",
    "    so it plugs directly into the existing data pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inputs\n",
    "    k_us = Input(shape=(H, W, 2), name=\"kspace_undersampled\")\n",
    "    mask = Input(shape=(1, W, 1), name=\"sampling_mask\")\n",
    "\n",
    "    # Core model\n",
    "    teid_net = CascadedTEIDNet(\n",
    "        num_cascades=num_cascades,\n",
    "        channels=channels\n",
    "    )\n",
    "\n",
    "    # Forward pass\n",
    "    x_rec = teid_net(k_us, mask)\n",
    "\n",
    "    # Optional identity layer (for loss dict / naming consistency)\n",
    "    x_rec = Lambda(lambda x: x, name=\"reconstructed_image\")(x_rec)\n",
    "\n",
    "    # Final wrapped model\n",
    "    model = Model(\n",
    "        inputs=[k_us, mask],\n",
    "        outputs=x_rec,\n",
    "        name=\"CascadedTEIDNet_Model\"\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aae97d29-2dcc-4ad2-8ad2-f0c3928e5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask (None, 1, 320, 1)\n",
      "x_u (None, 320, 320, 2)\n",
      "z_Hu (None, 320, 320, 2)\n",
      "Input after IDIFT height (None, 320, 320, 2)\n",
      "input_real (None, 320, 320, 1) input_imag (None, 320, 320, 1)\n",
      "Output after 1st conv1*1 real1_conv1 (None, 320, 320, 32) imag1_conv1 (None, 320, 320, 32)\n",
      "After ist transpose real_t (None, 320, 32, 320) imag_t (None, 320, 32, 320)\n",
      "After 2 intermediate 1*1 conv ::real2 (None, 320, 32, 320) imag2 (None, 320, 32, 320)\n",
      "After 2nd transpose::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After residual fusion::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After 2 3*3 conv ::Real  (None, 320, 320, 16) imag (None, 320, 320, 16)\n",
      "z_H (None, 320, 320, 2)\n",
      "y_hat (None, 320, 320, 2)\n",
      "x_u (None, 320, 320, 2)\n",
      "z_Hu (None, 320, 320, 2)\n",
      "Input after IDIFT height (None, 320, 320, 2)\n",
      "input_real (None, 320, 320, 1) input_imag (None, 320, 320, 1)\n",
      "Output after 1st conv1*1 real1_conv1 (None, 320, 320, 32) imag1_conv1 (None, 320, 320, 32)\n",
      "After ist transpose real_t (None, 320, 32, 320) imag_t (None, 320, 32, 320)\n",
      "After 2 intermediate 1*1 conv ::real2 (None, 320, 32, 320) imag2 (None, 320, 32, 320)\n",
      "After 2nd transpose::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After residual fusion::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After 2 3*3 conv ::Real  (None, 320, 320, 16) imag (None, 320, 320, 16)\n",
      "z_H (None, 320, 320, 2)\n",
      "y_hat (None, 320, 320, 2)\n",
      "x_u (None, 320, 320, 2)\n",
      "z_Hu (None, 320, 320, 2)\n",
      "Input after IDIFT height (None, 320, 320, 2)\n",
      "input_real (None, 320, 320, 1) input_imag (None, 320, 320, 1)\n",
      "Output after 1st conv1*1 real1_conv1 (None, 320, 320, 32) imag1_conv1 (None, 320, 320, 32)\n",
      "After ist transpose real_t (None, 320, 32, 320) imag_t (None, 320, 32, 320)\n",
      "After 2 intermediate 1*1 conv ::real2 (None, 320, 32, 320) imag2 (None, 320, 32, 320)\n",
      "After 2nd transpose::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After residual fusion::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After 2 3*3 conv ::Real  (None, 320, 320, 16) imag (None, 320, 320, 16)\n",
      "z_H (None, 320, 320, 2)\n",
      "y_hat (None, 320, 320, 2)\n",
      "x_u (None, 320, 320, 2)\n",
      "z_Hu (None, 320, 320, 2)\n",
      "Input after IDIFT height (None, 320, 320, 2)\n",
      "input_real (None, 320, 320, 1) input_imag (None, 320, 320, 1)\n",
      "Output after 1st conv1*1 real1_conv1 (None, 320, 320, 32) imag1_conv1 (None, 320, 320, 32)\n",
      "After ist transpose real_t (None, 320, 32, 320) imag_t (None, 320, 32, 320)\n",
      "After 2 intermediate 1*1 conv ::real2 (None, 320, 32, 320) imag2 (None, 320, 32, 320)\n",
      "After 2nd transpose::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After residual fusion::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After 2 3*3 conv ::Real  (None, 320, 320, 16) imag (None, 320, 320, 16)\n",
      "z_H (None, 320, 320, 2)\n",
      "y_hat (None, 320, 320, 2)\n",
      "x_u (None, 320, 320, 2)\n",
      "z_Hu (None, 320, 320, 2)\n",
      "Input after IDIFT height (None, 320, 320, 2)\n",
      "input_real (None, 320, 320, 1) input_imag (None, 320, 320, 1)\n",
      "Output after 1st conv1*1 real1_conv1 (None, 320, 320, 32) imag1_conv1 (None, 320, 320, 32)\n",
      "After ist transpose real_t (None, 320, 32, 320) imag_t (None, 320, 32, 320)\n",
      "After 2 intermediate 1*1 conv ::real2 (None, 320, 32, 320) imag2 (None, 320, 32, 320)\n",
      "After 2nd transpose::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After residual fusion::Real  (None, 320, 320, 32) imag (None, 320, 320, 32)\n",
      "After 2 3*3 conv ::Real  (None, 320, 320, 16) imag (None, 320, 320, 16)\n",
      "z_H (None, 320, 320, 2)\n",
      "y_hat (None, 320, 320, 2)\n",
      "Model: \"CascadedTEIDNet_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " kspace_undersampled (InputLaye  [(None, 320, 320, 2  0          []                               \n",
      " r)                             )]                                                                \n",
      "                                                                                                  \n",
      " sampling_mask (InputLayer)     [(None, 1, 320, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " cascaded_teid_net_3 (CascadedT  (None, 320, 320, 2)  2521475    ['kspace_undersampled[0][0]',    \n",
      " EIDNet)                                                          'sampling_mask[0][0]']          \n",
      "                                                                                                  \n",
      " reconstructed_image (Lambda)   (None, 320, 320, 2)  0           ['cascaded_teid_net_3[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,521,475\n",
      "Trainable params: 2,521,475\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_cascaded_teid_model(\n",
    "    H=320,\n",
    "    W=320,\n",
    "    num_cascades=5,\n",
    "    channels=64\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b0e79-8450-4379-834c-8f4eceb7391f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
