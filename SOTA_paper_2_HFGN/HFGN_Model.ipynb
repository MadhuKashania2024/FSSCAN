{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b58b704-12cb-4300-b219-18f8cc180331",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ComplexCNN_torch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a4b9c3-3efb-436d-8073-0185c4dbd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658bd1fb-2be0-480f-812a-21c987b1b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run fftc_torch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50864210-a94d-4819-9496-99722ffa1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898e6354-060b-4ac1-8880-74b0615f6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def DC(img, kspace, mask):\n",
    "    # #mask batch, 1, 320, 1;mask为1表示gt代替，为0使用预测值\n",
    "    # print(\"img inside dc\",img.shape)\n",
    "    # print(\"kspace inside dc\",kspace.shape)\n",
    "    # print(\"mask inside dc\",mask.shape)\n",
    "    \n",
    "    img = img.squeeze(1)\n",
    "    kspace = kspace.squeeze(1) \n",
    "    mask = mask.squeeze(1) \n",
    "    \n",
    "    pre_kspace = fft2c_new(img)\n",
    "    # print(\"img inside dc\",img.shape)\n",
    "    # print(\"kspace inside dc\",kspace.shape)\n",
    "    # print(\"pre_kspace inside dc\",pre_kspace.shape)\n",
    "    # print(\"mask inside dc\",mask.shape)\n",
    "\n",
    "    ans_kspace = kspace * mask + pre_kspace *(1 - mask)\n",
    "    #print(\"ans_kspace inside dc\",ans_kspace.shape)\n",
    "    return ifft2c_new(ans_kspace)\n",
    "\n",
    "\n",
    "## Channel Attention (CA) Layer\n",
    "class CALayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(CALayer, self).__init__()\n",
    "        # global average pooling: feature --> point\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # feature channel downscale and upscale --> channel weight\n",
    "        self.conv_du = nn.Sequential(\n",
    "                nn.Linear(channel, channel // reduction, bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(channel // reduction, channel, bias=False),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        # self.conv = ComplexConv(2 * channel, channel, kernel_size=3, padding=1,act='bn')\n",
    "\n",
    "    def forward(self, x):\n",
    "        b,c,h,w,d = x.size()\n",
    "        x_abs =  (x ** 2).sum(dim=-1)\n",
    "        y = self.avg_pool(x_abs).view(b,c)\n",
    "        y = self.conv_du(y).view(b,c,1,1)\n",
    "        y = y.unsqueeze(-1)\n",
    "        tmp = x * y\n",
    "        return tmp\n",
    "\n",
    "\n",
    "## spatial Attention (SA) Layer\n",
    "class SALayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=2):\n",
    "        super(SALayer, self).__init__()\n",
    "        self.conv =  nn.Sequential(\n",
    "            nn.Conv2d(2, 1, 3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, error):\n",
    "        b,c,h,w,d = x.size()\n",
    "        x_abs =  (error ** 2).sum(dim=-1)\n",
    "        avgout = torch.mean(x_abs, dim=1, keepdim=True)\n",
    "        maxout, _ = torch.max(x_abs, dim=1, keepdim=True)\n",
    "        y = torch.cat([avgout, maxout], dim=1)\n",
    "        # print(x.shape, y.shape)\n",
    "        y = self.conv(y)\n",
    "        y = y.unsqueeze(-1)\n",
    "        tmp = x * y\n",
    "        return tmp\n",
    "\n",
    "## Residual Channel Attention Block (RCAB)\n",
    "class RCAB(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_feat=64, kernel_size=3, reduction=4,flag = 'HF'):\n",
    "    \n",
    "        super(RCAB, self).__init__()\n",
    "        self.flag = flag\n",
    "        self.conv1 = ComplexConv(num_feat, num_feat, kernel_size=kernel_size, padding=1)\n",
    "        self.conv2 = ComplexConv(num_feat, num_feat, kernel_size=kernel_size, padding=1, act=None)\n",
    "        self.conv1_k = ComplexConv(num_feat, num_feat, kernel_size=1, padding=0)\n",
    "        self.conv2_k = ComplexConv(num_feat, num_feat, kernel_size=1, padding=0, act=None)\n",
    "        modules_body = []\n",
    "        modules_body.append(self.conv1)\n",
    "        modules_body.append(self.conv2)\n",
    "        modules_body.append(CALayer(num_feat, reduction))\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "        if self.flag != 'HF':\n",
    "            self.sa = SALayer(num_feat)\n",
    "            self.sa_k = SALayer(num_feat)\n",
    "        modules_body_k = []\n",
    "        modules_body_k.append(self.conv1_k)\n",
    "        modules_body_k.append(self.conv2_k)\n",
    "        modules_body_k.append(CALayer(num_feat, reduction))\n",
    "        self.body_k = nn.Sequential(*modules_body_k)\n",
    "        \n",
    "\n",
    "    def forward(self, x, error=None):\n",
    "        x_k = fft2c_new(x)\n",
    "        res_k = self.body_k(x_k)\n",
    "        res = self.body(x)\n",
    "        if self.flag != 'HF':\n",
    "            error_k = fft2c_new(error)\n",
    "            res_k = self.sa_k(res_k, error_k)\n",
    "            res = self.sa(res, error)\n",
    "        return res + x + ifft2c_new(res_k)\n",
    "        \n",
    "\n",
    "\n",
    "class FGNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_c = 1, out_c = 1, num_feat=64, kernel_size=3, reduction=4,\n",
    "        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
    "        super(FGNet, self).__init__()\n",
    "        self.feature_ext = nn.Sequential(\n",
    "            ComplexConv(in_c * 2, num_feat // 2, kernel_size = 3, stride=1, padding = 1),\n",
    "            ComplexConv(num_feat // 2, num_feat, kernel_size = 3, stride=1, padding = 1)\n",
    "        )\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            ComplexConv(num_feat, num_feat // 2, kernel_size = 3, stride=1, padding = 1),\n",
    "            ComplexConv(num_feat // 2, 1, kernel_size = 3, stride=1, padding = 1)\n",
    "        )\n",
    "        self.b1 = RCAB(flag='Recon')\n",
    "        self.b2 = RCAB(flag='Recon')\n",
    "        self.b3 = RCAB(flag='Recon')\n",
    "        self.b4 = RCAB(flag='Recon')\n",
    "\n",
    "        self.HF = nn.Sequential(\n",
    "            ComplexConv(in_c, num_feat // 2, kernel_size = 3, stride=1, padding = 1),\n",
    "            ComplexConv(num_feat // 2, num_feat, kernel_size = 3, stride=1, padding = 1),\n",
    "            RCAB(flag='HF'),\n",
    "            RCAB(flag='HF')\n",
    "        )\n",
    "        self.afterHF = nn.Sequential(\n",
    "            ComplexConv(num_feat, num_feat // 2, kernel_size = 3, stride=1, padding = 1),\n",
    "            ComplexConv(num_feat // 2, 1, kernel_size = 3, stride=1, padding = 1)\n",
    "        )\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, k, mask):\n",
    "        # x = torch.cat([x, error], dim=1)\n",
    "        x_HF = self.HF(x)\n",
    "        out1 = self.afterHF(x_HF)\n",
    "        # print(tmp.shape)\n",
    "        x0 = self.feature_ext(torch.cat([x, out1], dim=1))\n",
    "        x0 += x_HF\n",
    "        out1_s = self.sig(out1)\n",
    "        x1 = x0 + self.b1(x0,out1_s)\n",
    "        x2 = x1 + self.b2(x1,out1_s)\n",
    "        x3 = x2 + self.b3(x2,out1_s)\n",
    "        x4 = x3 + self.b4(x3,out1_s)\n",
    "        output = self.last(x4)\n",
    "        out=DC(output, k, mask)\n",
    "        return out, out1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9adb3-7767-42c3-97a7-016d2d41a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     model = FGNet(in_c=1, out_c=1)\n",
    "#     num_params = sum(param.nelement() for param in model.parameters())\n",
    "#     print(num_params / 1e6)\n",
    "#     x = torch.rand((2,1,256,256,2))\n",
    "#     k = torch.rand((2,1,256,256,2))\n",
    "#     error = torch.rand((2,1,256,256,2))\n",
    "#     mask = torch.rand((2,1,256,1))\n",
    "#     [out,out1] = model(x, k, mask)\n",
    "#     print(\"out\",out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
