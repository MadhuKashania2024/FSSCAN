{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0283c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b51482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae354cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_complex(x):\n",
    "    \"\"\"(H,W,2) → complex\"\"\"\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def complex_abs(x):\n",
    "    \"\"\"torch complex magnitude, x: (...,2)\"\"\"\n",
    "    return torch.sqrt(x[..., 0]**2 + x[..., 1]**2)\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + 1e-10)\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf1b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_PATH = \"./mask_4x_320_random.npy\"\n",
    "mask = np.load(MASK_PATH)           # (1,1,H,1)\n",
    "mask_t = torch.from_numpy(mask).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70df4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run HFGN_Model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a86cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ FGNet weights loaded\n"
     ]
    }
   ],
   "source": [
    "model = FGNet().to(DEVICE)\n",
    "\n",
    "ckpt = torch.load(\"fgnet_best.pth\")\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "model.eval()\n",
    "print(\"✔ FGNet weights loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9400e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of volumes: 199\n"
     ]
    }
   ],
   "source": [
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "file_paths = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "\n",
    "print(\"Number of volumes:\", len(file_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01824a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD volumes: 100\n",
      "PDFS volumes: 99\n"
     ]
    }
   ],
   "source": [
    "pd_files = []\n",
    "pdfs_files = []\n",
    "\n",
    "for f in file_paths:\n",
    "    if \"PDFS\" in f:\n",
    "        pdfs_files.append(f)\n",
    "    else:\n",
    "        pd_files.append(f)\n",
    "\n",
    "print(f\"PD volumes: {len(pd_files)}\")\n",
    "print(f\"PDFS volumes: {len(pdfs_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cedbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD volumes: 100\n",
      "PDFS volumes: 99\n"
     ]
    }
   ],
   "source": [
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "pd_files = []\n",
    "pdfs_files = []\n",
    "\n",
    "for f in kspace_files_list_val:\n",
    "    if \"PDFS\" in f:\n",
    "        pdfs_files.append(f)\n",
    "    else:\n",
    "        pd_files.append(f)\n",
    "\n",
    "print(f\"PD volumes: {len(pd_files)}\")\n",
    "print(f\"PDFS volumes: {len(pdfs_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b0b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running FGNet inference: 100%|████████████████████████████████████████████████████| 100/100 [3:28:05<00:00, 124.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PSNR (Mag, volume): 35.7083 ± 3.0233 dB\n",
      "NMSE (Mag, volume): 0.011012 ± 0.006443\n",
      "SSIM (Mag, slice):  0.8564 ± 0.0648\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "psnr_list = []\n",
    "nmse_list = []\n",
    "ssim_list = []\n",
    "with torch.no_grad():\n",
    "    for file in tqdm(pd_files, desc=\"Running FGNet inference\"):\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            img_us   = f[\"image_under\"][:]     # (S,H,W,2)\n",
    "            img_gt   = f[\"image_full\"][:]      # (S,H,W,2)\n",
    "            kspace   = f[\"kspace_full\"][:]     # (S,H,W,2)\n",
    "            max_val  = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "        num_slices = img_us.shape[0]\n",
    "\n",
    "        # --------------------------\n",
    "        # Torch conversion\n",
    "        # --------------------------\n",
    "        img_us_t = torch.from_numpy(img_us).float().to(DEVICE)\n",
    "        img_gt_t = torch.from_numpy(img_gt).float().to(DEVICE)\n",
    "        kspace_t = torch.from_numpy(kspace).float().to(DEVICE)\n",
    "\n",
    "        # Add channel dim for FGNet\n",
    "        img_us_t = img_us_t.unsqueeze(1)     # (S,1,H,W,2)\n",
    "        kspace_t = kspace_t.unsqueeze(1)     # (S,1,H,W,2)\n",
    "\n",
    "        # Tile mask for slices\n",
    "        mask_batch = mask_t.repeat(num_slices, 1,1, 1, 1).to(DEVICE)\n",
    "\n",
    "        # --------------------------\n",
    "        # FGNet Forward\n",
    "        # --------------------------\n",
    "        out, _ = model(img_us_t, kspace_t, mask_batch)\n",
    "\n",
    "        # --------------------------\n",
    "        # Scale back to original range\n",
    "        # --------------------------\n",
    "        pred_mag = complex_abs(out).cpu().numpy() * max_val\n",
    "        gt_mag   = complex_abs(img_gt_t).cpu().numpy() * max_val\n",
    "\n",
    "        # --------------------------\n",
    "        # Volume metrics\n",
    "        # --------------------------\n",
    "        psnr_val = peak_signal_noise_ratio(\n",
    "            gt_mag.flatten(), pred_mag.flatten(), data_range=max_val\n",
    "        )\n",
    "\n",
    "        nmse_val = nmse(gt_mag.flatten(), pred_mag.flatten())\n",
    "\n",
    "        psnr_list.append(psnr_val)\n",
    "        nmse_list.append(nmse_val)\n",
    "\n",
    "        # --------------------------\n",
    "        # Slice-wise SSIM\n",
    "        # --------------------------\n",
    "        for i in range(num_slices):\n",
    "            ssim_val = compute_ssim(gt_mag[i], pred_mag[i], max_val)\n",
    "            ssim_list.append(ssim_val)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"PSNR (Mag, volume): {np.mean(psnr_list):.4f} ± {np.std(psnr_list):.4f} dB\")\n",
    "print(f\"NMSE (Mag, volume): {np.mean(nmse_list):.6f} ± {np.std(nmse_list):.6f}\")\n",
    "print(f\"SSIM (Mag, slice):  {np.mean(ssim_list):.4f} ± {np.std(ssim_list):.4f}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53985a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timing on cpu:   1%|▋                                                               | 2/199 [03:49<6:16:23, 114.64s/it]\n",
      "Timing on cuda:0:   1%|▋                                                               | 2/199 [00:08<14:36,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FGNet EFFICIENCY REPORT (SLICE-WISE, BATCH SIZE = 1)\n",
      "======================================================================\n",
      "Parameters: 1.16 M\n",
      "FLOPs:      Not reported (complex-valued + FFT operations)\n",
      "\n",
      "--- CPU Inference ---\n",
      "Latency:     2.29 s / slice\n",
      "Throughput:  0.436 slices/sec\n",
      "Memory:      741.25 MB\n",
      "\n",
      "--- GPU Inference ---\n",
      "GPU:         NVIDIA RTX A5000\n",
      "Latency:     0.09 s / slice\n",
      "Throughput:  11.448 slices/sec\n",
      "Peak VRAM:   631.31 MB\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import psutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "VAL_FOLDER = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "\n",
    "WARMUP_SLICES = 10\n",
    "NUM_TIMING_SLICES = 100   # fixed slice count\n",
    "\n",
    "DEVICE_CPU = torch.device(\"cpu\")\n",
    "DEVICE_GPU = torch.device(\"cuda:0\") if torch.cuda.is_available() else None\n",
    "\n",
    "# ============================================================\n",
    "# FILE LIST\n",
    "# ============================================================\n",
    "file_paths = sorted(glob.glob(os.path.join(VAL_FOLDER, \"*.h5\")))\n",
    "assert len(file_paths) > 0, \"No validation files found\"\n",
    "\n",
    "# ============================================================\n",
    "# MODEL\n",
    "# ============================================================\n",
    "assert model is not None, \"Model not loaded\"\n",
    "model.eval()\n",
    "\n",
    "# ============================================================\n",
    "# PARAMETER COUNT\n",
    "# ============================================================\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# ============================================================\n",
    "# MEMORY HELPERS\n",
    "# ============================================================\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "def cpu_memory_mb():\n",
    "    return process.memory_info().rss / (1024 ** 2)\n",
    "\n",
    "def gpu_memory_mb():\n",
    "    return torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "\n",
    "# ============================================================\n",
    "# LATENCY MEASUREMENT\n",
    "# ============================================================\n",
    "def measure_latency(device):\n",
    "\n",
    "    model.to(device)\n",
    "    latencies = []\n",
    "\n",
    "    # -----------------------------\n",
    "    # WARM-UP\n",
    "    # -----------------------------\n",
    "    with torch.no_grad():\n",
    "        for file in file_paths[:1]:\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                img_us = f[\"image_under\"][:]\n",
    "                kspace = f[\"kspace_full\"][:]\n",
    "\n",
    "            for s in range(min(WARMUP_SLICES, img_us.shape[0])):\n",
    "                x = torch.from_numpy(img_us[s:s+1]).float().unsqueeze(1).to(device)\n",
    "                k = torch.from_numpy(kspace[s:s+1]).float().unsqueeze(1).to(device)\n",
    "                m = mask_t[:1].to(device)\n",
    "\n",
    "                _ = model(x, k, m)\n",
    "\n",
    "                if device.type == \"cuda\":\n",
    "                    torch.cuda.synchronize()\n",
    "\n",
    "    # -----------------------------\n",
    "    # TIMED INFERENCE\n",
    "    # -----------------------------\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for file in tqdm(file_paths, desc=f\"Timing on {device}\"):\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                img_us = f[\"image_under\"][:]\n",
    "                kspace = f[\"kspace_full\"][:]\n",
    "\n",
    "            for s in range(img_us.shape[0]):\n",
    "\n",
    "                if count >= NUM_TIMING_SLICES:\n",
    "                    break\n",
    "\n",
    "                x = torch.from_numpy(img_us[s:s+1]).float().unsqueeze(1).to(device)\n",
    "                k = torch.from_numpy(kspace[s:s+1]).float().unsqueeze(1).to(device)\n",
    "                m = mask_t[:1].to(device)\n",
    "\n",
    "                start = time.perf_counter()\n",
    "                _ = model(x, k, m)\n",
    "\n",
    "                if device.type == \"cuda\":\n",
    "                    torch.cuda.synchronize()\n",
    "\n",
    "                end = time.perf_counter()\n",
    "\n",
    "                latencies.append(end - start)\n",
    "                count += 1\n",
    "\n",
    "            if count >= NUM_TIMING_SLICES:\n",
    "                break\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "\n",
    "    return {\n",
    "        \"mean_s\": latencies.mean(),\n",
    "        \"median_s\": np.median(latencies),\n",
    "        \"std_s\": latencies.std(),\n",
    "        \"slices_per_sec\": 1.0 / latencies.mean()\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# CPU BENCHMARK\n",
    "# ============================================================\n",
    "cpu_mem_before = cpu_memory_mb()\n",
    "cpu_latency = measure_latency(DEVICE_CPU)\n",
    "cpu_mem_after = cpu_memory_mb()\n",
    "cpu_mem_peak = cpu_mem_after - cpu_mem_before\n",
    "\n",
    "# ============================================================\n",
    "# GPU BENCHMARK\n",
    "# ============================================================\n",
    "gpu_latency = None\n",
    "gpu_mem_peak = None\n",
    "gpu_name = None\n",
    "\n",
    "if DEVICE_GPU:\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_latency = measure_latency(DEVICE_GPU)\n",
    "    gpu_mem_peak = gpu_memory_mb()\n",
    "\n",
    "# ============================================================\n",
    "# FINAL REPORT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FGNet EFFICIENCY REPORT (SLICE-WISE, BATCH SIZE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Parameters: {num_params / 1e6:.2f} M\")\n",
    "print(\"FLOPs:      Not reported (complex-valued + FFT operations)\")\n",
    "\n",
    "print(\"\\n--- CPU Inference ---\")\n",
    "print(f\"Latency:     {cpu_latency['mean_s']:.2f} s / slice\")\n",
    "print(f\"Throughput:  {cpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "print(f\"Memory:      {cpu_mem_peak:.2f} MB\")\n",
    "\n",
    "if gpu_latency:\n",
    "    print(\"\\n--- GPU Inference ---\")\n",
    "    print(f\"GPU:         {gpu_name}\")\n",
    "    print(f\"Latency:     {gpu_latency['mean_s']:.2f} s / slice\")\n",
    "    print(f\"Throughput:  {gpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "    print(f\"Peak VRAM:   {gpu_mem_peak:.2f} MB\")\n",
    "else:\n",
    "    print(\"\\nGPU not available.\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb029e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
