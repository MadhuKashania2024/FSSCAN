{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34caa0fa-7d16-428e-a91a-ef4367a02529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20d0554-37ec-463a-a4f1-67767c7ea9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRISliceGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, file_list, batch_size=4, shuffle=True, use_dc=False):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.use_dc = use_dc   # NEW FLAG\n",
    "        self.slice_index_map = []\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        for file_idx, file_path in enumerate(self.file_list):\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                num_slices = f['image_under'].shape[0]\n",
    "                for slice_idx in range(num_slices):\n",
    "                    self.slice_index_map.append((file_idx, slice_idx))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.slice_index_map) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_map = self.slice_index_map[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        input_img_batch = []\n",
    "        target_img_batch = []\n",
    "        input_kspace_batch = []\n",
    "\n",
    "        for file_idx, slice_idx in batch_map:\n",
    "            with h5py.File(self.file_list[file_idx], 'r') as f:\n",
    "                input_img = f['image_under'][slice_idx]       # (H,W,2)\n",
    "                target_img = f['image_full'][slice_idx]       # (H,W,2)\n",
    "                input_kspace = f['kspace_under'][slice_idx]   # (H,W,2)\n",
    "\n",
    "                input_img_batch.append(input_img)\n",
    "                target_img_batch.append(target_img)\n",
    "                input_kspace_batch.append(input_kspace)\n",
    "\n",
    "        x_img = np.stack(input_img_batch, axis=0)\n",
    "        x_kspace = np.stack(input_kspace_batch, axis=0)\n",
    "        y_batch = np.stack(target_img_batch, axis=0)\n",
    "\n",
    "        if self.use_dc:\n",
    "            # DSMENet expects two inputs when DC is used\n",
    "            return [x_img, x_kspace], y_batch\n",
    "        else:\n",
    "            # Only image input (ZF)\n",
    "            return x_img, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.slice_index_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bc4fdd-623c-4960-842b-ea23e71d8d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784\n"
     ]
    }
   ],
   "source": [
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "\n",
    "# half_train = 20\n",
    "# half_val = 10\n",
    "\n",
    "half_val = len(kspace_files_list_val) \n",
    "# print(\"half_train\",half_train)\n",
    "# print(\"half_val\",half_val)\n",
    "\n",
    "kspace_files_list_val = kspace_files_list_val[:half_val]\n",
    "\n",
    "# Create generators\n",
    "# train_gen = MRISliceGenerator(kspace_files_list_train,batch_size=16, shuffle=True,mask=mask)\n",
    "# val_gen = MRISliceGenerator(kspace_files_list_val, batch_size=4, shuffle=False,mask=mask)\n",
    "\n",
    "val_gen = MRISliceGenerator(kspace_files_list_val, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "print(len(val_gen))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7352df5-7554-4a4d-afbf-8564008e39f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DSMENet_Functional\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 256, 256, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " SRUN_1 (SRUN)                  ((None, 256, 256, 1  542204      ['input_image[0][0]']            \n",
      "                                6),                                                               \n",
      "                                 (None, 256, 256, 2                                               \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " DRCM_initial (DRCM)            (None, 256, 256, 2)  38          ['input_image[0][0]']            \n",
      "                                                                                                  \n",
      " DFRM_1 (DFRM)                  (None, 256, 256, 2)  61683       ['DRCM_initial[0][0]',           \n",
      "                                                                  'SRUN_1[0][0]']                 \n",
      "                                                                                                  \n",
      " DGFM_1 (DGFM)                  (None, 256, 256, 2)  22          ['SRUN_1[0][1]',                 \n",
      "                                                                  'DFRM_1[0][0]']                 \n",
      "                                                                                                  \n",
      " SRUN_shared (SRUN)             ((None, 256, 256, 1  542204      ['DGFM_1[0][0]',                 \n",
      "                                6),                               'DGFM_shared[0][0]',            \n",
      "                                 (None, 256, 256, 2               'DGFM_shared[1][0]',            \n",
      "                                ))                                'DGFM_shared[2][0]',            \n",
      "                                                                  'DGFM_shared[3][0]',            \n",
      "                                                                  'DGFM_shared[4][0]']            \n",
      "                                                                                                  \n",
      " DFRM_shared (DFRM)             (None, 256, 256, 2)  61683       ['DFRM_1[0][0]',                 \n",
      "                                                                  'SRUN_shared[0][0]',            \n",
      "                                                                  'DFRM_shared[0][0]',            \n",
      "                                                                  'SRUN_shared[1][0]',            \n",
      "                                                                  'DFRM_shared[1][0]',            \n",
      "                                                                  'SRUN_shared[2][0]',            \n",
      "                                                                  'DFRM_shared[2][0]',            \n",
      "                                                                  'SRUN_shared[3][0]',            \n",
      "                                                                  'DFRM_shared[3][0]',            \n",
      "                                                                  'SRUN_shared[4][0]',            \n",
      "                                                                  'DFRM_shared[4][0]',            \n",
      "                                                                  'SRUN_shared[5][0]']            \n",
      "                                                                                                  \n",
      " DGFM_shared (DGFM)             (None, 256, 256, 2)  22          ['SRUN_shared[0][1]',            \n",
      "                                                                  'DFRM_shared[0][0]',            \n",
      "                                                                  'SRUN_shared[1][1]',            \n",
      "                                                                  'DFRM_shared[1][0]',            \n",
      "                                                                  'SRUN_shared[2][1]',            \n",
      "                                                                  'DFRM_shared[2][0]',            \n",
      "                                                                  'SRUN_shared[3][1]',            \n",
      "                                                                  'DFRM_shared[3][0]',            \n",
      "                                                                  'SRUN_shared[4][1]',            \n",
      "                                                                  'DFRM_shared[4][0]',            \n",
      "                                                                  'SRUN_shared[5][1]',            \n",
      "                                                                  'DFRM_shared[5][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,207,856\n",
      "Trainable params: 1,207,856\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "SRUN output shape: (1, 256, 256, 2)\n",
      "DRCM output shape: (1, 256, 256, 2)\n",
      "DFRM output shape: (1, 256, 256, 2)\n",
      "DFGM output shape: (1, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f506d95-c1d1-4290-937d-e365b309207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_DSMENet_functional(\n",
    "    N=6, M=1, T=2,\n",
    "    H=320, W=320, C=2\n",
    ")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aea4266-eed4-423d-8e31-e1a36d666b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DU\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timing on /CPU:0:   1%|‚ñå                                                           | 2/199 [07:58<13:05:57, 239.38s/it]\n",
      "Timing on /GPU:0:   1%|‚ñå                                                             | 2/199 [02:03<3:23:15, 61.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL EFFICIENCY REPORT (SLICE-WISE, BATCH SIZE = 1)\n",
      "======================================================================\n",
      "Parameters: 1.21 M\n",
      "FLOPs:      258.25 GFLOPs (per slice)\n",
      "\n",
      "--- CPU Inference ---\n",
      "Latency:    4.79 s / slice\n",
      "Throughput:0.209 slices/sec\n",
      "Memory:     5.51 MB\n",
      "\n",
      "--- GPU Inference ---\n",
      "GPU:        NVIDIA RTX A5000\n",
      "Latency:    1.24 s / slice\n",
      "Throughput:0.809 slices/sec\n",
      "Peak VRAM:  269.08 MB\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import psutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras_flops import get_flops\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "VAL_FOLDER = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "WARMUP_SLICES = 10\n",
    "NUM_TIMING_SLICES = 100   # fixed slice count\n",
    "\n",
    "# ============================================================\n",
    "# FILE LIST\n",
    "# ============================================================\n",
    "file_paths = sorted(glob.glob(os.path.join(VAL_FOLDER, \"*.h5\")))\n",
    "def inference_slice(model, x):\n",
    "    _, F_final = model(x, training=False)\n",
    "    #print(\"F_final\",F_final.shape)\n",
    "    return F_final\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL + INFERENCE FUNCTION MUST EXIST\n",
    "# ============================================================\n",
    "# model = ...\n",
    "# def inference_slice(model, x): ...\n",
    "assert model is not None, \"Model is not loaded.\"\n",
    "assert callable(inference_slice), \"inference_slice() is not defined.\"\n",
    "\n",
    "# ============================================================\n",
    "# PARAMETER COUNT\n",
    "# ============================================================\n",
    "num_params = model.count_params()\n",
    "\n",
    "# ============================================================\n",
    "# FLOPs (PER SLICE, BATCH SIZE = 1)\n",
    "# NOTE: FLOPs are counted for the model forward pass\n",
    "# ============================================================\n",
    "flops = get_flops(model, batch_size=1)\n",
    "\n",
    "# ============================================================\n",
    "# MEMORY HELPERS\n",
    "# ============================================================\n",
    "process = psutil.Process(os.getpid())\n",
    "def cpu_memory_mb():\n",
    "    return process.memory_info().rss / (1024 ** 2)\n",
    "\n",
    "def gpu_memory_mb():\n",
    "    info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "    return info[\"peak\"] / (1024 ** 2)\n",
    "\n",
    "# ============================================================\n",
    "# LATENCY / THROUGHPUT MEASUREMENT\n",
    "# ============================================================\n",
    "def measure_latency(device):\n",
    "\n",
    "    latencies = []\n",
    "\n",
    "    with tf.device(device):\n",
    "\n",
    "        # -----------------------------\n",
    "        # WARM-UP\n",
    "        # -----------------------------\n",
    "        for file in file_paths[:1]:\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(min(WARMUP_SLICES, image_under.shape[0])):\n",
    "                x = tf.convert_to_tensor(\n",
    "                    image_under[s:s+1], dtype=tf.float32\n",
    "                )\n",
    "                _ = inference_slice(model, x)\n",
    "\n",
    "        # -----------------------------\n",
    "        # TIMED INFERENCE\n",
    "        # -----------------------------\n",
    "        count = 0\n",
    "        for file in tqdm(file_paths, desc=f\"Timing on {device}\"):\n",
    "\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(image_under.shape[0]):\n",
    "\n",
    "                if count >= NUM_TIMING_SLICES:\n",
    "                    break\n",
    "\n",
    "                x = tf.convert_to_tensor(\n",
    "                    image_under[s:s+1], dtype=tf.float32\n",
    "                )\n",
    "                assert x.shape[0] == 1  # batch size = 1\n",
    "\n",
    "                start = time.perf_counter()\n",
    "                _ = inference_slice(model, x)\n",
    "\n",
    "                # üîë GPU synchronization\n",
    "                if \"GPU\" in device:\n",
    "                    tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "\n",
    "                end = time.perf_counter()\n",
    "\n",
    "                latencies.append(end - start)\n",
    "                count += 1\n",
    "\n",
    "            if count >= NUM_TIMING_SLICES:\n",
    "                break\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "\n",
    "    mean_s = latencies.mean()\n",
    "    median_s = np.median(latencies)\n",
    "\n",
    "    return {\n",
    "        \"mean_s\": mean_s,\n",
    "        \"median_s\": median_s,\n",
    "        \"std_s\": latencies.std(),\n",
    "        \"slices_per_sec\": 1.0 / mean_s\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# CPU BENCHMARK\n",
    "# ============================================================\n",
    "cpu_mem_before = cpu_memory_mb()\n",
    "cpu_latency = measure_latency(\"/CPU:0\")\n",
    "cpu_mem_after = cpu_memory_mb()\n",
    "cpu_mem_peak = cpu_mem_after - cpu_mem_before\n",
    "\n",
    "# ============================================================\n",
    "# GPU BENCHMARK (IF AVAILABLE)\n",
    "# ============================================================\n",
    "gpu_latency = None\n",
    "gpu_mem_peak = None\n",
    "gpu_name = None\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    gpu_name = tf.config.experimental.get_device_details(gpus[0])[\"device_name\"]\n",
    "    gpu_latency = measure_latency(\"/GPU:0\")\n",
    "    gpu_mem_peak = gpu_memory_mb()\n",
    "\n",
    "# ============================================================\n",
    "# FINAL REPORT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL EFFICIENCY REPORT (SLICE-WISE, BATCH SIZE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Parameters: {num_params / 1e6:.2f} M\")\n",
    "print(f\"FLOPs:      {flops / 1e9:.2f} GFLOPs (per slice)\")\n",
    "\n",
    "print(\"\\n--- CPU Inference ---\")\n",
    "print(f\"Latency:    {cpu_latency['mean_s']:.2f} s / slice\")\n",
    "print(f\"Throughput:{cpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "print(f\"Memory:     {cpu_mem_peak:.2f} MB\")\n",
    "\n",
    "if gpu_latency:\n",
    "    print(\"\\n--- GPU Inference ---\")\n",
    "    print(f\"GPU:        {gpu_name}\")\n",
    "    print(f\"Latency:    {gpu_latency['mean_s']:.2f} s / slice\")\n",
    "    print(f\"Throughput:{gpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "    print(f\"Peak VRAM:  {gpu_mem_peak:.2f} MB\")\n",
    "else:\n",
    "    print(\"\\nGPU not available.\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e066729-67c5-40ef-af9b-34996bb25e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Total parameters:       1.208 M\n",
      "Trainable parameters:   1.208 M\n",
      "Non-trainable params:   0.000 M\n",
      "========================================\n",
      "WARNING:tensorflow:From C:\\Users\\Research\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOPs (single forward pass): 258.04 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "def count_parameters_millions(model):\n",
    "    trainable = np.sum([np.prod(v.shape) for v in model.trainable_variables])\n",
    "    non_trainable = np.sum([np.prod(v.shape) for v in model.non_trainable_variables])\n",
    "    total = trainable + non_trainable\n",
    "    return (\n",
    "        total / 1e6,\n",
    "        trainable / 1e6,\n",
    "        non_trainable / 1e6\n",
    "    )\n",
    "\n",
    "total_M, trainable_M, non_trainable_M = count_parameters_millions(model)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"Total parameters:       {total_M:.3f} M\")\n",
    "print(f\"Trainable parameters:   {trainable_M:.3f} M\")\n",
    "print(f\"Non-trainable params:   {non_trainable_M:.3f} M\")\n",
    "print(\"=\" * 40)\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "def compute_flops(model, input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: tuple, e.g. (1, H, W, 2)\n",
    "    returns FLOPs (float operations) for one forward pass\n",
    "    \"\"\"\n",
    "\n",
    "    @tf.function\n",
    "    def forward(x):\n",
    "        return model(x)\n",
    "\n",
    "    concrete_func = forward.get_concrete_function(\n",
    "        tf.TensorSpec(input_shape, tf.float32)\n",
    "    )\n",
    "\n",
    "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=graph,\n",
    "            run_meta=run_meta,\n",
    "            cmd=\"op\",\n",
    "            options=opts\n",
    "        )\n",
    "\n",
    "    return flops.total_float_ops\n",
    "# Example: infer H, W from your data or define explicitly\n",
    "H, W = 320,320\n",
    "\n",
    "flops = compute_flops(model, input_shape=(1, H, W, 2))\n",
    "\n",
    "print(f\"FLOPs (single forward pass): {flops / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cebe0ec-e3ba-41a0-b52b-d7587973399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# METRICS (SAME AS TRAINING)\n",
    "# =========================================================\n",
    "\n",
    "def nmse(pred, target):\n",
    "    return tf.reduce_sum(tf.square(pred - target)) / tf.reduce_sum(tf.square(target))\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CHECKPOINT LOADER\n",
    "# =========================================================\n",
    "\n",
    "def load_dmse_checkpoint(model, ckpt_dir=\"./checkpoints_dmse_full\"):\n",
    "    optimizer = tf.keras.optimizers.Adam()  # dummy optimizer\n",
    "\n",
    "    epoch_counter = tf.Variable(0, dtype=tf.int64)\n",
    "    best_val_ssim = tf.Variable(-1.0, dtype=tf.float32)\n",
    "\n",
    "    ckpt = tf.train.Checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        epoch=epoch_counter,\n",
    "        best_val_ssim=best_val_ssim\n",
    "    )\n",
    "\n",
    "    manager = tf.train.CheckpointManager(\n",
    "        ckpt,\n",
    "        directory=ckpt_dir,\n",
    "        max_to_keep=1\n",
    "    )\n",
    "\n",
    "    if not manager.latest_checkpoint:\n",
    "        raise RuntimeError(\"‚ùå No checkpoint found!\")\n",
    "\n",
    "    ckpt.restore(manager.latest_checkpoint).expect_partial()\n",
    "\n",
    "    print(f\"\\n‚úÖ Restored checkpoint: {manager.latest_checkpoint}\")\n",
    "    print(f\"‚≠ê Best Val SSIM: {best_val_ssim.numpy():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# INFERENCE STEP\n",
    "# =========================================================\n",
    "\n",
    "@tf.function\n",
    "def inference_step(model, x):\n",
    "    _, F_final = model(x, training=False)\n",
    "    return F_final\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# EVALUATION LOOP (NO SAVING)\n",
    "# =========================================================\n",
    "\n",
    "def evaluate_dmse(model, val_gen):\n",
    "    ssim_list = []\n",
    "    psnr_list = []\n",
    "    nmse_list = []\n",
    "\n",
    "    val_bar = tqdm(range(len(val_gen)), desc=\"Evaluating\", ncols=120)\n",
    "\n",
    "    for step in val_bar:\n",
    "        x_val, y_val = val_gen[step]\n",
    "\n",
    "        # Forward pass\n",
    "        F_final = inference_step(model, x_val)\n",
    "\n",
    "        # Metrics\n",
    "        ssim_val = tf.reduce_mean(tf.image.ssim(F_final, y_val, max_val=1.0))\n",
    "        psnr_val = tf.reduce_mean(tf.image.psnr(F_final, y_val, max_val=1.0))\n",
    "        nmse_val = nmse(F_final, y_val)\n",
    "\n",
    "        ssim_list.append(ssim_val.numpy())\n",
    "        psnr_list.append(psnr_val.numpy())\n",
    "        nmse_list.append(nmse_val.numpy())\n",
    "\n",
    "        val_bar.set_postfix({\n",
    "            \"SSIM\": f\"{ssim_val.numpy():.4f}\",\n",
    "            \"PSNR\": f\"{psnr_val.numpy():.2f}\",\n",
    "            \"NMSE\": f\"{nmse_val.numpy():.4f}\"\n",
    "        })\n",
    "\n",
    "    # =====================================================\n",
    "    # FINAL METRICS\n",
    "    # =====================================================\n",
    "    mean_ssim = float(np.mean(ssim_list))\n",
    "    mean_psnr = float(np.mean(psnr_list))\n",
    "    mean_nmse = float(np.mean(nmse_list))\n",
    "\n",
    "    print(\"\\nüìä FINAL VALIDATION RESULTS\")\n",
    "    print(f\"  Mean SSIM : {mean_ssim:.4f}\")\n",
    "    print(f\"  Mean PSNR : {mean_psnr:.2f}\")\n",
    "    print(f\"  Mean NMSE : {mean_nmse:.4f}\")\n",
    "\n",
    "    return mean_ssim, mean_psnr, mean_nmse\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# RUN EVALUATION\n",
    "# =========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc60c0b-2dcf-4dcf-827e-f3faff9e6daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Restored checkpoint: ./checkpoints_dmse_full\\ckpt-27\n",
      "‚≠ê Best Val SSIM: 0.7191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1784/1784 [19:54<00:00,  1.49it/s, SSIM=0.6350, PSNR=29.57, NMSE=0.0579]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä FINAL VALIDATION RESULTS\n",
      "  Mean SSIM : 0.7192\n",
      "  Mean PSNR : 32.82\n",
      "  Mean NMSE : 0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_dmse_checkpoint(model)\n",
    "\n",
    "mean_ssim, mean_psnr, mean_nmse = evaluate_dmse(model, val_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ede8bfb-eb25-44cb-8b04-9401dd5319d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD volumes: 100\n",
      "PDFS volumes: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [13:41<00:00,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PSNR (Mag, volume): -13.9292 ¬± 3.2128 dB\n",
      "NMSE (Mag, volume): 1530.412936 ¬± 1501.141297\n",
      "SSIM (Mag, slice):  0.0000 ¬± 0.0000\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "pd_files = []\n",
    "pdfs_files = []\n",
    "\n",
    "for f in kspace_files_list_val:\n",
    "    if \"PDFS\" in f:\n",
    "        pdfs_files.append(f)\n",
    "    else:\n",
    "        pd_files.append(f)\n",
    "\n",
    "print(f\"PD volumes: {len(pd_files)}\")\n",
    "print(f\"PDFS volumes: {len(pdfs_files)}\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2)\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03,\n",
    "        full=False\n",
    "    )\n",
    "@tf.function\n",
    "def inference_slice(model, x):\n",
    "    _, F_final = model(x, training=False)\n",
    "    #print(\"F_final\",F_final.shape)\n",
    "    return F_final\n",
    "\n",
    "# ----------------------------------\n",
    "# Containers for Excel\n",
    "# ----------------------------------\n",
    "volume_metrics = []   # volume-wise PSNR & NMSE\n",
    "slice_metrics  = []   # slice-wise SSIM\n",
    "\n",
    "psnr_list = []\n",
    "nmse_list = []\n",
    "ssim_list = []\n",
    "\n",
    "for file in tqdm(pdfs_files, desc=\"Processing volumes\", ncols=120):\n",
    "\n",
    "    volume_name = os.path.basename(file)\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full  = f[\"image_full\"][:]      # (S, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]     # (S, H, W, 2)\n",
    "        max_val     = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "    # ----------------------\n",
    "    # Slice-wise inference\n",
    "    # ----------------------\n",
    "    preds = []\n",
    "    for s in range(image_under.shape[0]):\n",
    "        x = tf.convert_to_tensor(image_under[s:s+1], dtype=tf.float32)\n",
    "        pred = inference_slice(model, x)\n",
    "        preds.append(pred.numpy()[0])\n",
    "\n",
    "    pred = np.stack(preds, axis=0)  # (S, H, W, 2)\n",
    "\n",
    "    # ----------------------\n",
    "    # De-normalize\n",
    "    # ----------------------\n",
    "    image_full = image_full * max_val\n",
    "    pred       = pred * max_val\n",
    "\n",
    "    # ----------------------\n",
    "    # Magnitude images\n",
    "    # ----------------------\n",
    "    gt_mag   = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # ----------------------\n",
    "    # Volume-wise metrics\n",
    "    # ----------------------\n",
    "    nmse_val = nmse(gt_mag.flatten(), pred_mag.flatten())\n",
    "    psnr_val = peak_signal_noise_ratio(gt_mag, pred_mag, data_range=max_val)\n",
    "\n",
    "    nmse_list.append(nmse_val)\n",
    "    psnr_list.append(psnr_val)\n",
    "\n",
    "    volume_metrics.append({\n",
    "        \"Volume\": volume_name,\n",
    "        \"PSNR (dB)\": psnr_val,\n",
    "        \"NMSE\": nmse_val\n",
    "    })\n",
    "\n",
    "    # ----------------------\n",
    "    # Slice-wise SSIM\n",
    "    # ----------------------\n",
    "    for i in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(gt_mag[i], pred_mag[i], max_val)\n",
    "\n",
    "        ssim_list.append(ssim_val)\n",
    "\n",
    "        slice_metrics.append({\n",
    "            \"Volume\": volume_name,\n",
    "            \"Slice_ID\": i,\n",
    "            \"SSIM\": ssim_val\n",
    "        })\n",
    "\n",
    "# ----------------------------------\n",
    "# Print summary\n",
    "# ----------------------------------\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"PSNR (Mag, volume): {np.mean(psnr_list):.4f} ¬± {np.std(psnr_list):.4f} dB\")\n",
    "print(f\"NMSE (Mag, volume): {np.mean(nmse_list):.6f} ¬± {np.std(nmse_list):.6f}\")\n",
    "print(f\"SSIM (Mag, slice):  {np.mean(ssim_list):.4f} ¬± {np.std(ssim_list):.4f}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ----------------------------------\n",
    "# Save to Excel (multi-sheet)\n",
    "# ----------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ae7a488-dbd3-4e21-a633-82a0deb45291",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_files = []\n",
    "pdfs_files = []\n",
    "\n",
    "for f in kspace_files_list_val:\n",
    "    if \"PDFS\" in f:\n",
    "        pdfs_files.append(f)\n",
    "    else:\n",
    "        pd_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "435cd9a5-6c93-4f41-a056-653e607cc2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [13:21<00:00,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PSNR (Mag, volume): 32.5894 ¬± 2.5905 dB\n",
      "NMSE (Mag, volume): 0.029795 ¬± 0.013134\n",
      "SSIM (Mag, slice):  0.7649 ¬± 0.0809\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2)\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03,\n",
    "        full=False\n",
    "    )\n",
    "\n",
    "# ----------------------------------\n",
    "# Containers for Excel\n",
    "# ----------------------------------\n",
    "volume_metrics = []   # volume-wise PSNR & NMSE\n",
    "slice_metrics  = []   # slice-wise SSIM\n",
    "\n",
    "psnr_list = []\n",
    "nmse_list = []\n",
    "ssim_list = []\n",
    "\n",
    "for file in tqdm(pdfs_files, desc=\"Processing volumes\", ncols=120):\n",
    "\n",
    "    volume_name = os.path.basename(file)\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full  = f[\"image_full\"][:]      # (S, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]     # (S, H, W, 2)\n",
    "        max_val     = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "    # ----------------------\n",
    "    # Slice-wise inference\n",
    "    # ----------------------\n",
    "    preds = []\n",
    "    for s in range(image_under.shape[0]):\n",
    "        x = tf.convert_to_tensor(image_under[s:s+1], dtype=tf.float32)\n",
    "        pred = inference_slice(model, x)\n",
    "        preds.append(pred.numpy()[0])\n",
    "\n",
    "    pred = np.stack(preds, axis=0)  # (S, H, W, 2)\n",
    "\n",
    "    # ----------------------\n",
    "    # De-normalize\n",
    "    # ----------------------\n",
    "    image_full = image_full * max_val\n",
    "    pred       = pred * max_val\n",
    "\n",
    "    # ----------------------\n",
    "    # Magnitude images\n",
    "    # ----------------------\n",
    "    gt_mag   = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # ----------------------\n",
    "    # Volume-wise metrics\n",
    "    # ----------------------\n",
    "    nmse_val = nmse(gt_mag.flatten(), pred_mag.flatten())\n",
    "    psnr_val = peak_signal_noise_ratio(gt_mag, pred_mag, data_range=max_val)\n",
    "\n",
    "    nmse_list.append(nmse_val)\n",
    "    psnr_list.append(psnr_val)\n",
    "\n",
    "    volume_metrics.append({\n",
    "        \"Volume\": volume_name,\n",
    "        \"PSNR (dB)\": psnr_val,\n",
    "        \"NMSE\": nmse_val\n",
    "    })\n",
    "\n",
    "    # ----------------------\n",
    "    # Slice-wise SSIM\n",
    "    # ----------------------\n",
    "    for i in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(gt_mag[i], pred_mag[i], max_val)\n",
    "\n",
    "        ssim_list.append(ssim_val)\n",
    "\n",
    "        slice_metrics.append({\n",
    "            \"Volume\": volume_name,\n",
    "            \"Slice_ID\": i,\n",
    "            \"SSIM\": ssim_val\n",
    "        })\n",
    "\n",
    "# ----------------------------------\n",
    "# Print summary\n",
    "# ----------------------------------\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"PSNR (Mag, volume): {np.mean(psnr_list):.4f} ¬± {np.std(psnr_list):.4f} dB\")\n",
    "print(f\"NMSE (Mag, volume): {np.mean(nmse_list):.6f} ¬± {np.std(nmse_list):.6f}\")\n",
    "print(f\"SSIM (Mag, slice):  {np.mean(ssim_list):.4f} ¬± {np.std(ssim_list):.4f}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ----------------------------------\n",
    "# Save to Excel (multi-sheet)\n",
    "# ----------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa72ecd-37a3-4567-8a77-ef1cdc0f0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume(h5_path):\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        x = f[\"image_under\"][:]     # [S, H, W, C]\n",
    "        y = f[\"image_full\"][:]   # [S, H, W, C]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e4183f-32ae-4476-a84c-31e7c5abe0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def inference_slice(model, x):\n",
    "    _, F_final = model(x, training=False)\n",
    "    #print(\"F_final\",F_final.shape)\n",
    "    return F_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3506a62b-16fb-4e34-8557-02577d340796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cfff61a-1e58-497f-90a8-635496bc5da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [24:32<00:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PSNR (Mag, volume): 33.3280 ¬± 2.7036 dB\n",
      "NMSE (Mag, volume): 0.022481 ¬± 0.012902\n",
      "SSIM (Mag, slice):  0.7894 ¬± 0.0771\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 102\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# ----------------------------------\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Save to Excel (multi-sheet)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# ----------------------------------\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m df_volume \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(volume_metrics)\n\u001b[0;32m    103\u001b[0m df_slice  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(slice_metrics)\n\u001b[0;32m    105\u001b[0m excel_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_metrics_FSSCAN.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ffa4405-5c27-4b8c-993f-ffacb64a5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved metrics to: validation_metrics_DMSENet.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_volume = pd.DataFrame(volume_metrics)\n",
    "df_slice  = pd.DataFrame(slice_metrics)\n",
    "\n",
    "excel_path = \"validation_metrics_DMSENet.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "    df_volume.to_excel(writer, sheet_name=\"Volume_PSNR_NMSE\", index=False)\n",
    "    df_slice.to_excel(writer, sheet_name=\"Slice_SSIM\", index=False)\n",
    "\n",
    "print(f\"\\nSaved metrics to: {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4d4b749-7baf-4ddf-8934-760733fced50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [30:15<00:00,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PSNR (Mag, volume): 32.6027 ¬± 3.7079 dB\n",
      "NMSE (Mag, volume): 0.064605 ¬± 0.054789\n",
      "SSIM (Mag, slice):  0.7834 ¬± 0.0784\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2)\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03,\n",
    "        full=False\n",
    "    )\n",
    "ssim_list = []\n",
    "psnr_list = []\n",
    "nmse_list = []\n",
    "for file in tqdm(kspace_files_list_val, desc=\"Processing volumes\", ncols=120):\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full  = f[\"image_full\"][:]      # (S, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]     # (S, H, W, 2)\n",
    "        max_val     = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "    # ----------------------\n",
    "    # Slice-wise inference\n",
    "    # ----------------------\n",
    "    preds = []\n",
    "\n",
    "    for s in range(image_under.shape[0]):\n",
    "        x = tf.convert_to_tensor(image_under[s:s+1], dtype=tf.float32)\n",
    "        pred = inference_slice(model, x)\n",
    "        preds.append(pred.numpy()[0])\n",
    "\n",
    "    pred = np.stack(preds, axis=0)  # (S, H, W, 2)\n",
    "\n",
    "    # ----------------------\n",
    "    # De-normalize\n",
    "    # ----------------------\n",
    "    image_full = image_full * max_val\n",
    "    pred = pred * max_val\n",
    "\n",
    "    # ----------------------\n",
    "    # Magnitude images\n",
    "    # ----------------------\n",
    "    gt_mag   = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # ----------------------\n",
    "    # Volume-wise NMSE & PSNR\n",
    "    # ----------------------\n",
    "    nmse_val = nmse(gt_mag.flatten(), pred_mag.flatten())\n",
    "    psnr_val = peak_signal_noise_ratio(gt_mag, pred_mag, data_range=max_val)\n",
    "    #print(\"psnr_val\",psnr_val)\n",
    "    #print(\"nmse_val\",nmse_val)\n",
    "    nmse_list.append(nmse_val)\n",
    "    psnr_list.append(psnr_val)\n",
    "\n",
    "    # ----------------------\n",
    "    # Slice-wise SSIM\n",
    "    # ----------------------\n",
    "    for i in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(gt_mag[i], pred_mag[i], max_val)\n",
    "        ssim_list.append(ssim_val)\n",
    "        #print(\"ssim_val\",ssim_val)\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"PSNR (Mag, volume): {np.mean(psnr_list):.4f} ¬± {np.std(psnr_list):.4f} dB\")\n",
    "print(f\"NMSE (Mag, volume): {np.mean(nmse_list):.6f} ¬± {np.std(nmse_list):.6f}\")\n",
    "print(f\"SSIM (Mag, slice):  {np.mean(ssim_list):.4f} ¬± {np.std(ssim_list):.4f}\")\n",
    "print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dead3277-d21c-4b80-8544-667c76470152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_dmse_volume_wise(model, h5_files):\n",
    "    vol_ssim_all = []\n",
    "    vol_psnr_all = []\n",
    "    vol_nmse_all = []\n",
    "\n",
    "    vol_bar = tqdm(h5_files, desc=\"Evaluating volumes\", ncols=120)\n",
    "\n",
    "    for h5_path in vol_bar:\n",
    "        x_vol, y_vol = load_volume(h5_path)\n",
    "\n",
    "        slice_ssim = []\n",
    "        slice_psnr = []\n",
    "        slice_nmse = []\n",
    "\n",
    "        for s in range(x_vol.shape[0]):\n",
    "            x_slice = tf.convert_to_tensor(x_vol[s:s+1])  # [1,H,W,C]\n",
    "            y_slice = tf.convert_to_tensor(y_vol[s:s+1])\n",
    "\n",
    "            F_final = inference_slice(model, x_slice)\n",
    "\n",
    "            ssim = tf.image.ssim(F_final, y_slice, max_val=1.0)\n",
    "            psnr = tf.image.psnr(F_final, y_slice, max_val=1.0)\n",
    "            nmse_val = nmse(F_final, y_slice)\n",
    "\n",
    "            slice_ssim.append(ssim.numpy()[0])\n",
    "            slice_psnr.append(psnr.numpy()[0])\n",
    "            slice_nmse.append(nmse_val.numpy())\n",
    "\n",
    "        # Per-volume mean\n",
    "        vol_ssim = np.mean(slice_ssim)\n",
    "        vol_psnr = np.mean(slice_psnr)\n",
    "        vol_nmse = np.mean(slice_nmse)\n",
    "\n",
    "        vol_ssim_all.append(vol_ssim)\n",
    "        vol_psnr_all.append(vol_psnr)\n",
    "        vol_nmse_all.append(vol_nmse)\n",
    "\n",
    "        vol_bar.set_postfix({\n",
    "            \"SSIM\": f\"{vol_ssim:.4f}\",\n",
    "            \"PSNR\": f\"{vol_psnr:.2f}\",\n",
    "            \"NMSE\": f\"{vol_nmse:.4f}\"\n",
    "        })\n",
    "\n",
    "    print(\"\\nüìä FINAL VOLUME-WISE METRICS\")\n",
    "    print(f\"Mean SSIM : {np.mean(vol_ssim_all):.4f}\")\n",
    "    print(f\"Mean PSNR : {np.mean(vol_psnr_all):.2f}\")\n",
    "    print(f\"Mean NMSE : {np.mean(vol_nmse_all):.4f}\")\n",
    "\n",
    "    return (\n",
    "        float(np.mean(vol_ssim_all)),\n",
    "        float(np.mean(vol_psnr_all)),\n",
    "        float(np.mean(vol_nmse_all))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177f080-5ce8-486b-a53a-ce8f51a39887",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_dmse_checkpoint(model)\n",
    "\n",
    "mean_ssim, mean_psnr, mean_nmse = evaluate_dmse_volume_wise(\n",
    "    model,\n",
    "    kspace_files_list_val\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8ef40-0588-4fc6-956e-bd2f242c40b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
