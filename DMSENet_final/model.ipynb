{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f57a23a-fffc-4236-9d34-e599ece8dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1) Weight Normalized Convolution (WNConv2D)\n",
    "# ============================================================\n",
    "class WNConv2D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, padding=\"same\", use_bias=True, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = (kernel_size, kernel_size) if isinstance(kernel_size, int) else kernel_size\n",
    "        self.strides = (strides, strides)\n",
    "        self.padding = padding.upper()\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        in_channels = int(input_shape[-1])\n",
    "        kH, kW = self.kernel_size\n",
    "\n",
    "        # v: unnormalized weights\n",
    "        self.v = self.add_weight(\n",
    "            name=\"v\",\n",
    "            shape=(kH, kW, in_channels, self.filters),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        # g: per-channel scaling\n",
    "        v_flat = tf.reshape(self.v, [-1, self.filters])\n",
    "        g_init = tf.norm(v_flat, axis=0)\n",
    "        self.g = self.add_weight(\n",
    "            name=\"g\",\n",
    "            shape=(self.filters,),\n",
    "            initializer=tf.keras.initializers.Constant(g_init.numpy()),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name=\"bias\",\n",
    "                shape=(self.filters,),\n",
    "                initializer=\"zeros\",\n",
    "                trainable=True\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def call(self, x):\n",
    "        v_flat = tf.reshape(self.v, [-1, self.filters])\n",
    "        v_norm = tf.norm(v_flat, axis=0) + 1e-8\n",
    "        w = self.v * (self.g / v_norm)\n",
    "\n",
    "        x = tf.nn.conv2d(x, w, strides=(1, *self.strides, 1), padding=self.padding)\n",
    "        if self.bias is not None:\n",
    "            x = tf.nn.bias_add(x, self.bias)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Channel Attention (CA)\n",
    "# ============================================================\n",
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.reduction = reduction\n",
    "        self.fc1 = layers.Dense(channels // reduction, activation='relu')\n",
    "        self.fc2 = layers.Dense(channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        s = tf.reduce_mean(x, axis=[1, 2])  # GAP\n",
    "        s = self.fc1(s)\n",
    "        s = self.fc2(s)\n",
    "        s = tf.reshape(s, [-1, 1, 1, self.channels])\n",
    "        return x * s\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Spatial Attention (SA)\n",
    "# ============================================================\n",
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        maxp = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        t = tf.concat([avg, maxp], axis=-1)\n",
    "        att = self.conv(t)\n",
    "        return x * att\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Wide Activation ConvBlock (WACB)\n",
    "#     EXACT structure from figure: Conv3×3 → WN → ReLU → Conv3×3 → WN → residual\n",
    "# ============================================================\n",
    "class WACB(layers.Layer):\n",
    "    def __init__(self, channels, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.channels = channels\n",
    "        self.conv1 = WNConv2D(channels, 3)\n",
    "        self.conv2 = WNConv2D(channels, 3)\n",
    "\n",
    "    def call(self, x):\n",
    "        res = x\n",
    "        out = self.conv1(x)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        #print(\"WACB\",out.shape)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Wide Activation TransBlock (WATB)\n",
    "#     EXACT: TransConv2×2 → WN → ReLU → Conv3×3 → WN → residual\n",
    "# ============================================================\n",
    "class WATB(layers.Layer):\n",
    "    def __init__(self, channels, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.channels = channels\n",
    "\n",
    "        # Transposed convolution from figure (pink block)\n",
    "        self.trans = layers.Conv2DTranspose(channels, kernel_size=2, strides=2, padding='same')\n",
    "\n",
    "        self.conv = WNConv2D(channels, 3)\n",
    "\n",
    "    def call(self, x):\n",
    "        res = x\n",
    "        out = self.trans(x)\n",
    "        out = self.conv(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        \n",
    "\n",
    "        # # match channels if needed\n",
    "        # if res.shape[-1] != self.channels:\n",
    "        #     res = WNConv2D(self.channels, 1)(res)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Hybrid Attention Block (HAB)\n",
    "# ============================================================\n",
    "class HAB(layers.Layer):\n",
    "    def __init__(self, channels, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.channels = channels\n",
    "        self.wacb = WACB(channels)\n",
    "        self.ca = ChannelAttention(channels)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.conv1x1 = WNConv2D(channels, 1)\n",
    "\n",
    "    def call(self, x):\n",
    "        h = self.wacb(x)\n",
    "\n",
    "        h_ca = self.ca(h)\n",
    "        h_sa = self.sa(h)\n",
    "\n",
    "        h_cat = tf.concat([h_ca, h_sa], axis=-1)  # concat channels\n",
    "        h_proj = self.conv1x1(h_cat)\n",
    "\n",
    "        return x + h_proj\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) SRUN (main module)\n",
    "# ============================================================\n",
    "class SRUN(layers.Layer):\n",
    "    def __init__(self, name=\"SRUN\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        # Channel widths EXACTLY from figure\n",
    "        self.ch0 = 16\n",
    "        self.ch1 = 32\n",
    "        self.ch2 = 64\n",
    "        self.ch3 = 128\n",
    "\n",
    "        # Head\n",
    "        self.wacb_head = WACB(self.ch0)\n",
    "        self.hab_head = HAB(self.ch0)\n",
    "\n",
    "        # Encoder\n",
    "        #self.enc1 = WACB(self.ch0)\n",
    "        self.pool1 = layers.AveragePooling2D(pool_size=2)\n",
    "        self.enc2 = WACB(self.ch1)\n",
    "\n",
    "        \n",
    "        self.pool2 = layers.AveragePooling2D(pool_size=2)\n",
    "        self.enc3 = WACB(self.ch2)\n",
    "\n",
    "        \n",
    "        self.pool3 = layers.AveragePooling2D(pool_size=2)\n",
    "        self.bottleneck = WACB(self.ch3)\n",
    "\n",
    "        # Bottleneck\n",
    "        \n",
    "\n",
    "        # Decoder (EXACT pink/blue pattern)\n",
    "        self.dec3_watb = WATB(self.ch2)\n",
    "        self.dec3_wacb = WACB(self.ch2)\n",
    "\n",
    "        self.dec2_watb = WATB(self.ch1)\n",
    "        self.dec2_wacb = WACB(self.ch1)\n",
    "\n",
    "        self.dec1_watb = WATB(self.ch0)\n",
    "        self.dec1_wacb = WACB(self.ch0)\n",
    "\n",
    "        # Tail\n",
    "        self.hab_tail = HAB(self.ch0)\n",
    "        self.out_conv = WNConv2D(2, 3)\n",
    "\n",
    "    def call(self, undersampled_image):\n",
    "        # -----------------------------\n",
    "        # Eq (3) & (4): Shallow + Head HAB\n",
    "        x=undersampled_image\n",
    "        # -----------------------------\n",
    "        shallow = self.wacb_head(x)     # → 16 ch\n",
    "        # print(\"shallow\",shallow.shape)\n",
    "        head = self.hab_head(shallow)   # → 16 ch\n",
    "        # print(\"head\",head.shape)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Encoder (with skips)\n",
    "        # -----------------------------\n",
    "        #e1 = self.enc1(head)        # 16\n",
    "        p1 = self.pool1(head)\n",
    "        e2 = self.enc2(p1) # 32\n",
    "        # print(\"p1\",p1.shape)\n",
    "        # print(\"e2\",e2.shape)\n",
    "        \n",
    "\n",
    "                  \n",
    "        p2 = self.pool2(e2)\n",
    "        e3 = self.enc3(p2)          # 64\n",
    "        # print(\"p2\",p2.shape)\n",
    "        # print(\"e3\",e3.shape)\n",
    "\n",
    "        p3 = self.pool3(e3)\n",
    "        b = self.bottleneck(p3)\n",
    "        # print(\"p3\",p3.shape)\n",
    "        # print(\"b\",b.shape)\n",
    "\n",
    "        # Bottleneck\n",
    "             # 128\n",
    "\n",
    "        # -----------------------------\n",
    "        # Decoder (mirror)\n",
    "        # -----------------------------\n",
    "        # Level 3\n",
    "        d3 = self.dec3_watb(b)\n",
    "        # print(\"d3\",d3.shape)\n",
    "        d3 = tf.concat([d3, e3], axis=-1)\n",
    "        # print(\"d3\",d3.shape)\n",
    "        d3 = self.dec3_wacb(d3)     # 64\n",
    "        # print(\"d3\",d3.shape)\n",
    "        # Level 2\n",
    "        d2 = self.dec2_watb(d3)\n",
    "        # print(\"d2\",d2.shape)\n",
    "        d2 = tf.concat([d2, e2], axis=-1)\n",
    "        # print(\"d2\",d2.shape)\n",
    "        d2 = self.dec2_wacb(d2)     # 32\n",
    "        # print(\"d2\",d2.shape)\n",
    "        # Level 1\n",
    "        d1 = self.dec1_watb(d2)\n",
    "        # print(\"d1\",d1.shape)\n",
    "        d1 = tf.concat([d1, head], axis=-1)\n",
    "        # print(\"d1\",d1.shape)\n",
    "        d1 = self.dec1_wacb(d1)     # 16\n",
    "        # print(\"d1\",d1.shape)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Tail HAB\n",
    "        # -----------------------------\n",
    "        out_feat = self.hab_tail(d1)\n",
    "        # print(\"out_feat\",out_feat.shape)\n",
    "\n",
    "        # Final projection → 2 channels\n",
    "        out = self.out_conv(out_feat)\n",
    "        # print(\"out\",out.shape)\n",
    "\n",
    "        return shallow, out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Test SRUN correctness\n",
    "# # ============================================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = np.random.randn(1, 256, 256, 2).astype(np.float32)\n",
    "#     srun = SRUN()\n",
    "#     y = srun(x)\n",
    "#     #print(\"Output shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7640b9-0070-4767-91b2-36a31c0213f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "class DRCM(layers.Layer):\n",
    "    \"\"\"\n",
    "    Detail Representation Construction Module (DRCM)\n",
    "    Uses fixed Sobel edge detectors + standard Conv2D(3x3).\n",
    "    \"\"\"\n",
    "    def __init__(self, out_channels=2, name=\"DRCM\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "       # Final convolution (standard)\n",
    "        self.proj = layers.Conv2D(out_channels, kernel_size=3, padding='same', name=name+\"_conv\")\n",
    "\n",
    "        # Sobel filters\n",
    "        sobel_x = np.array([[ -1., 0., 1.],\n",
    "                            [ -2., 0., 2.],\n",
    "                            [ -1., 0., 1.]], dtype=np.float32)\n",
    "        sobel_y = np.array([[ -1., -2., -1.],\n",
    "                            [  0.,  0.,  0.],\n",
    "                            [  1.,  2.,  1.]], dtype=np.float32)\n",
    "\n",
    "        self.sobel_x = tf.constant(sobel_x.reshape(3,3,1,1), dtype=tf.float32)\n",
    "        self.sobel_y = tf.constant(sobel_y.reshape(3,3,1,1), dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        real = x[..., 0:1]\n",
    "        imag = x[..., 1:2]\n",
    "\n",
    "        # Real magnitude\n",
    "        Gx_r = tf.nn.conv2d(real, self.sobel_x, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        Gy_r = tf.nn.conv2d(real, self.sobel_y, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        G_real = tf.sqrt(Gx_r**2 + Gy_r**2 + 1e-12)\n",
    "\n",
    "        # Imag magnitude\n",
    "        Gx_i = tf.nn.conv2d(imag, self.sobel_x, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        Gy_i = tf.nn.conv2d(imag, self.sobel_y, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        G_imag = tf.sqrt(Gx_i**2 + Gy_i**2 + 1e-12)\n",
    "\n",
    "        G_cat = tf.concat([G_real, G_imag], axis=-1)\n",
    "\n",
    "        # Standard 3×3 conv (per figure + eq.(8))\n",
    "        D0 = self.proj(G_cat)\n",
    "\n",
    "        return D0\n",
    "# if __name__ == \"__main__\":\n",
    "#     # dummy zero-filled example (batch 1, 128x128, 2 channels)\n",
    "#     inp = np.random.randn(1,320,320,2).astype(np.float32)\n",
    "#     drcm = DRCM(out_channels=2)\n",
    "#     out = drcm(inp)\n",
    "#     print(\"DRCM input shape:\", inp.shape)\n",
    "#     print(\"DRCM output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4951b-e29a-4913-9abe-ef32a3754079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acaa65f8-6f89-4f63-8555-6019dc06bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class LRDB(layers.Layer):\n",
    "    \"\"\"\n",
    "    Lite Residual Dense Block (faithful to figure):\n",
    "      - 4 conv3x3 layers with channel pattern: 32 -> 16 -> 32 -> 16\n",
    "      - Dense-style concatenation: each conv input = concat(original_input + previous outputs)\n",
    "      - Final 1x1 conv (bottleneck) to project concatenated intermediates back to 'out_channels' (default 16)\n",
    "      - Local residual: output = input + bottleneck_proj\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=16, out_channels=16, name=\"LRDB\"):\n",
    "        super().__init__(name=name)\n",
    "        # convs use the filters seen in the figure\n",
    "        self.conv1 = layers.Conv2D(32, 3, padding='same', activation='relu', name=name+\"_c1\")\n",
    "        self.conv2 = layers.Conv2D(16, 3, padding='same', activation='relu', name=name+\"_c2\")\n",
    "        self.conv3 = layers.Conv2D(32, 3, padding='same', activation='relu', name=name+\"_c3\")\n",
    "        self.conv4 = layers.Conv2D(16, 3, padding='same', activation='relu', name=name+\"_c4\")\n",
    "\n",
    "        # bottleneck: project concatenated features back to out_channels\n",
    "        # The concatenation will be of [y1,y2,y3,y4] => channels = 32+16+32+16 = 96\n",
    "        self.bottleneck = layers.Conv2D(out_channels, 1, padding='same', name=name+\"_bottleneck\")\n",
    "\n",
    "    def call(self, x):\n",
    "        # x shape: (B,H,W,C) where C is typically 16 in the DFRM usage\n",
    "        y1 = self.conv1(x)                          # -> 32\n",
    "        #print(\"y1\",y1.shape)\n",
    "        y1_con=tf.concat([x, y1], axis=-1)\n",
    "        #print(\"y1_con\",y1_con.shape)\n",
    "        y2 = self.conv2(y1_con)  # -> 16\n",
    "        #print(\"y2\",y2.shape)\n",
    "\n",
    "        y2_con = x + y2\n",
    "        #print(\"y2_con\",y2_con.shape)\n",
    "        y3 = self.conv3(y2_con)  # -> 32\n",
    "        #print(\"y3\",y3.shape)\n",
    "\n",
    "        y3_con=tf.concat([ y2_con, y3], axis=-1)\n",
    "        #print(\"y3_con\",y3_con.shape)\n",
    "        y4 = self.conv4(y3_con)  # -> 16\n",
    "        #print(\"y4\",y4.shape)\n",
    "        # concat intermediates and bottleneck-project\n",
    "        out = x+y2_con+y4  # channels = 96\n",
    "        #print(\"out\",out.shape)\n",
    "        #out = self.bottleneck(concat_feats)                  # -> out_channels (e.g., 16)\n",
    "\n",
    "        # # local residual\n",
    "        # # If input channels != out_channels, project input accordingly before add\n",
    "        # if x.shape[-1] != out.shape[-1]:\n",
    "        #     x_proj = layers.Conv2D(out.shape[-1], 1, padding='same')(x)\n",
    "        #     return x_proj + out\n",
    "        # else:\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f6101c-deea-42ef-9beb-4f17169175f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     import numpy as np\n",
    "#     lrdb = LRDB(in_channels=16, out_channels=16)\n",
    "#     x = np.random.randn(1, 128, 128, 16).astype('float32')\n",
    "#     y = lrdb(x)\n",
    "#     print(\"LRDB out shape:\", y.shape)  # expect (1,128,128,16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ad3b48b-79a1-49d0-8c03-4ad7a4f5ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DFRM (Detail Feature Refinement Module)\n",
    "# ============================================================\n",
    "class DFRM(layers.Layer):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        D_in  : detail input     (B,H,W,16)\n",
    "        S_shallow : shallow structure features from SRUN (B,H,W,16)\n",
    "\n",
    "    Outputs:\n",
    "        D_out : refined detail output (B,H,W,16)\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=16, name=\"DFRM\"):\n",
    "        super().__init__(name=name)\n",
    "        self.channels = channels\n",
    "\n",
    "        # Eq (9) — Extract shallow detail features\n",
    "        self.conv_shallow = layers.Conv2D(channels, 3, padding='same')\n",
    "\n",
    "        # Eq (10) — WACB fused head\n",
    "        self.wacb_head = WACB(channels)\n",
    "\n",
    "        # Feature refinement body (LRDB + Conv1×1 + LRDB + Conv1×1 + CA)\n",
    "        self.lrd1 = LRDB(channels)\n",
    "        self.ca = ChannelAttention(channels)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(channels, 1, padding='same')\n",
    "        self.lrd2 = LRDB(channels)\n",
    "        self.conv2 = layers.Conv2D(channels, 1, padding='same')\n",
    "\n",
    "        # Channel attention (pink block)\n",
    "        \n",
    "\n",
    "        # Tail WACB (Eq 12)\n",
    "        self.wacb_tail = WACB(channels)\n",
    "\n",
    "        # Final output conv (Eq 13)\n",
    "        self.conv_out = layers.Conv2D(channels, 3, padding='same')\n",
    "        self.dfrm_final = layers.Conv2D(2, 1, padding='same', name=name+\"_DFRM_1x1\")\n",
    "\n",
    "    def call(self, D_in, S_shallow):\n",
    "        # -----------------------------\n",
    "        # (1) Shallow detail features\n",
    "        # -----------------------------\n",
    "        D_shallow = self.conv_shallow(D_in)   # Eq (9)\n",
    "\n",
    "        # -----------------------------\n",
    "        # (2) Concatenate with S_shallow → WACB head\n",
    "        # -----------------------------\n",
    "        fused = tf.concat([D_shallow, S_shallow], axis=-1)\n",
    "        D_head = self.wacb_head(fused)        # Eq (10)\n",
    "\n",
    "        # -----------------------------\n",
    "        # (3) Feature refinement body\n",
    "        # -----------------------------\n",
    "        lrd_1 = self.lrd1(D_head)\n",
    "        att = self.ca(D_head)\n",
    "        lrdb1_con=tf.concat([lrd_1, att], axis=-1)\n",
    "        \n",
    "        c_1 = self.conv1(lrdb1_con)\n",
    "\n",
    "        lrd_2 = self.lrd2(c_1)\n",
    "        lrdb2_con=tf.concat([lrd_2, att], axis=-1)\n",
    "        h = self.conv2(lrdb2_con)\n",
    "        D_tail = self.wacb_tail(h) \n",
    "\n",
    "        # channel attention applied to D_head (source-shared)\n",
    "        \n",
    "\n",
    "        # -----------------------------\n",
    "        D_sum = D_shallow + D_tail\n",
    "\n",
    "        # final output convolution (Eq 13)\n",
    "        D_out_pre = self.conv_out(D_sum)\n",
    "        D_out=self.dfrm_final(D_out_pre)\n",
    "        \n",
    "\n",
    "        return D_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc52d16e-6ea1-4621-96ff-428889b8f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ------------------------\n",
    "# Instance Normalization\n",
    "# ------------------------\n",
    "class InstanceNorm(layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5, name=\"InstanceNorm\"):\n",
    "        super().__init__(name=name)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        ch = int(input_shape[-1])\n",
    "        self.gamma = self.add_weight(shape=(ch,),\n",
    "                                     initializer=\"ones\",\n",
    "                                     trainable=True,\n",
    "                                     name=\"gamma\")\n",
    "        self.beta = self.add_weight(shape=(ch,),\n",
    "                                    initializer=\"zeros\",\n",
    "                                    trainable=True,\n",
    "                                    name=\"beta\")\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, var = tf.nn.moments(x, axes=[1,2], keepdims=True)\n",
    "        x_norm = (x - mean) / tf.sqrt(var + self.epsilon)\n",
    "        return self.gamma * x_norm + self.beta\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Memory-safe, adaptive DGFM\n",
    "# ------------------------\n",
    "class DGFM(layers.Layer):\n",
    "    \"\"\"\n",
    "    Detail Guided Fusion Module (memory-safe and adaptive).\n",
    "\n",
    "    This implementation:\n",
    "      - Infers channel count from inputs (works for 2 or 16 etc).\n",
    "      - Computes attention on a reduced spatial grid only when needed, to avoid OOM.\n",
    "      - Uses conv 1x1 for query/key/value applied to appropriate tensors:\n",
    "          * query, key <- D_out\n",
    "          * value        <- F_input = D_out + S_out\n",
    "      - Applies InstanceNorm to the attention-activated output, then adds a global skip.\n",
    "\n",
    "    Args:\n",
    "      max_attn_elements: maximum allowed H*W for attention matrix (default 4096).\n",
    "                         This controls when downsampling is applied. 4096 => ~64x64 attention.\n",
    "      name: layer name\n",
    "    \"\"\"\n",
    "    def __init__(self, max_attn_elements=4096, name=\"DGFM\"):\n",
    "        super().__init__(name=name)\n",
    "        self.max_attn_elements = int(max_attn_elements)\n",
    "        self.IN = InstanceNorm(name=name + \"/IN\")\n",
    "\n",
    "        # conv layers will be created lazily in build() because we need input channel count\n",
    "        self.conv_query = None\n",
    "        self.conv_key = None\n",
    "        self.conv_value = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape is [S_out_shape, D_out_shape] or we will infer in call\n",
    "        # We don't rely on build input_shape here; layer convs are created in call when channels known.\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def _make_conv_layers(self, channels):\n",
    "        # Create 1x1 convs for query/key/value if not already created\n",
    "        if self.conv_query is None:\n",
    "            self.conv_query = layers.Conv2D(channels, kernel_size=1, padding='same', name=self.name + \"/conv_q\")\n",
    "            self.conv_key   = layers.Conv2D(channels, kernel_size=1, padding='same', name=self.name + \"/conv_k\")\n",
    "            self.conv_value = layers.Conv2D(channels, kernel_size=1, padding='same', name=self.name + \"/conv_v\")\n",
    "\n",
    "    def _compute_reduced_size(self, H, W):\n",
    "        \"\"\"\n",
    "        Compute an integer reduced size (new_H, new_W) such that\n",
    "        new_H * new_W <= self.max_attn_elements, preserving roughly the aspect ratio.\n",
    "        H, W are tf.Tensor (ints).\n",
    "        \"\"\"\n",
    "        HW = tf.cast(H, tf.int64) * tf.cast(W, tf.int64)\n",
    "        maxE = tf.cast(self.max_attn_elements, tf.int64)\n",
    "\n",
    "        # If HW <= maxE, no reduction\n",
    "        def no_downsample():\n",
    "            return H, W\n",
    "\n",
    "        def do_downsample():\n",
    "            # scale = ceil(sqrt(HW / maxE))\n",
    "            ratio = tf.cast(HW, tf.float32) / tf.cast(maxE, tf.float32)\n",
    "            ratio = tf.math.maximum(ratio, 1.0)\n",
    "            scale = tf.math.ceil(tf.math.sqrt(ratio))\n",
    "            # new_H = ceil(H / scale), new_W = ceil(W / scale)\n",
    "            new_H = tf.cast(tf.math.ceil(tf.cast(H, tf.float32) / scale), tf.int32)\n",
    "            new_W = tf.cast(tf.math.ceil(tf.cast(W, tf.float32) / scale), tf.int32)\n",
    "            # Ensure minimum 1\n",
    "            new_H = tf.maximum(new_H, 1)\n",
    "            new_W = tf.maximum(new_W, 1)\n",
    "            return new_H, new_W\n",
    "\n",
    "        new_H, new_W = tf.cond(HW <= maxE, no_downsample, do_downsample)\n",
    "        return new_H, new_W\n",
    "\n",
    "    def call(self, S_out, D_out):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          S_out: structure output tensor, shape (B, H, W, C)\n",
    "          D_out: detail output tensor,    shape (B, H, W, C)\n",
    "        Returns:\n",
    "          F_out: fused tensor, same shape (B, H, W, C)\n",
    "        \"\"\"\n",
    "        # Validate shapes\n",
    "        # Ensure same spatial and channel dims\n",
    "        s_shape = tf.shape(S_out)\n",
    "        d_shape = tf.shape(D_out)\n",
    "        # (B,H,W,C) expected\n",
    "        # If channels differ, raise error\n",
    "        C_s = s_shape[-1]\n",
    "        C_d = d_shape[-1]\n",
    "        tf.debugging.assert_equal(C_s, C_d, message=\"S_out and D_out must have the same channel count\")\n",
    "\n",
    "        # Fused input (Eq 14)\n",
    "        F_input = S_out + D_out  # (B, H, W, C)\n",
    "\n",
    "        B = s_shape[0]\n",
    "        H = s_shape[1]\n",
    "        W = s_shape[2]\n",
    "        C = C_s  # number of channels (inferred)\n",
    "\n",
    "        # Create convs if needed with 'C' filters (1x1 convs)\n",
    "        # Use python int if statically known, else use C (tensor), but layers require integer - try to get static\n",
    "        static_C = S_out.shape[-1]\n",
    "        channels_for_conv = int(static_C) if static_C is not None else None\n",
    "        if channels_for_conv is not None:\n",
    "            self._make_conv_layers(channels_for_conv)\n",
    "        else:\n",
    "            # shape unknown at graph build - create convs with C by casting to int via tf.get_static_value not available here\n",
    "            # fallback: create with filters=0? Not allowed. So create lazily using first call with dynamic channel via build.\n",
    "            # Here we'll construct using a small trick: create convs with channels= C by converting to int in python if possible\n",
    "            # Practically, in most TF/Keras setups channels are known; if not, calling .build later will succeed.\n",
    "            # We ensure convs exist by reusing default size 8 then re-wrapping - but to keep correctness, require static channels.\n",
    "            raise ValueError(\"DGFM requires known channel dimension at graph build time. Make sure channel dimension is statically defined.\")\n",
    "\n",
    "        # Decide reduced spatial size to keep attention matrix <= max_attn_elements\n",
    "        new_H, new_W = self._compute_reduced_size(H, W)  # tf.int32\n",
    "\n",
    "        # If new_H == H and new_W == W -> compute attention at full resolution (safe)\n",
    "        full_res = tf.logical_and(tf.equal(new_H, H), tf.equal(new_W, W))\n",
    "\n",
    "        def _attend_at_full_res():\n",
    "            D_q = self.conv_query(D_out)\n",
    "            D_k = self.conv_key(D_out)\n",
    "            F_v = self.conv_value(F_input)\n",
    "            return D_q, D_k, F_v, H, W  # return original sizes\n",
    "\n",
    "        def _attend_at_reduced_res():\n",
    "            # Resize (bilinear) down\n",
    "            # use tf.image.resize which expects float32\n",
    "            D_small = tf.image.resize(D_out, size=(new_H, new_W), method=\"bilinear\", antialias=True)\n",
    "            F_small = tf.image.resize(F_input, size=(new_H, new_W), method=\"bilinear\", antialias=True)\n",
    "            D_q = self.conv_query(D_small)\n",
    "            D_k = self.conv_key(D_small)\n",
    "            F_v = self.conv_value(F_small)\n",
    "            return D_q, D_k, F_v, new_H, new_W\n",
    "\n",
    "        D_q, D_k, F_v, Hs, Ws = tf.cond(full_res, _attend_at_full_res, _attend_at_reduced_res)\n",
    "\n",
    "        # Flatten spatial dims: (B, Hs*Ws, C)\n",
    "        HW_small = Hs * Ws\n",
    "        Q = tf.reshape(D_q, [B, HW_small, C])\n",
    "        K = tf.reshape(D_k, [B, HW_small, C])\n",
    "        V = tf.reshape(F_v, [B, HW_small, C])\n",
    "\n",
    "        # Attention logits: (B, HW_small, HW_small)\n",
    "        att_logits = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        # Softmax along last axis (for each query position)\n",
    "        att_map = tf.nn.softmax(att_logits, axis=-1)\n",
    "\n",
    "        # Apply attention: (B, HW_small, C)\n",
    "        F_active_flat = tf.matmul(att_map, V)\n",
    "\n",
    "        # Reshape back to spatial (B, Hs, Ws, C)\n",
    "        F_active_small = tf.reshape(F_active_flat, [B, Hs, Ws, C])\n",
    "\n",
    "        # If we computed on reduced size, upsample back to original H,W\n",
    "        F_active = tf.image.resize(F_active_small, size=(H, W), method=\"bilinear\", antialias=True)\n",
    "\n",
    "        # InstanceNorm then global skip (Eq 18)\n",
    "        F_active_norm = self.IN(F_active)\n",
    "        F_out = F_input + F_active_norm\n",
    "\n",
    "        return F_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de56e0dd-bf25-4d5b-917f-b7449d7135b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "def cascade_block(F_in, D_in, srun, dfrm, dfgm, dc=None, zf=None, name=\"Cascade\"):\n",
    "    with tf.name_scope(name):\n",
    "        # SRUN\n",
    "        shallow, S = srun(F_in)\n",
    "\n",
    "        # DFRM\n",
    "        D_out = dfrm(D_in, shallow)\n",
    "\n",
    "        # DGFM\n",
    "        F_out = dfgm(S, D_out)\n",
    "\n",
    "        # DC (optional)\n",
    "        if dc is not None:\n",
    "            F_out = dc(F_out, zf)\n",
    "\n",
    "        return F_out, D_out\n",
    "\n",
    "def build_DSMENet_functional(\n",
    "        N=4, M=1, T=2,\n",
    "        H=256, W=256, C=2,\n",
    "        DC_cls=None\n",
    "):\n",
    "    inp = Input(shape=(H, W, C), name=\"input_image\")\n",
    "    zf_in = Input(shape=(H, W, C), name=\"zf_image\") if DC_cls else None\n",
    "\n",
    "    # -------------------------------------\n",
    "    # INITIAL DRCM\n",
    "    # -------------------------------------\n",
    "    DRCM_init = DRCM(out_channels=2, name=\"DRCM_initial\")\n",
    "    D = DRCM_init(inp)\n",
    "    F = inp\n",
    "\n",
    "    # -------------------------------------\n",
    "    # FIRST M CASCADES (unique)\n",
    "    # -------------------------------------\n",
    "    for i in range(M):\n",
    "        srun = SRUN(name=f\"SRUN_{i+1}\")\n",
    "        dfrm = DFRM(channels=16, name=f\"DFRM_{i+1}\")\n",
    "        dfgm = DGFM(name=f\"DGFM_{i+1}\")\n",
    "        dc = DC_cls(name=f\"DC_{i+1}\") if DC_cls else None\n",
    "\n",
    "        F, D = cascade_block(\n",
    "            F, D,\n",
    "            srun, dfrm, dfgm,\n",
    "            dc=dc, zf=zf_in,\n",
    "            name=f\"Cascade_{i+1}\"\n",
    "        )\n",
    "\n",
    "    # Save output of first cascade → for ERC\n",
    "    F_M = F\n",
    "\n",
    "    # -------------------------------------\n",
    "    # SHARED CASCADES (M+1...N)\n",
    "    # -------------------------------------\n",
    "    shared_srun = SRUN(name=\"SRUN_shared\")\n",
    "    shared_dfrm = DFRM(channels=16, name=\"DFRM_shared\")\n",
    "    shared_dfgm = DGFM(name=\"DGFM_shared\")\n",
    "    shared_dc = DC_cls(name=\"DC_shared\") if DC_cls else None\n",
    "\n",
    "    for t in range(T):  # ERR\n",
    "        F_temp, D_temp = F, D\n",
    "        for j in range(N - M):\n",
    "            F_temp, D_temp = cascade_block(\n",
    "                F_temp, D_temp,\n",
    "                shared_srun, shared_dfrm, shared_dfgm,\n",
    "                dc=shared_dc, zf=zf_in,\n",
    "                name=f\"SharedCascade_round{t+1}_{j+1}\"\n",
    "            )\n",
    "        F, D = F_temp, D_temp\n",
    "\n",
    "    F_final = F\n",
    "\n",
    "    # -------------------------------------\n",
    "    # MODEL OUTPUT: MUST RETURN BOTH\n",
    "    # -------------------------------------\n",
    "    if DC_cls:\n",
    "        return Model([inp, zf_in], [F_M, F_final], name=\"DSMENet_Functional\")\n",
    "    else:\n",
    "        return Model(inp, [F_M, F_final], name=\"DSMENet_Functional\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4b25288-5b0d-4622-bc09-d5f24492ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DSMENet_Functional\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 256, 256, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " SRUN_1 (SRUN)                  ((None, 256, 256, 1  542204      ['input_image[0][0]']            \n",
      "                                6),                                                               \n",
      "                                 (None, 256, 256, 2                                               \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " DRCM_initial (DRCM)            (None, 256, 256, 2)  38          ['input_image[0][0]']            \n",
      "                                                                                                  \n",
      " DFRM_1 (DFRM)                  (None, 256, 256, 2)  61683       ['DRCM_initial[0][0]',           \n",
      "                                                                  'SRUN_1[0][0]']                 \n",
      "                                                                                                  \n",
      " DGFM_1 (DGFM)                  (None, 256, 256, 2)  22          ['SRUN_1[0][1]',                 \n",
      "                                                                  'DFRM_1[0][0]']                 \n",
      "                                                                                                  \n",
      " SRUN_shared (SRUN)             ((None, 256, 256, 1  542204      ['DGFM_1[0][0]',                 \n",
      "                                6),                               'DGFM_shared[0][0]',            \n",
      "                                 (None, 256, 256, 2               'DGFM_shared[1][0]',            \n",
      "                                ))                                'DGFM_shared[2][0]',            \n",
      "                                                                  'DGFM_shared[3][0]',            \n",
      "                                                                  'DGFM_shared[4][0]']            \n",
      "                                                                                                  \n",
      " DFRM_shared (DFRM)             (None, 256, 256, 2)  61683       ['DFRM_1[0][0]',                 \n",
      "                                                                  'SRUN_shared[0][0]',            \n",
      "                                                                  'DFRM_shared[0][0]',            \n",
      "                                                                  'SRUN_shared[1][0]',            \n",
      "                                                                  'DFRM_shared[1][0]',            \n",
      "                                                                  'SRUN_shared[2][0]',            \n",
      "                                                                  'DFRM_shared[2][0]',            \n",
      "                                                                  'SRUN_shared[3][0]',            \n",
      "                                                                  'DFRM_shared[3][0]',            \n",
      "                                                                  'SRUN_shared[4][0]',            \n",
      "                                                                  'DFRM_shared[4][0]',            \n",
      "                                                                  'SRUN_shared[5][0]']            \n",
      "                                                                                                  \n",
      " DGFM_shared (DGFM)             (None, 256, 256, 2)  22          ['SRUN_shared[0][1]',            \n",
      "                                                                  'DFRM_shared[0][0]',            \n",
      "                                                                  'SRUN_shared[1][1]',            \n",
      "                                                                  'DFRM_shared[1][0]',            \n",
      "                                                                  'SRUN_shared[2][1]',            \n",
      "                                                                  'DFRM_shared[2][0]',            \n",
      "                                                                  'SRUN_shared[3][1]',            \n",
      "                                                                  'DFRM_shared[3][0]',            \n",
      "                                                                  'SRUN_shared[4][1]',            \n",
      "                                                                  'DFRM_shared[4][0]',            \n",
      "                                                                  'SRUN_shared[5][1]',            \n",
      "                                                                  'DFRM_shared[5][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,207,856\n",
      "Trainable params: 1,207,856\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_DSMENet_functional(N=4, M=1, T=2)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba47c462-eb3e-44fd-be21-b08722b296d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRUN output shape: (1, 256, 256, 2)\n",
      "DRCM output shape: (1, 256, 256, 2)\n",
      "DFRM output shape: (1, 256, 256, 2)\n",
      "DFGM output shape: (1, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "class DMSENet(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Wrapper model:\n",
    "        Input: undersampled image  (B,H,W,2)\n",
    "        Output:\n",
    "            S0 = SRUN output (structure-dominated representation)\n",
    "            D0 = DRCM output (initial detail representation)\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"DMSENet\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.srun = SRUN(name=\"SRUN\")\n",
    "        self.drcm = DRCM(out_channels=2, name=\"DRCM\")\n",
    "        self.dfrm=DFRM(channels=16)\n",
    "        self.dfgm=DGFM()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x: undersampled image (B,H,W,2)\n",
    "        returns: (structure_output, detail_output)\n",
    "        \"\"\"\n",
    "        shallow,S0 = self.srun(x)   # structure reconstruction\n",
    "        D0 = self.drcm(x)   # detail representation construction\n",
    "        D_out =self.dfrm(D0,shallow)\n",
    "        dfgm_out=self.dfgm(S0,D_out)\n",
    "        return S0, D0, D_out,dfgm_out\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# Dummy input (batch=1, 256×256, 2 channels)\n",
    "inp = tf.random.normal([1, 256, 256, 2])\n",
    "\n",
    "model = DMSENet()\n",
    "S0, D0,DF,dfgm_out = model(inp)\n",
    "\n",
    "print(\"SRUN output shape:\", S0.shape)\n",
    "print(\"DRCM output shape:\", D0.shape)\n",
    "print(\"DFRM output shape:\", DF.shape)\n",
    "print(\"DFGM output shape:\", dfgm_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a618506-5ffe-48fa-9f4b-6c8b713b3342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad951df-a880-437a-82fb-c32c861b4598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
