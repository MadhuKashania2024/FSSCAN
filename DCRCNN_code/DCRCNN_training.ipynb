{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e936b9-7232-443e-9e8a-6d0392f5a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dbc21ba-ab1e-4cd6-81d8-672670e027d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og shape: (1, 1, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "mask = np.load(r\"C:\\Users\\DU\\aman_fastmri\\Data\\mask_4x_320_random.npy\")  # Shape: (1, 320, 320)\n",
    "print(\"og shape:\", mask.shape)\n",
    "\n",
    "# # Use np.tile to reshape it to (1, 320, 320, 1)\n",
    "# # var_sampling_mask = np.tile(var_sampling_mask[..., np.newaxis], (1, 1, 1, 1))  # Final shape: (1, 320, 320, 1)\n",
    "# mask = np.tile(mask, (1, 320, 1, 2))  # tile height=320 times\n",
    "\n",
    "# # Confirm final shape\n",
    "# print(\"New shape:\", mask.shape) \n",
    "# mask_for_plot = np.squeeze(mask[...,0])  # Shape: (320, 320)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(mask_for_plot, cmap='gray')\n",
    "# plt.title(\"Tiled Sampling Mask (320x320)\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fad8987-86b0-40f4-979e-34f9fa2b8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "class MRISliceGeneratorMag(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Data generator for magnitude-only MRI reconstruction.\n",
    "\n",
    "    Input  : undersampled magnitude image  (B, H, W, 1)\n",
    "    Target : fully-sampled magnitude image (B, H, W, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_list, batch_size=4, shuffle=True):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.slice_index_map = []\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        for file_idx, file_path in enumerate(self.file_list):\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                num_slices = f['image_under'].shape[0]\n",
    "                for slice_idx in range(num_slices):\n",
    "                    self.slice_index_map.append((file_idx, slice_idx))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.slice_index_map) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_map = self.slice_index_map[\n",
    "            index * self.batch_size : (index + 1) * self.batch_size\n",
    "        ]\n",
    "\n",
    "        input_mag_batch = []\n",
    "        target_mag_batch = []\n",
    "\n",
    "        for file_idx, slice_idx in batch_map:\n",
    "            with h5py.File(self.file_list[file_idx], 'r') as f:\n",
    "                img_under = f['image_under'][slice_idx]  # (H, W, 2)\n",
    "                img_full  = f['image_full'][slice_idx]   # (H, W, 2)\n",
    "\n",
    "                # Convert to complex\n",
    "                img_under_c = to_complex(img_under)\n",
    "                img_full_c  = to_complex(img_full)\n",
    "\n",
    "                # Magnitude\n",
    "                img_under_mag = np.abs(img_under_c)\n",
    "                img_full_mag  = np.abs(img_full_c)\n",
    "\n",
    "                input_mag_batch.append(img_under_mag)\n",
    "                target_mag_batch.append(img_full_mag)\n",
    "\n",
    "        # Stack and add channel dimension\n",
    "        x_batch = np.stack(input_mag_batch, axis=0)[..., np.newaxis]  # (B, H, W, 1)\n",
    "        y_batch = np.stack(target_mag_batch, axis=0)[..., np.newaxis] # (B, H, W, 1)\n",
    "\n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.slice_index_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3febe028-3e5b-495d-80a1-31fa79114195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\train_norm\"\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c0fa50-26bb-4ef6-962b-ddaef27463cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4338\n",
      "1784\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "kspace_files_list_train = sorted(glob.glob(os.path.join(train_folder, \"*.h5\")))\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "\n",
    "# half_train = 20\n",
    "# half_val = 10\n",
    "half_train = len(kspace_files_list_train) \n",
    "half_val = len(kspace_files_list_val) \n",
    "# print(\"half_train\",half_train)\n",
    "# print(\"half_val\",half_val)\n",
    "kspace_files_list_train = kspace_files_list_train[:half_train]\n",
    "kspace_files_list_val = kspace_files_list_val[:half_val]\n",
    "\n",
    "# Create generators\n",
    "# train_gen = MRISliceGeneratorMag(kspace_files_list_train,batch_size=4, shuffle=True,mask=mask)\n",
    "# val_gen = MRISliceGeneratorMag(kspace_files_list_val, batch_size=4, shuffle=False,mask=mask)\n",
    "train_gen = MRISliceGeneratorMag(kspace_files_list_train,batch_size=8, shuffle=True)\n",
    "val_gen = MRISliceGeneratorMag(kspace_files_list_val, batch_size=4, shuffle=False)\n",
    "\n",
    "print(len(train_gen))  \n",
    "print(len(val_gen))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7ab52d-ea9c-44a0-a8e2-b434fde50c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DCRCNN.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95f7e68-86e6-4c31-8e1e-73ce6602e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß TRAINING CONFIGURATION\n",
      "============================================================\n",
      " Save Directory:       ./SavedModels_DCRCNN_full\n",
      " Model Dimensions:     320x320\n",
      " Epochs:               50\n",
      " Learning Rate:        0.0001\n",
      " Init Checkpoint:      ./SavedModels_DCRCNN_full\\init_ckpt\n",
      " Best Checkpoint:      ./SavedModels_DCRCNN_full\\best_ckpt\n",
      " Final Checkpoint:     ./SavedModels_DCRCNN_full\\final_ckpt\n",
      "============================================================\n",
      "‚ÑπÔ∏è No checkpoint found. Training from scratch.\n",
      "\n",
      "üöÄ STARTING TRAINING...\n",
      "============================================================\n",
      "Epoch 1/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 0.0017      \n",
      "Epoch 1: val_loss improved from inf to 0.00059, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2717s 624ms/step - loss: 0.0017 - val_loss: 5.8512e-04 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 5.5709e-04   \n",
      "Epoch 2: val_loss improved from 0.00059 to 0.00056, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2710s 625ms/step - loss: 5.5709e-04 - val_loss: 5.5656e-04 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 5.3383e-04   \n",
      "Epoch 3: val_loss improved from 0.00056 to 0.00053, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2711s 625ms/step - loss: 5.3383e-04 - val_loss: 5.3248e-04 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 5.1789e-04   \n",
      "Epoch 4: val_loss improved from 0.00053 to 0.00052, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2710s 625ms/step - loss: 5.1789e-04 - val_loss: 5.1973e-04 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.9602e-04   \n",
      "Epoch 5: val_loss improved from 0.00052 to 0.00051, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2715s 626ms/step - loss: 4.9602e-04 - val_loss: 5.0883e-04 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.8042e-04   \n",
      "Epoch 6: val_loss improved from 0.00051 to 0.00049, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2708s 624ms/step - loss: 4.8042e-04 - val_loss: 4.9403e-04 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.7074e-04   \n",
      "Epoch 7: val_loss improved from 0.00049 to 0.00049, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2709s 625ms/step - loss: 4.7074e-04 - val_loss: 4.8595e-04 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.6147e-04   \n",
      "Epoch 8: val_loss improved from 0.00049 to 0.00048, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2714s 626ms/step - loss: 4.6147e-04 - val_loss: 4.8392e-04 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.5506e-04   \n",
      "Epoch 9: val_loss improved from 0.00048 to 0.00047, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2709s 625ms/step - loss: 4.5506e-04 - val_loss: 4.7000e-04 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.4912e-04   \n",
      "Epoch 10: val_loss improved from 0.00047 to 0.00047, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2710s 625ms/step - loss: 4.4912e-04 - val_loss: 4.6568e-04 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.4456e-04   \n",
      "Epoch 11: val_loss did not improve from 0.00047\n",
      "4338/4338 [==============================] - 2714s 626ms/step - loss: 4.4456e-04 - val_loss: 4.7397e-04 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.4073e-04   \n",
      "Epoch 12: val_loss improved from 0.00047 to 0.00046, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2711s 625ms/step - loss: 4.4073e-04 - val_loss: 4.5781e-04 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.3814e-04   \n",
      "Epoch 13: val_loss improved from 0.00046 to 0.00046, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2715s 626ms/step - loss: 4.3814e-04 - val_loss: 4.5519e-04 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.3469e-04   \n",
      "Epoch 14: val_loss did not improve from 0.00046\n",
      "4338/4338 [==============================] - 2710s 625ms/step - loss: 4.3469e-04 - val_loss: 4.6735e-04 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.3240e-04   \n",
      "Epoch 15: val_loss improved from 0.00046 to 0.00045, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2710s 625ms/step - loss: 4.3240e-04 - val_loss: 4.5344e-04 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.3024e-04   \n",
      "Epoch 16: val_loss improved from 0.00045 to 0.00045, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2711s 625ms/step - loss: 4.3024e-04 - val_loss: 4.4892e-04 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.2886e-04   \n",
      "Epoch 17: val_loss improved from 0.00045 to 0.00045, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2710s 625ms/step - loss: 4.2886e-04 - val_loss: 4.4868e-04 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.2652e-04   \n",
      "Epoch 18: val_loss improved from 0.00045 to 0.00045, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "4338/4338 [==============================] - 2709s 624ms/step - loss: 4.2652e-04 - val_loss: 4.4742e-04 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.2089e-04   \n",
      "Epoch 19: val_loss improved from 0.00045 to 0.00044, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2712s 625ms/step - loss: 4.2089e-04 - val_loss: 4.4186e-04 - lr: 5.0000e-05\n",
      "Epoch 20/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1993e-04   \n",
      "Epoch 20: val_loss improved from 0.00044 to 0.00044, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2714s 626ms/step - loss: 4.1993e-04 - val_loss: 4.4111e-04 - lr: 5.0000e-05\n",
      "Epoch 21/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1897e-04   \n",
      "Epoch 21: val_loss improved from 0.00044 to 0.00044, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2713s 625ms/step - loss: 4.1897e-04 - val_loss: 4.3927e-04 - lr: 5.0000e-05\n",
      "Epoch 22/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1843e-04   \n",
      "Epoch 22: val_loss did not improve from 0.00044\n",
      "4338/4338 [==============================] - 2714s 626ms/step - loss: 4.1843e-04 - val_loss: 4.4100e-04 - lr: 5.0000e-05\n",
      "Epoch 23/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1754e-04   \n",
      "Epoch 23: val_loss did not improve from 0.00044\n",
      "4338/4338 [==============================] - 2713s 625ms/step - loss: 4.1754e-04 - val_loss: 4.3961e-04 - lr: 5.0000e-05\n",
      "Epoch 24/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1707e-04   \n",
      "Epoch 24: val_loss did not improve from 0.00044\n",
      "4338/4338 [==============================] - 2713s 625ms/step - loss: 4.1707e-04 - val_loss: 4.3970e-04 - lr: 5.0000e-05\n",
      "Epoch 25/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1630e-04   \n",
      "Epoch 25: val_loss improved from 0.00044 to 0.00044, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2713s 625ms/step - loss: 4.1630e-04 - val_loss: 4.3812e-04 - lr: 5.0000e-05\n",
      "Epoch 26/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1563e-04   \n",
      "Epoch 26: val_loss did not improve from 0.00044\n",
      "4338/4338 [==============================] - 2714s 626ms/step - loss: 4.1563e-04 - val_loss: 4.3946e-04 - lr: 5.0000e-05\n",
      "Epoch 27/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1508e-04   \n",
      "Epoch 27: val_loss improved from 0.00044 to 0.00044, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2713s 625ms/step - loss: 4.1508e-04 - val_loss: 4.3713e-04 - lr: 5.0000e-05\n",
      "Epoch 28/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1441e-04   \n",
      "Epoch 28: val_loss improved from 0.00044 to 0.00044, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "4338/4338 [==============================] - 2713s 625ms/step - loss: 4.1441e-04 - val_loss: 4.3602e-04 - lr: 5.0000e-05\n",
      "Epoch 29/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1163e-04   \n",
      "Epoch 29: val_loss improved from 0.00044 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2713s 625ms/step - loss: 4.1163e-04 - val_loss: 4.3485e-04 - lr: 2.5000e-05\n",
      "Epoch 30/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1122e-04   \n",
      "Epoch 30: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2714s 626ms/step - loss: 4.1122e-04 - val_loss: 4.3380e-04 - lr: 2.5000e-05\n",
      "Epoch 31/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1093e-04   \n",
      "Epoch 31: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2719s 627ms/step - loss: 4.1093e-04 - val_loss: 4.3372e-04 - lr: 2.5000e-05\n",
      "Epoch 32/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1064e-04   \n",
      "Epoch 32: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2721s 627ms/step - loss: 4.1064e-04 - val_loss: 4.3324e-04 - lr: 2.5000e-05\n",
      "Epoch 33/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1031e-04   \n",
      "Epoch 33: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2716s 626ms/step - loss: 4.1031e-04 - val_loss: 4.3232e-04 - lr: 2.5000e-05\n",
      "Epoch 34/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.1011e-04   \n",
      "Epoch 34: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2715s 626ms/step - loss: 4.1011e-04 - val_loss: 4.3215e-04 - lr: 2.5000e-05\n",
      "Epoch 35/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0980e-04   \n",
      "Epoch 35: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2717s 626ms/step - loss: 4.0980e-04 - val_loss: 4.3164e-04 - lr: 2.5000e-05\n",
      "Epoch 36/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0952e-04   \n",
      "Epoch 36: val_loss did not improve from 0.00043\n",
      "4338/4338 [==============================] - 2717s 626ms/step - loss: 4.0952e-04 - val_loss: 4.3212e-04 - lr: 2.5000e-05\n",
      "Epoch 37/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0928e-04   \n",
      "Epoch 37: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2740s 632ms/step - loss: 4.0928e-04 - val_loss: 4.3138e-04 - lr: 2.5000e-05\n",
      "Epoch 38/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0902e-04   \n",
      "Epoch 38: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "4338/4338 [==============================] - 2724s 628ms/step - loss: 4.0902e-04 - val_loss: 4.3076e-04 - lr: 2.5000e-05\n",
      "Epoch 39/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0754e-04   \n",
      "Epoch 39: val_loss did not improve from 0.00043\n",
      "4338/4338 [==============================] - 2716s 626ms/step - loss: 4.0754e-04 - val_loss: 4.3135e-04 - lr: 1.2500e-05\n",
      "Epoch 40/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0739e-04   \n",
      "Epoch 40: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2721s 627ms/step - loss: 4.0739e-04 - val_loss: 4.2972e-04 - lr: 1.2500e-05\n",
      "Epoch 41/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0723e-04   \n",
      "Epoch 41: val_loss did not improve from 0.00043\n",
      "4338/4338 [==============================] - 2716s 626ms/step - loss: 4.0723e-04 - val_loss: 4.2996e-04 - lr: 1.2500e-05\n",
      "Epoch 42/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0703e-04   \n",
      "Epoch 42: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2717s 626ms/step - loss: 4.0703e-04 - val_loss: 4.2970e-04 - lr: 1.2500e-05\n",
      "Epoch 43/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0691e-04   \n",
      "Epoch 43: val_loss did not improve from 0.00043\n",
      "4338/4338 [==============================] - 2718s 627ms/step - loss: 4.0691e-04 - val_loss: 4.3093e-04 - lr: 1.2500e-05\n",
      "Epoch 44/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0680e-04   \n",
      "Epoch 44: val_loss did not improve from 0.00043\n",
      "4338/4338 [==============================] - 2718s 626ms/step - loss: 4.0680e-04 - val_loss: 4.3025e-04 - lr: 1.2500e-05\n",
      "Epoch 45/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0666e-04   \n",
      "Epoch 45: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2718s 627ms/step - loss: 4.0666e-04 - val_loss: 4.2965e-04 - lr: 1.2500e-05\n",
      "Epoch 46/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0654e-04   \n",
      "Epoch 46: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2718s 626ms/step - loss: 4.0654e-04 - val_loss: 4.2922e-04 - lr: 1.2500e-05\n",
      "Epoch 47/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0640e-04   \n",
      "Epoch 47: val_loss did not improve from 0.00043\n",
      "4338/4338 [==============================] - 2717s 626ms/step - loss: 4.0640e-04 - val_loss: 4.2926e-04 - lr: 1.2500e-05\n",
      "Epoch 48/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0627e-04   \n",
      "Epoch 48: val_loss did not improve from 0.00043\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "4338/4338 [==============================] - 2716s 626ms/step - loss: 4.0627e-04 - val_loss: 4.2938e-04 - lr: 1.2500e-05\n",
      "Epoch 49/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0549e-04   \n",
      "Epoch 49: val_loss improved from 0.00043 to 0.00043, saving model to ./SavedModels_DCRCNN_full\\best_ckpt\n",
      "4338/4338 [==============================] - 2717s 626ms/step - loss: 4.0549e-04 - val_loss: 4.2857e-04 - lr: 6.2500e-06\n",
      "Epoch 50/50\n",
      "4338/4338 [==============================] - ETA: 0s - loss: 4.0539e-04   \n",
      "Epoch 50: val_loss did not improve from 0.00043\n",
      "4338/4338 [==============================] - 2716s 626ms/step - loss: 4.0539e-04 - val_loss: 4.2863e-04 - lr: 6.2500e-06\n",
      "\n",
      "‚úÖ TRAINING COMPLETED\n",
      "‚úÖ Final weights saved to ./SavedModels_DCRCNN_full\\final_ckpt\n",
      "\n",
      "üìä TRAINING ANALYSIS\n",
      "============================================================\n",
      " Best Epoch: 49\n",
      " Best Val Loss: 0.000429\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ============================================================\n",
    "# Directory Setup\n",
    "# ============================================================\n",
    "save_dir = \"./SavedModels_DCRCNN_full\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "H, W = 320, 320\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# TensorFlow checkpoint paths (NO .h5)\n",
    "INIT_CKPT  = os.path.join(save_dir, \"init_ckpt\")\n",
    "BEST_CKPT  = os.path.join(save_dir, \"best_ckpt\")\n",
    "FINAL_CKPT = os.path.join(save_dir, \"final_ckpt\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîß TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\" Save Directory:       {save_dir}\")\n",
    "print(f\" Model Dimensions:     {H}x{W}\")\n",
    "print(f\" Epochs:               {EPOCHS}\")\n",
    "print(f\" Learning Rate:        {LEARNING_RATE}\")\n",
    "print(f\" Init Checkpoint:      {INIT_CKPT}\")\n",
    "print(f\" Best Checkpoint:      {BEST_CKPT}\")\n",
    "print(f\" Final Checkpoint:     {FINAL_CKPT}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# Model Setup\n",
    "# ============================================================\n",
    "model = build_dcr_cnn(\n",
    "    input_shape=(320, 320, 1),\n",
    "    num_dcr_blocks=10,   # or 3 / 8\n",
    "    num_features=64,\n",
    "    growth_rate=32\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Optimizer & Compile\n",
    "# ============================================================\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "# ============================================================\n",
    "# Load Initial Weights (Optional Resume)\n",
    "# ============================================================\n",
    "if tf.train.latest_checkpoint(save_dir):\n",
    "    model.load_weights(tf.train.latest_checkpoint(save_dir))\n",
    "    print(\"‚úÖ Loaded latest checkpoint\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No checkpoint found. Training from scratch.\")\n",
    "\n",
    "# ============================================================\n",
    "# Callbacks\n",
    "# ============================================================\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=BEST_CKPT,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_cb, earlystop_cb, reduce_lr_cb]\n",
    "\n",
    "# ============================================================\n",
    "# Training\n",
    "# ============================================================\n",
    "print(\"\\nüöÄ STARTING TRAINING...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ TRAINING COMPLETED\")\n",
    "\n",
    "# ============================================================\n",
    "# Save Final Weights\n",
    "# ============================================================\n",
    "model.save_weights(FINAL_CKPT)\n",
    "print(f\"‚úÖ Final weights saved to {FINAL_CKPT}\")\n",
    "\n",
    "# ============================================================\n",
    "# Training Analysis\n",
    "# ============================================================\n",
    "if history:\n",
    "    print(\"\\nüìä TRAINING ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    best_epoch = np.argmin(history.history[\"val_loss\"]) + 1\n",
    "    print(f\" Best Epoch: {best_epoch}\")\n",
    "    print(f\" Best Val Loss: {np.min(history.history['val_loss']):.6f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Plot Training Curves\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63b9cb-8095-41e2-85ce-5112daca569a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
