{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1a001a-6efd-4a72-ab79-15dde44dfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./Modules/cv_can_new.ipynb\n",
    "# %run sfanet_new-Copy2.ipynb\n",
    "\n",
    "# %run sfanet_new_mpca_fsa-Copy1.ipynb\n",
    "%run \"./sfanet_new-Copy2.ipynb\"\n",
    "\n",
    "# %run sfanet_new_mpca_fsa.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344b0973-bf63-48f2-9f68-5124962a6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_dual_output_model()\n",
    "# model.load_weights(\".\\SavedModels\\weight_sfu_fastmri_complex_perploss_mpca_fsa2.h5\")\n",
    "model.load_weights(\"./weight_sfu_fastmri_complex_perploss_fsa.h5\")\n",
    "\n",
    "\n",
    "# output = model(input_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01537672-eb6a-4990-aa15-0cb21d25d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "# files = sorted([os.path.join(val_folder, f) for f in os.listdir(val_folder) if f.endswith(\".h5\")])\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7e4b27-3624-4266-b9e2-4aaf6a29b62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_000.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_001.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_002.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_003.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_004.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_005.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_006.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_007.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_008.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_009.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_010.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_011.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_012.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_013.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_014.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_015.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_016.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_017.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_018.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_019.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_020.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_021.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_022.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_023.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_024.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_025.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_026.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_027.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_028.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_029.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_030.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_031.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_032.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_033.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_034.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_035.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_036.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_037.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_038.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_039.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_040.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_041.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_042.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_043.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_044.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_045.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_046.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_047.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_048.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_049.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_050.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_051.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_052.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_053.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_054.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_055.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_056.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_057.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_058.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_059.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_060.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_061.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_062.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_063.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_064.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_065.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_066.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_067.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_068.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_069.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_070.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_071.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_072.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_073.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_074.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_075.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_076.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_077.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_078.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_079.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_080.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_081.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_082.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_083.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_084.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_085.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_086.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_087.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_088.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_089.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_090.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_091.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_092.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_093.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_094.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_095.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_096.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_097.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_098.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_099.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_000.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_001.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_002.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_003.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_004.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_005.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_006.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_007.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_008.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_009.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_010.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_011.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_012.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_013.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_014.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_015.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_016.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_017.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_018.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_019.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_020.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_021.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_022.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_023.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_024.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_025.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_026.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_027.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_028.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_029.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_030.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_031.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_032.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_033.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_034.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_035.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_036.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_037.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_038.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_039.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_040.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_041.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_042.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_043.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_044.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_045.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_046.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_047.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_048.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_049.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_050.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_051.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_052.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_053.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_054.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_055.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_056.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_057.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_058.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_059.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_060.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_061.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_062.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_063.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_064.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_065.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_066.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_067.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_068.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_069.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_070.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_071.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_072.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_073.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_074.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_075.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_076.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_077.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_078.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_079.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_080.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_081.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_082.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_083.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_084.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_085.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_086.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_087.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_088.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_089.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_090.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_091.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_092.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_093.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_094.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_095.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_096.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_097.h5',\n",
       " 'D:\\\\fastmri_singlecoil_FSSCAN\\\\val_norm\\\\volume_PDFS_098.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kspace_files_list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f88c40c9-6283-4360-801e-7d70c3ce103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD volumes: 483\n",
      "PDFS volumes: 489\n"
     ]
    }
   ],
   "source": [
    "pd_files = []\n",
    "pdfs_files = []\n",
    "\n",
    "for f in kspace_files_list_val:\n",
    "    if \"PDFS\" in f:\n",
    "        pdfs_files.append(f)\n",
    "    else:\n",
    "        pd_files.append(f)\n",
    "\n",
    "print(f\"PD volumes: {len(pd_files)}\")\n",
    "print(f\"PDFS volumes: {len(pdfs_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0efa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [05:26<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PSNR (Mag, volume): 34.27 ¬± 2.36 dB\n",
      "NMSE (Mag, volume): 0.073141 ¬± 0.062938\n",
      "SSIM (Mag, slice):  0.8332 ¬± 0.0754\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# Path to validation folder\n",
    "# val_folder = \"F:/denoised_preprocessed_h5_val\"\n",
    "\n",
    "# val_folder = r\"E:\\fastmri\\val_norm\"\n",
    "# val_folder = r\"D:\\val_norm\"\n",
    "# train_folder = r\"D:\\train_norm\"\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "# files = sorted([os.path.join(val_folder, f) for f in os.listdir(val_folder) if f.endswith(\".h5\")])\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "# file_paths = kspace_files_list_val[0:5]\n",
    "\n",
    "file_paths = kspace_files_list_val\n",
    "\n",
    "# ----------------------\n",
    "# HELPERS\n",
    "# ----------------------\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + 1e-10)\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "\n",
    "# ----------------------\n",
    "# STORAGE\n",
    "# ----------------------\n",
    "ssim_list = []\n",
    "psnr_list = []\n",
    "nmse_list = []\n",
    "\n",
    "# ----------------------\n",
    "# PROCESSING\n",
    "# ----------------------\n",
    "for file in tqdm(file_paths, desc=\"Processing volumes\"):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full = f[\"image_full\"][:]       # (slices, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]     # (slices, H, W, 2)\n",
    "        max_val = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "#     mask_batch = np.tile(mask, (image_under.shape[0], 1, 1, 1)) \n",
    "    # Get model prediction (still in normalized form)\n",
    "    # pred = model.predict([image_under,mask_batch,image_under], verbose=0)  # shape (slices, H, W, 2)\n",
    "    pred = model.predict(image_under, verbose=0)  # shape (slices, H, W, 2)\n",
    "    \n",
    "    image_full *= max_val\n",
    "    \n",
    "    pred *= max_val  # Scale predicted output to original intensity range\n",
    "\n",
    "    # Convert to complex and get magnitude\n",
    "    gt_mag = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # Volume-wise PSNR and NMSE\n",
    "    psnr_val = peak_signal_noise_ratio(gt_mag, pred_mag, data_range=max_val)\n",
    "    nmse_val = nmse(gt_mag.flatten(), pred_mag.flatten())\n",
    "\n",
    "    psnr_list.append(psnr_val)\n",
    "    nmse_list.append(nmse_val)\n",
    "\n",
    "    # Slice-wise SSIM\n",
    "    for i in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(gt_mag[i], pred_mag[i], max_val)\n",
    "        ssim_list.append(ssim_val)\n",
    "\n",
    "# ----------------------\n",
    "# REPORT\n",
    "# ----------------------\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"PSNR (Mag, volume): {np.mean(psnr_list):.2f} ¬± {np.std(psnr_list):.2f} dB\")\n",
    "print(f\"NMSE (Mag, volume): {np.mean(nmse_list):.6f} ¬± {np.std(nmse_list):.6f}\")\n",
    "print(f\"SSIM (Mag, slice):  {np.mean(ssim_list):.4f} ¬± {np.std(ssim_list):.4f}\")\n",
    "\n",
    "print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b4d564-ed3b-4c0f-ba60-76f440176ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timing on /CPU:0:   1%|‚ñå                                                           | 2/199 [08:57<14:41:35, 268.50s/it]\n",
      "Timing on /GPU:0:   1%|‚ñã                                                               | 2/199 [00:19<32:25,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL EFFICIENCY REPORT (BATCH SIZE = 1)\n",
      "======================================================================\n",
      "Parameters: 22.22 M\n",
      "FLOPs:      159.10 GFLOPs (per slice)\n",
      "\n",
      "--- CPU Inference ---\n",
      "Mean latency:   5.37 s / slice\n",
      "Throughput:    0.186 slices/sec\n",
      "Memory usage:  0.08 MB\n",
      "\n",
      "--- GPU Inference ---\n",
      "GPU:           NVIDIA RTX A5000\n",
      "Mean latency:  0.20 s / slice\n",
      "Throughput:   5.082 slices/sec\n",
      "Peak memory:  626.97 MB\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import psutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras_flops import get_flops\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "VAL_FOLDER = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "WARMUP_SLICES = 10\n",
    "NUM_TIMING_SLICES = 100  # increase for more stable stats\n",
    "\n",
    "# ============================================================\n",
    "# FILE LIST\n",
    "# ============================================================\n",
    "file_paths = sorted(glob.glob(os.path.join(VAL_FOLDER, \"*.h5\")))\n",
    "\n",
    "# ============================================================\n",
    "# MODEL MUST BE LOADED BEFORE THIS SCRIPT\n",
    "# ============================================================\n",
    "# model = ...\n",
    "assert model is not None, \"Model is not loaded.\"\n",
    "\n",
    "# ============================================================\n",
    "# PARAMETER COUNT\n",
    "# ============================================================\n",
    "num_params = model.count_params()\n",
    "\n",
    "# ============================================================\n",
    "# FLOPs (PER SLICE, BATCH SIZE = 1)\n",
    "# ============================================================\n",
    "flops = get_flops(model, batch_size=1)\n",
    "\n",
    "# ============================================================\n",
    "# MEMORY HELPERS\n",
    "# ============================================================\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "def cpu_memory_mb():\n",
    "    return process.memory_info().rss / (1024 ** 2)\n",
    "\n",
    "def gpu_memory_mb():\n",
    "    info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "    return info[\"peak\"] / (1024 ** 2)\n",
    "\n",
    "# ============================================================\n",
    "# LATENCY / THROUGHPUT MEASUREMENT\n",
    "# ============================================================\n",
    "def measure_latency(device):\n",
    "\n",
    "    latencies = []\n",
    "\n",
    "    with tf.device(device):\n",
    "\n",
    "        # -----------------------------\n",
    "        # WARM-UP\n",
    "        # -----------------------------\n",
    "        for file in file_paths[:1]:\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(min(WARMUP_SLICES, image_under.shape[0])):\n",
    "                _ = model(image_under[s:s+1], training=False)\n",
    "\n",
    "        # -----------------------------\n",
    "        # TIMED INFERENCE\n",
    "        # -----------------------------\n",
    "        count = 0\n",
    "        for file in tqdm(file_paths, desc=f\"Timing on {device}\"):\n",
    "\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(image_under.shape[0]):\n",
    "\n",
    "                if count >= NUM_TIMING_SLICES:\n",
    "                    break\n",
    "\n",
    "                slice_input = image_under[s:s+1]\n",
    "                assert slice_input.shape[0] == 1  # batch size check\n",
    "\n",
    "                start = time.perf_counter()\n",
    "                _ = model(slice_input, training=False)\n",
    "\n",
    "                # üîë GPU synchronization\n",
    "                if \"GPU\" in device:\n",
    "                    tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "\n",
    "                end = time.perf_counter()\n",
    "\n",
    "                latencies.append(end - start)\n",
    "                count += 1\n",
    "\n",
    "            if count >= NUM_TIMING_SLICES:\n",
    "                break\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "\n",
    "    mean_s = latencies.mean()\n",
    "    median_s = np.median(latencies)\n",
    "\n",
    "    return {\n",
    "        \"mean_s\": mean_s,\n",
    "        \"median_s\": median_s,\n",
    "        \"std_s\": latencies.std(),\n",
    "        \"slices_per_sec_mean\": 1.0 / mean_s,\n",
    "        \"slices_per_sec_median\": 1.0 / median_s\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# CPU BENCHMARK\n",
    "# ============================================================\n",
    "cpu_mem_before = cpu_memory_mb()\n",
    "cpu_latency = measure_latency(\"/CPU:0\")\n",
    "cpu_mem_after = cpu_memory_mb()\n",
    "cpu_mem_peak = cpu_mem_after - cpu_mem_before\n",
    "\n",
    "# ============================================================\n",
    "# GPU BENCHMARK (IF AVAILABLE)\n",
    "# ============================================================\n",
    "gpu_latency = None\n",
    "gpu_mem_peak = None\n",
    "gpu_name = None\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    gpu_name = tf.config.experimental.get_device_details(gpus[0])[\"device_name\"]\n",
    "    gpu_latency = measure_latency(\"/GPU:0\")\n",
    "    gpu_mem_peak = gpu_memory_mb()\n",
    "\n",
    "# ============================================================\n",
    "# FINAL REPORT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL EFFICIENCY REPORT (BATCH SIZE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Parameters: {num_params / 1e6:.2f} M\")\n",
    "print(f\"FLOPs:      {flops / 1e9:.2f} GFLOPs (per slice)\")\n",
    "\n",
    "print(\"\\n--- CPU Inference ---\")\n",
    "print(f\"Mean latency:   {cpu_latency['mean_s']:.2f} s / slice\")\n",
    "print(f\"Throughput:    {cpu_latency['slices_per_sec_mean']:.3f} slices/sec\")\n",
    "print(f\"Memory usage:  {cpu_mem_peak:.2f} MB\")\n",
    "\n",
    "if gpu_latency:\n",
    "    print(\"\\n--- GPU Inference ---\")\n",
    "    print(f\"GPU:           {gpu_name}\")\n",
    "    print(f\"Mean latency:  {gpu_latency['mean_s']:.2f} s / slice\")\n",
    "    print(f\"Throughput:   {gpu_latency['slices_per_sec_mean']:.3f} slices/sec\")\n",
    "    print(f\"Peak memory:  {gpu_mem_peak:.2f} MB\")\n",
    "else:\n",
    "    print(\"\\nGPU not available.\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45275b64-7e0f-438f-9ac6-6d30ed936d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [05:15<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RECONSTRUCTION PERFORMANCE (VALIDATION SET)\n",
      "==================================================\n",
      "PSNR  (Mag, volume): 34.27 ¬± 2.36 dB\n",
      "NMSE  (Mag, volume): 0.016860 ¬± 0.007025\n",
      "SSIM  (Mag, slice):  0.8332 ¬± 0.0754\n",
      "CONF  (slice-wise):  0.9792 ¬± 0.0177\n",
      "CONF  (volume-wise): 0.9790 ¬± 0.0079\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "file_paths = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "def to_complex(x):\n",
    "    \"\"\"Convert [..., 2] real/imag array to complex.\"\"\"\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    \"\"\"Normalized MSE.\"\"\"\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + 1e-10)\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "\n",
    "def confidence_score(gt_mag, pred_mag):\n",
    "    \"\"\"\n",
    "    Residual-based confidence score.\n",
    "    Higher value => higher reconstruction reliability.\n",
    "    \"\"\"\n",
    "    num = np.linalg.norm(gt_mag - pred_mag) ** 2\n",
    "    den = np.linalg.norm(gt_mag) ** 2 + 1e-10\n",
    "    return 1.0 - num / den\n",
    "\n",
    "# ============================================================\n",
    "# STORAGE\n",
    "# ============================================================\n",
    "psnr_list = []          # volume-wise\n",
    "nmse_list = []          # volume-wise\n",
    "ssim_list = []          # slice-wise\n",
    "confidence_list = []    # slice-wise\n",
    "confidence_vol_list = []  # volume-wise\n",
    "\n",
    "# ============================================================\n",
    "# PROCESSING\n",
    "# ============================================================\n",
    "for file in tqdm(file_paths, desc=\"Processing volumes\"):\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full = f[\"image_full\"][:]        # (S, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]      # (S, H, W, 2)\n",
    "        max_val = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # MODEL INFERENCE (normalized domain)\n",
    "    # --------------------------------------------------------\n",
    "    pred = model.predict(image_under, verbose=0)  # (S, H, W, 2)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # SCALE BACK TO ORIGINAL INTENSITY RANGE\n",
    "    # --------------------------------------------------------\n",
    "    image_full = image_full * max_val\n",
    "    pred = pred * max_val\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # MAGNITUDE IMAGES\n",
    "    # --------------------------------------------------------\n",
    "    gt_mag = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # VOLUME-WISE METRICS\n",
    "    # --------------------------------------------------------\n",
    "    psnr_val = peak_signal_noise_ratio(\n",
    "        gt_mag, pred_mag, data_range=max_val\n",
    "    )\n",
    "    nmse_val = nmse(gt_mag.flatten(), pred_mag.flatten())\n",
    "\n",
    "    psnr_list.append(psnr_val)\n",
    "    nmse_list.append(nmse_val)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # SLICE-WISE METRICS + CONFIDENCE\n",
    "    # --------------------------------------------------------\n",
    "    slice_confidence = []\n",
    "\n",
    "    for s in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(gt_mag[s], pred_mag[s], max_val)\n",
    "        conf_val = confidence_score(gt_mag[s], pred_mag[s])\n",
    "\n",
    "        ssim_list.append(ssim_val)\n",
    "        confidence_list.append(conf_val)\n",
    "        slice_confidence.append(conf_val)\n",
    "\n",
    "    # Volume-wise confidence (mean over slices)\n",
    "    confidence_vol_list.append(np.mean(slice_confidence))\n",
    "\n",
    "# ============================================================\n",
    "# REPORT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RECONSTRUCTION PERFORMANCE (VALIDATION SET)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"PSNR  (Mag, volume): {np.mean(psnr_list):.2f} ¬± {np.std(psnr_list):.2f} dB\")\n",
    "print(f\"NMSE  (Mag, volume): {np.mean(nmse_list):.6f} ¬± {np.std(nmse_list):.6f}\")\n",
    "print(f\"SSIM  (Mag, slice):  {np.mean(ssim_list):.4f} ¬± {np.std(ssim_list):.4f}\")\n",
    "print(f\"CONF  (slice-wise):  {np.mean(confidence_list):.4f} ¬± {np.std(confidence_list):.4f}\")\n",
    "print(f\"CONF  (volume-wise): {np.mean(confidence_vol_list):.4f} ¬± {np.std(confidence_vol_list):.4f}\")\n",
    "\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c85c5f6-68fa-4c57-a651-3623d0506549",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# files = sorted([os.path.join(val_folder, f) for f in os.listdir(val_folder) if f.endswith(\".h5\")])\u001b[39;00m\n\u001b[0;32m    105\u001b[0m kspace_files_list_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(val_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m--> 106\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[43mkspace_files_list_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    110\u001b[0m     image_full \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_full\u001b[39m\u001b[38;5;124m\"\u001b[39m][:]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    eps = 1e-10\n",
    "    nmse = np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + eps)\n",
    "    psnr = peak_signal_noise_ratio(np.abs(gt), np.abs(pred), data_range=np.abs(gt).max() - np.abs(gt).min())\n",
    "    ssim = structural_similarity(\n",
    "        np.abs(gt), np.abs(pred),\n",
    "        data_range=np.abs(gt).max() - np.abs(gt).min(),\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "    return nmse, psnr, ssim\n",
    "\n",
    "def overlay_stats(ax, text):\n",
    "    ax.text(\n",
    "        0.05, 0.95, text,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        color=\"yellow\", fontsize=20, fontweight=\"bold\",\n",
    "        bbox=dict(facecolor=\"black\", alpha=0.5, pad=2)\n",
    "    )\n",
    "\n",
    "def plot_slice(gt, under, pred, slice_idx, pdf, max_val):\n",
    "    domains = ['Real', 'Imag', 'Abs']\n",
    "    gt_split = [gt.real, gt.imag, np.abs(gt)]\n",
    "    under_split = [under.real, under.imag, np.abs(under)]\n",
    "    pred_split = [pred.real, pred.imag, np.abs(pred)]\n",
    "\n",
    "    # Compute error maps\n",
    "    error_abs_under = [np.abs(gt_split[i] - under_split[i]) for i in range(3)]\n",
    "    error_abs_pred = [np.abs(gt_split[i] - pred_split[i]) for i in range(3)]\n",
    "    error_signed_under = [gt_split[i] - under_split[i] for i in range(3)]\n",
    "    error_signed_pred = [gt_split[i] - pred_split[i] for i in range(3)]\n",
    "\n",
    "    \n",
    "    # fig, axs = plt.subplots(3, 5, figsize=(28, 20), constrained_layout=True)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(28, 18))  # 3 rows (domains) √ó 5 columns (types)\n",
    "    plt.suptitle(f\"Slice {slice_idx}\", fontsize=28, fontweight=\"bold\")\n",
    "\n",
    "    for row, domain in enumerate(domains):\n",
    "        # Compute metrics\n",
    "        nmse_u = compute_metrics(gt_split[row], under_split[row])[0]\n",
    "        psnr_u = compute_metrics(gt_split[row], under_split[row])[1]\n",
    "        ssim_u = compute_metrics(gt_split[row], under_split[row])[2]\n",
    "\n",
    "        nmse_p = compute_metrics(gt_split[row], pred_split[row])[0]\n",
    "        psnr_p = compute_metrics(gt_split[row], pred_split[row])[1]\n",
    "        ssim_p = compute_metrics(gt_split[row], pred_split[row])[2]\n",
    "\n",
    "        metric_text_under = f\"NMSE: {nmse_u:.4f}\\nPSNR: {psnr_u:.2f} dB\\nSSIM: {ssim_u:.4f}\"\n",
    "        metric_text_pred = f\"NMSE: {nmse_p:.4f}\\nPSNR: {psnr_p:.2f} dB\\nSSIM: {ssim_p:.4f}\"\n",
    "\n",
    "        vmax_abs = max(np.max(error_abs_under[row]), np.max(error_abs_pred[row]))\n",
    "        # vmax_signed = max(np.max(np.abs(error_signed_under[i])), np.max(np.abs(error_signed_pred[i])))\n",
    "\n",
    "        axs[row, 0].imshow(gt_split[row], cmap=\"gray\")\n",
    "        # axs[row, 0].set_title(f\"GT {domain}\", fontsize=18)\n",
    "        axs[row, 0].axis(\"off\")\n",
    "\n",
    "        axs[row, 1].imshow(under_split[row], cmap=\"gray\")\n",
    "        # axs[row, 1].set_title(f\"Undersampled {domain}\", fontsize=18)\n",
    "        axs[row, 1].axis(\"off\")\n",
    "        overlay_stats(axs[row, 1], metric_text_under)\n",
    "\n",
    "        axs[row, 2].imshow(pred_split[row], cmap=\"gray\")\n",
    "        # axs[row, 2].set_title(f\"Reconstructed {domain}\", fontsize=18)\n",
    "        axs[row, 2].axis(\"off\")\n",
    "        overlay_stats(axs[row, 2], metric_text_pred)\n",
    "\n",
    "        axs[row, 3].imshow(error_abs_under[row], cmap=\"hot\", vmin=0, vmax=vmax_abs)\n",
    "        # axs[row, 3].set_title(f\"|GT ‚àí Und| {domain}\", fontsize=18)\n",
    "        axs[row, 3].axis(\"off\")\n",
    "\n",
    "        axs[row, 4].imshow(error_abs_pred[row], cmap=\"hot\", vmin=0, vmax=vmax_abs)\n",
    "        # axs[row, 4].set_title(f\"|GT ‚àí Pred| {domain}\", fontsize=18)\n",
    "        axs[row, 4].axis(\"off\")\n",
    "\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.subplots_adjust(hspace=0.1,wspace=0.1) \n",
    "    pdf.savefig(fig)\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "# file_path = \"your_file_path_here.h5\"  # ‚Üê Replace this path\n",
    "val_folder = r\"D:\\val_norm\"\n",
    "# files = sorted([os.path.join(val_folder, f) for f in os.listdir(val_folder) if f.endswith(\".h5\")])\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "file_path = kspace_files_list_val[0]\n",
    "\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    image_full = f[\"image_full\"][:]\n",
    "    image_under = f[\"image_under\"][:]\n",
    "    max_val = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "# -----------------------\n",
    "# CONVERT TO COMPLEX\n",
    "# -----------------------\n",
    "gt_complex = to_complex(image_full)\n",
    "under_complex = to_complex(image_under)\n",
    "\n",
    "# -----------------------\n",
    "# MODEL PREDICTION\n",
    "# -----------------------\n",
    "pred_slices = []\n",
    "for i in range(image_under.shape[0]):\n",
    "    input_slice = image_under[i:i+1]\n",
    "    pred_slice = model.predict(input_slice, verbose=0)[0]\n",
    "    pred_slices.append(pred_slice)\n",
    "\n",
    "pred_slices = np.array(pred_slices)\n",
    "pred_complex = to_complex(pred_slices)\n",
    "\n",
    "# -----------------------\n",
    "# PDF VISUALIZATION\n",
    "# -----------------------\n",
    "output_pdf_path = \"volume_visualization_fsa_mse_cmap_hot.pdf\"\n",
    "with PdfPages(output_pdf_path) as pdf:\n",
    "    # slice_indices = np.linspace(0, gt_complex.shape[0] - 1, 4, dtype=int)\n",
    "    slice_indices = range(gt_complex.shape[0])\n",
    "\n",
    "    for idx in slice_indices:\n",
    "        plot_slice(gt_complex[idx], under_complex[idx], pred_complex[idx], idx, pdf, max_val)\n",
    "        \n",
    "    # Summary\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_title(\"Volume Intensity Summary\", fontsize=18)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    text = (\n",
    "        f\"GT Abs:    min={np.abs(gt_complex).min():.4f}, max={np.abs(gt_complex).max():.4f}\\n\"\n",
    "        f\"Under Abs: min={np.abs(under_complex).min():.4f}, max={np.abs(under_complex).max():.4f}\\n\"\n",
    "        f\"Pred Abs:  min={np.abs(pred_complex).min():.4f}, max={np.abs(pred_complex).max():.4f}\\n\\n\"\n",
    "        f\"GT Real:   min={gt_complex.real.min():.4f}, max={gt_complex.real.max():.4f}\\n\"\n",
    "        f\"GT Imag:   min={gt_complex.imag.min():.4f}, max={gt_complex.imag.max():.4f}\"\n",
    "    )\n",
    "    ax.text(0.05, 0.5, text, fontsize=12, va=\"center\")\n",
    "    pdf.savefig(fig)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"‚úÖ PDF saved at: {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a04ff2-86fb-443d-9c9d-de6a05ee58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG (edit these)\n",
    "# -----------------------\n",
    "val_folder = r\"D:\\val_norm\"           # folder with .h5 files\n",
    "file_index = 0                         # which file in sorted list to use\n",
    "requested = [18, 19, 20]                # list of slice indices you want saved as PNG\n",
    "out_dir = \"slice_pngs\"                 # where PNGs will be saved\n",
    "dpi = 300                              # output dpi (300 recommended)\n",
    "# -----------------------\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    eps = 1e-10\n",
    "    nmse = np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + eps)\n",
    "    psnr = peak_signal_noise_ratio(np.abs(gt), np.abs(pred), data_range=np.abs(gt).max() - np.abs(gt).min())\n",
    "    ssim = structural_similarity(\n",
    "        np.abs(gt), np.abs(pred),\n",
    "        data_range=np.abs(gt).max() - np.abs(gt).min(),\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "    return nmse, psnr, ssim\n",
    "\n",
    "def overlay_stats(ax, text):\n",
    "    ax.text(\n",
    "        0.05, 0.95, text,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        color=\"yellow\", fontsize=14, fontweight=\"bold\",\n",
    "        bbox=dict(facecolor=\"black\", alpha=0.5, pad=2)\n",
    "    )\n",
    "\n",
    "def plot_slice(gt, under, pred, slice_idx, pdf, max_val):\n",
    "    domains = ['Real', 'Imag', 'Abs']\n",
    "    gt_split = [gt.real, gt.imag, np.abs(gt)]\n",
    "    under_split = [under.real, under.imag, np.abs(under)]\n",
    "    pred_split = [pred.real, pred.imag, np.abs(pred)]\n",
    "\n",
    "    # Compute error maps\n",
    "    error_abs_under = [np.abs(gt_split[i] - under_split[i]) for i in range(3)]\n",
    "    error_abs_pred = [np.abs(gt_split[i] - pred_split[i]) for i in range(3)]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(28, 18))\n",
    "    plt.suptitle(f\"Slice {slice_idx}\", fontsize=28, fontweight=\"bold\")\n",
    "\n",
    "    for row, domain in enumerate(domains):\n",
    "        # Compute metrics\n",
    "        nmse_u = compute_metrics(gt_split[row], under_split[row])[0]\n",
    "        psnr_u = compute_metrics(gt_split[row], under_split[row])[1]\n",
    "        ssim_u = compute_metrics(gt_split[row], under_split[row])[2]\n",
    "\n",
    "        nmse_p = compute_metrics(gt_split[row], pred_split[row])[0]\n",
    "        psnr_p = compute_metrics(gt_split[row], pred_split[row])[1]\n",
    "        ssim_p = compute_metrics(gt_split[row], pred_split[row])[2]\n",
    "\n",
    "        metric_text_under = f\"NMSE: {nmse_u:.4f}\\nPSNR: {psnr_u:.2f} dB\\nSSIM: {ssim_u:.4f}\"\n",
    "        metric_text_pred = f\"NMSE: {nmse_p:.4f}\\nPSNR: {psnr_p:.2f} dB\\nSSIM: {ssim_p:.4f}\"\n",
    "\n",
    "        vmax_abs = max(np.max(error_abs_under[row]), np.max(error_abs_pred[row]))\n",
    "        if vmax_abs == 0:\n",
    "            vmax_abs = 1e-8  # avoid vmin==vmax\n",
    "\n",
    "        # Column 0: GT\n",
    "        axs[row, 0].imshow(gt_split[row], cmap=\"gray\", interpolation='nearest')\n",
    "        axs[row, 0].axis(\"off\")\n",
    "\n",
    "        # Column 1: Undersampled\n",
    "        axs[row, 1].imshow(under_split[row], cmap=\"gray\", interpolation='nearest')\n",
    "        axs[row, 1].axis(\"off\")\n",
    "        overlay_stats(axs[row, 1], metric_text_under)\n",
    "\n",
    "        # Column 2: Reconstructed\n",
    "        axs[row, 2].imshow(pred_split[row], cmap=\"gray\", interpolation='nearest')\n",
    "        axs[row, 2].axis(\"off\")\n",
    "        overlay_stats(axs[row, 2], metric_text_pred)\n",
    "\n",
    "        # Column 3: |GT - Und|\n",
    "        axs[row, 3].imshow(error_abs_under[row], cmap=\"hot\", vmin=0, vmax=vmax_abs, interpolation='nearest')\n",
    "        axs[row, 3].axis(\"off\")\n",
    "\n",
    "        # Column 4: |GT - Pred|\n",
    "        axs[row, 4].imshow(error_abs_pred[row], cmap=\"hot\", vmin=0, vmax=vmax_abs, interpolation='nearest')\n",
    "        axs[row, 4].axis(\"off\")\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    # Minimal change: either save into provided pdf, or save as PNG into out_dir\n",
    "    if pdf is not None:\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        out_path = os.path.join(out_dir, f\"slice_{slice_idx:03d}.png\")\n",
    "        fig.savefig(out_path, dpi=300, bbox_inches='tight', pad_inches=0.04)\n",
    "        plt.close(fig)\n",
    "\n",
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "h5_list = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "if len(h5_list) == 0:\n",
    "    raise FileNotFoundError(f\"No .h5 files found in {val_folder}\")\n",
    "if file_index < 0 or file_index >= len(h5_list):\n",
    "    raise IndexError(f\"file_index {file_index} out of range (0..{len(h5_list)-1})\")\n",
    "\n",
    "file_path = h5_list[file_index]\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Keys in file:\", list(f.keys()))\n",
    "    image_full = f[\"image_full\"][:]       # (slices, H, W, 2)\n",
    "    image_under = f[\"image_under\"][:]     # (slices, H, W, 2)\n",
    "    max_val = float(f[\"max_val_full_image\"][0]) if \"max_val_full_image\" in f else None\n",
    "\n",
    "# -----------------------\n",
    "# CONVERT TO COMPLEX\n",
    "# -----------------------\n",
    "gt_complex = to_complex(image_full)\n",
    "under_complex = to_complex(image_under)\n",
    "\n",
    "# -----------------------\n",
    "# MODEL PREDICTION (slice-by-slice to match your earlier approach)\n",
    "# -----------------------\n",
    "if \"model\" not in globals():\n",
    "    raise RuntimeError(\"No 'model' found in the session. Load your TF model into variable name `model` first.\")\n",
    "\n",
    "pred_slices = []\n",
    "for i in range(image_under.shape[0]):\n",
    "    input_slice = image_under[i:i+1].astype(np.float32)\n",
    "    pred_slice = model.predict(input_slice, verbose=0)[0]\n",
    "    pred_slices.append(pred_slice)\n",
    "pred_slices = np.array(pred_slices)\n",
    "pred_complex = to_complex(pred_slices)\n",
    "\n",
    "# -----------------------\n",
    "# SAVE SPECIFIC SLICES AS PNG\n",
    "# -----------------------\n",
    "num_slices = gt_complex.shape[0]\n",
    "slice_indices = [i for i in requested if 0 <= i < num_slices]\n",
    "if len(slice_indices) == 0:\n",
    "    raise ValueError(f\"No valid slices in requested={requested} for volume length {num_slices}\")\n",
    "\n",
    "for idx in slice_indices:\n",
    "    plot_slice(gt_complex[idx], under_complex[idx], pred_complex[idx], idx, None, max_val)\n",
    "    print(f\"Saved slice_{idx:03d}.png to {out_dir}\")\n",
    "\n",
    "# Optional: save a summary image\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_title(\"Volume Intensity Summary\", fontsize=18)\n",
    "ax.axis(\"off\")\n",
    "text = (\n",
    "    f\"GT Abs:    min={np.abs(gt_complex).min():.4f}, max={np.abs(gt_complex).max():.4f}\\n\"\n",
    "    f\"Under Abs: min={np.abs(under_complex).min():.4f}, max={np.abs(under_complex).max():.4f}\\n\"\n",
    "    f\"Pred Abs:  min={np.abs(pred_complex).min():.4f}, max={np.abs(pred_complex).max():.4f}\\n\\n\"\n",
    "    f\"GT Real:   min={gt_complex.real.min():.4f}, max={gt_complex.real.max():.4f}\\n\"\n",
    "    f\"GT Imag:   min={gt_complex.imag.min():.4f}, max={gt_complex.imag.max():.4f}\"\n",
    ")\n",
    "ax.text(0.05, 0.5, text, fontsize=12, va=\"center\")\n",
    "summary_out = os.path.join(out_dir, \"summary.png\")\n",
    "fig.savefig(summary_out, dpi=300, bbox_inches='tight', pad_inches=0.04)\n",
    "plt.close(fig)\n",
    "print(f\"‚úÖ Saved summary: {summary_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cad974-74f4-4a08-a86b-3b66642e4920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b31c40-77ff-41ef-bdea-88f39194d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob, os\n",
    "\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "file_path = kspace_files_list_val[0]\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Keys in file:\", list(f.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714067a-50ee-4911-93e2-52c38f6a1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_maps(model):\n",
    "    attn_maps = {}\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:\n",
    "                skip = getattr(layer, name)\n",
    "                attn = skip.fsa.sa.last_attn_map\n",
    "                if attn is not None:\n",
    "                    attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46beeea-3d2b-468c-880e-e83f17620af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_attention_grid(attn_maps):\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    for i, (name, attn) in enumerate(attn_maps.items(), 1):\n",
    "        plt.subplot(1, len(attn_maps), i)\n",
    "        plt.imshow(attn, cmap='viridis')\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd63e5a-b283-4a2b-a2ff-f55ba420f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "def save_attention_maps_to_pdf(attn_maps, save_path=\"attention_maps_new_fsa.pdf\"):\n",
    "    with PdfPages(save_path) as pdf:\n",
    "        for name, attn in attn_maps.items():\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(attn, cmap='viridis')\n",
    "            plt.title(f\"{name} Attention Map\")\n",
    "            plt.axis('off')\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "    print(f\"‚úÖ Saved attention maps to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8f80e-2ec3-4af2-9ff1-22e53ae51d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_maps = get_attention_maps(model)\n",
    "# plot_attention_grid(attn_maps)\n",
    "# save_attention_maps_to_pdf(attn_maps, \"attention_maps_from_volume000_mse_mpca_fsa.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7939e7-e36a-41cc-bfe1-35bbb1df0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# -- Extract attention maps from model, now including skip0 --\n",
    "def get_attention_maps(model):\n",
    "    attn_maps = {}\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:  # ‚¨ÖÔ∏è added skip0\n",
    "                skip = getattr(layer, name)\n",
    "                if hasattr(skip.fsa.sa, 'last_attn_map') and skip.fsa.sa.last_attn_map is not None:\n",
    "                    attn = skip.fsa.sa.last_attn_map\n",
    "                    attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n",
    "\n",
    "# -- Plot one row of attention maps --\n",
    "def plot_attention_maps_for_slice(attn_maps, slice_idx):\n",
    "    fig, axs = plt.subplots(1, len(attn_maps), figsize=(4 * len(attn_maps), 4))\n",
    "    for i, (name, attn) in enumerate(attn_maps.items()):\n",
    "        axs[i].imshow(attn, cmap='viridis')\n",
    "        axs[i].set_title(name)\n",
    "        axs[i].axis('off')\n",
    "    fig.suptitle(f\"Slice {slice_idx}\", fontsize=14)\n",
    "    return fig\n",
    "\n",
    "# -- Run volume through model and save attention maps to PDF --\n",
    "def process_volume_and_save_attention_pdf(h5_path, model, save_path=\"attention_all_slices.pdf\", key='image_under'):\n",
    "    with h5py.File(h5_path, 'r') as f, PdfPages(save_path) as pdf:\n",
    "        volume = f[key][...]  # shape: [num_slices, H, W, 2] or [num_slices, H, W]\n",
    "        if volume.ndim == 3:\n",
    "            volume = np.stack([volume, np.zeros_like(volume)], axis=-1)  # Make complex\n",
    "\n",
    "        num_slices = volume.shape[0]\n",
    "        for i in range(num_slices):\n",
    "            input_slice = np.expand_dims(volume[i], axis=0).astype(np.float32)  # [1, H, W, 2]\n",
    "            _ = model(input_slice, training=False)\n",
    "\n",
    "            attn_maps = get_attention_maps(model)\n",
    "            fig = plot_attention_maps_for_slice(attn_maps, i)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"‚úÖ Saved attention maps for all {num_slices} slices to: {save_path}\")\n",
    "process_volume_and_save_attention_pdf(\n",
    "    h5_path=\"D:/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    save_path=\"attention_maps_fsa.pdf\",\n",
    "    key='image_under'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c3cb5-ff6d-4cdc-a8cb-632f2a6b4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def get_attention_maps(model):\n",
    "    \"\"\"Return dict of attention maps found on SF_UNet_TF skip layers.\"\"\"\n",
    "    attn_maps = {}\n",
    "    for layer in model.layers:\n",
    "        # If your model itself is the SF_UNet_TF instance, consider checking the model object directly\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:\n",
    "                skip = getattr(layer, name)\n",
    "                # safe attribute check\n",
    "                if hasattr(skip, 'fsa') and hasattr(skip.fsa, 'sa') and hasattr(skip.fsa.sa, 'last_attn_map'):\n",
    "                    attn = skip.fsa.sa.last_attn_map\n",
    "                    if attn is not None:\n",
    "                        # adapt indexing if your attn shape differs\n",
    "                        attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n",
    "\n",
    "def plot_attention_row(attn_maps, under_img, full_img, slice_idx, attn_cmap='viridis'):\n",
    "    \"\"\"\n",
    "    attn_maps: Ordered dict-like (name->2D array)\n",
    "    under_img: (H, W, 2) or (H, W) -> will be converted to magnitude for display\n",
    "    full_img:  same as under_img (ground truth)\n",
    "    \"\"\"\n",
    "    # Ensure magnitude images\n",
    "    if under_img.ndim == 3 and under_img.shape[-1] == 2:\n",
    "        under_disp = np.abs(under_img[...,0] + 1j * under_img[...,1])\n",
    "    else:\n",
    "        under_disp = np.abs(under_img)\n",
    "\n",
    "    if full_img.ndim == 3 and full_img.shape[-1] == 2:\n",
    "        full_disp = np.abs(full_img[...,0] + 1j * full_img[...,1])\n",
    "    else:\n",
    "        full_disp = np.abs(full_img)\n",
    "\n",
    "    # Number of columns: under + attention maps + full\n",
    "    n_attn = len(attn_maps)\n",
    "    n_cols = 1 + max(0, n_attn) + 1\n",
    "\n",
    "    fig, axs = plt.subplots(1, n_cols, figsize=(4 * n_cols, 4))\n",
    "    if n_cols == 1:\n",
    "        axs = np.array([axs])  # keep indexing consistent\n",
    "\n",
    "    # Leftmost = under-sampled magnitude\n",
    "    axs[0].imshow(under_disp, cmap='gray')\n",
    "    axs[0].set_title(\"Under-sampled (Abs)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Middle = attention maps in order\n",
    "    for i, (name, attn) in enumerate(attn_maps.items(), start=1):\n",
    "        ax = axs[i]\n",
    "        # optional: set vmin/vmax for cross-slice consistency outside this function\n",
    "        ax.imshow(attn, cmap=attn_cmap)\n",
    "        ax.set_title(name)\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Rightmost = full-sampled magnitude\n",
    "    axs[-1].imshow(full_disp, cmap='gray')\n",
    "    axs[-1].set_title(\"Full-sampled (Abs)\")\n",
    "    axs[-1].axis('off')\n",
    "\n",
    "    fig.suptitle(f\"Slice {slice_idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ---------- Main processing & PDF saving ----------\n",
    "def process_volume_and_save_attention_pdf(h5_path, model, save_path=\"attention_with_under_and_full.pdf\",\n",
    "                                         key_under='image_under', key_full='image_full'):\n",
    "    with h5py.File(h5_path, 'r') as f, PdfPages(save_path) as pdf:\n",
    "        # read volumes\n",
    "        under_vol = f[key_under][...]   # expected shape: [num_slices, H, W, 2] or [num_slices, H, W]\n",
    "        full_vol = f[key_full][...]     # same shape\n",
    "\n",
    "        # ensure complex-like shape (H, W, 2) if stored as 3D\n",
    "        if under_vol.ndim == 3:\n",
    "            under_vol = np.stack([under_vol, np.zeros_like(under_vol)], axis=-1)\n",
    "        if full_vol.ndim == 3:\n",
    "            full_vol = np.stack([full_vol, np.zeros_like(full_vol)], axis=-1)\n",
    "\n",
    "        num_slices = under_vol.shape[0]\n",
    "        for i in range(num_slices):\n",
    "            # prepare input for model: [1, H, W, 2], float32\n",
    "            input_slice = np.expand_dims(under_vol[i], axis=0).astype(np.float32)\n",
    "\n",
    "            # forward pass (this should populate last_attn_map inside the skip blocks)\n",
    "            _ = model(input_slice, training=False)\n",
    "\n",
    "            # extract attention maps\n",
    "            attn_maps = get_attention_maps(model)  # dict: name -> 2D\n",
    "\n",
    "            # plot row with under | attn maps... | full\n",
    "            fig = plot_attention_row(attn_maps, under_vol[i], full_vol[i], slice_idx=i)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"‚úÖ Saved attention maps + under + full for {num_slices} slices to: {save_path}\")\n",
    "\n",
    "# Example usage (update path & model as needed)\n",
    "process_volume_and_save_attention_pdf(\n",
    "    h5_path=\"D:/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    save_path=\"attention_maps_with_under_full_mse_FSA.pdf\",\n",
    "    key_under='image_under',\n",
    "    key_full='image_full'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2249e69-f771-46bf-b5d4-b399d6230fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # <- small necessary addition\n",
    "\n",
    "# ---------- Main: process specific slices and save PNGs ----------\n",
    "def process_and_save_slices_png(h5_path, model, out_dir,\n",
    "                                slices=[0], key_under='image_under', key_full='image_full',\n",
    "                                dpi=300, figsize_per_col=4, attn_cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Minimal replacement to save specific slices as PNGs.\n",
    "    - slices: list of slice indices to process (e.g. [0,10,20]) or \"all\"\n",
    "    - out_dir: directory to save PNGs\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        under_vol = f[key_under][...]   # [S, H, W, 2] or [S, H, W]\n",
    "        full_vol = f[key_full][...]     # same\n",
    "\n",
    "    # make sure shape is (S, H, W, 2)\n",
    "    if under_vol.ndim == 3:\n",
    "        under_vol = np.stack([under_vol, np.zeros_like(under_vol)], axis=-1)\n",
    "    if full_vol.ndim == 3:\n",
    "        full_vol = np.stack([full_vol, np.zeros_like(full_vol)], axis=-1)\n",
    "\n",
    "    num_slices = under_vol.shape[0]\n",
    "    if slices == \"all\":\n",
    "        selected = list(range(num_slices))\n",
    "    else:\n",
    "        # filter valid indices\n",
    "        selected = [int(s) for s in slices if 0 <= int(s) < num_slices]\n",
    "\n",
    "    if len(selected) == 0:\n",
    "        raise ValueError(\"No valid slices selected.\")\n",
    "\n",
    "    for idx in selected:\n",
    "        inp = np.expand_dims(under_vol[idx], axis=0).astype(np.float32)\n",
    "        # forward pass to populate attention maps\n",
    "        _ = model(inp, training=False)\n",
    "\n",
    "        attn_maps = get_attention_maps(model)  # same helper you already have\n",
    "\n",
    "        # build figure (reuses your plot_attention_row which returns a fig)\n",
    "        fig = plot_attention_row(attn_maps, under_vol[idx], full_vol[idx], slice_idx=idx, attn_cmap=attn_cmap)\n",
    "\n",
    "        # Save PNG\n",
    "        out_name = f\"fsa_perp_slice_{idx:03d}.png\"\n",
    "        out_path = os.path.join(out_dir, out_name)\n",
    "        fig.savefig(out_path, dpi=dpi, bbox_inches='tight', pad_inches=0.05)\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"‚úÖ Saved {len(selected)} images to: {out_dir}\")\n",
    "\n",
    "# ---------- Example usage ----------\n",
    "process_and_save_slices_png(\n",
    "    h5_path=\"D:/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    out_dir=\"attention_pngs\",    # where PNGs will go\n",
    "    slices=[18, 19, 20],         # <-- specify slices you want\n",
    "    dpi=300,                    # change if you want higher/lower resolution\n",
    "    figsize_per_col=4,          # not used here directly (plot_attention_row uses fixed figsize), kept for compatibility\n",
    "    attn_cmap='viridis'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fc24b-13d3-4f9b-804e-601292107f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_maps(model):\n",
    "    attn_maps = {}\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:\n",
    "                skip = getattr(layer, name)\n",
    "                attn = skip.fsa.sa.last_attn_map\n",
    "                if attn is not None:\n",
    "                    attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n",
    "\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_attention_maps_for_slice(attn_maps, slice_idx):\n",
    "    fig, axs = plt.subplots(1, len(attn_maps), figsize=(16, 4))\n",
    "    for i, (name, attn) in enumerate(attn_maps.items()):\n",
    "        axs[i].imshow(attn, cmap='viridis')\n",
    "        axs[i].set_title(f\"{name}\")\n",
    "        axs[i].axis('off')\n",
    "    fig.suptitle(f\"Slice {slice_idx}\", fontsize=14)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8c35d06-2573-4564-8060-dc181daeef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def process_volume_and_save_attention_pdf(h5_path, model, save_path=\"attention_all_slices_mpca_fsa_mse.pdf\", key='image_under'):\n",
    "    with h5py.File(h5_path, 'r') as f, PdfPages(save_path) as pdf:\n",
    "        volume = f[key][...]  # shape: [num_slices, H, W, 2] or [num_slices, H, W]\n",
    "        if volume.ndim == 3:  # Real-only, no complex\n",
    "            volume = np.stack([volume, np.zeros_like(volume)], axis=-1)  # Add imaginary\n",
    "\n",
    "        num_slices = volume.shape[0]\n",
    "\n",
    "        for i in range(num_slices):\n",
    "            input_slice = np.expand_dims(volume[i], axis=0).astype(np.float32)  # [1, H, W, 2]\n",
    "\n",
    "            # Run forward pass\n",
    "            _ = model(input_slice)\n",
    "\n",
    "            # Extract attention maps\n",
    "            attn_maps = get_attention_maps(model)\n",
    "\n",
    "            # Plot and save figure\n",
    "            fig = plot_attention_maps_for_slice(attn_maps, i)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"‚úÖ Saved all {num_slices} slices' attention maps to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee25144f-6155-4b77-9e2f-6c9e474b2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved all 40 slices' attention maps to attention_maps_volume_000_mpca_fsa_perploss.pdf\n"
     ]
    }
   ],
   "source": [
    "# model = build_dual_output_model()\n",
    "# model.load_weights(\"weight_sfu_fastmri_complex_perploss_fsa.h5\")\n",
    "\n",
    "process_volume_and_save_attention_pdf(\n",
    "    h5_path=\"G:/val_norm/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    save_path=\"attention_maps_volume_000_mpca_fsa_perploss.pdf\",\n",
    "    key='image_under'  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2981da0-00bc-47a6-a65a-5079a2e31302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
