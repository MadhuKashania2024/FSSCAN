{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e936b9-7232-443e-9e8a-6d0392f5a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dbc21ba-ab1e-4cd6-81d8-672670e027d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og shape: (1, 1, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "mask = np.load(r\"C:\\Users\\Research\\aman fastmri\\Data\\mask_4x_320_random.npy\")  # Shape: (1, 320, 320)\n",
    "print(\"og shape:\", mask.shape)\n",
    "\n",
    "# # Use np.tile to reshape it to (1, 320, 320, 1)\n",
    "# # var_sampling_mask = np.tile(var_sampling_mask[..., np.newaxis], (1, 1, 1, 1))  # Final shape: (1, 320, 320, 1)\n",
    "# mask = np.tile(mask, (1, 320, 1, 2))  # tile height=320 times\n",
    "\n",
    "# # Confirm final shape\n",
    "# print(\"New shape:\", mask.shape) \n",
    "# mask_for_plot = np.squeeze(mask[...,0])  # Shape: (320, 320)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(mask_for_plot, cmap='gray')\n",
    "# plt.title(\"Tiled Sampling Mask (320x320)\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fad8987-86b0-40f4-979e-34f9fa2b8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MRISliceGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, file_list, batch_size=4, shuffle=True, mask=None):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.mask = mask  # Shape: (1, 320, 320, 2)\n",
    "        self.slice_index_map = []\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        for file_idx, file_path in enumerate(self.file_list):\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                num_slices = f['image_under'].shape[0]\n",
    "                for slice_idx in range(num_slices):\n",
    "                    self.slice_index_map.append((file_idx, slice_idx))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.slice_index_map) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_map = self.slice_index_map[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        input_img_batch = []\n",
    "        target_img_batch = []\n",
    "        input_kspace_batch = []\n",
    "\n",
    "        for file_idx, slice_idx in batch_map:\n",
    "            with h5py.File(self.file_list[file_idx], 'r') as f:\n",
    "                input_img = f['image_under'][slice_idx]       # shape: [H, W, 2]\n",
    "                target_img = f['image_full'][slice_idx]       # shape: [H, W, 2]\n",
    "                #input_kspace = f['kspace_under'][slice_idx]   # shape: [H, W, 2]\n",
    "\n",
    "                input_img_batch.append(input_img)\n",
    "                target_img_batch.append(target_img)\n",
    "                #input_kspace_batch.append(input_kspace)\n",
    "\n",
    "        x_img = np.stack(input_img_batch, axis=0)\n",
    "        #x_kspace = np.stack(input_kspace_batch, axis=0)\n",
    "        y_batch = np.stack(target_img_batch, axis=0)\n",
    "\n",
    "        # if self.mask is not None:\n",
    "        #     actual_batch_size = len(x_img)\n",
    "        #     if self.mask.shape == (1, 320, 320, 2):\n",
    "        #         mask_batch = np.tile(self.mask, (actual_batch_size, 1, 1, 1))\n",
    "        #     else:\n",
    "        #         raise ValueError(\"Mask must have shape (1, 320, 320, 2)\")\n",
    "        #     return [x_img, mask_batch, x_kspace], y_batch\n",
    "        # else:\n",
    "        #     return [x_img, x_kspace], y_batch\n",
    "        return x_img, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.slice_index_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3febe028-3e5b-495d-80a1-31fa79114195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = r\"E:\\fastmri_singlecoil_FSSCAN\\train_norm\"\n",
    "val_folder = r\"E:\\fastmri_singlecoil_FSSCAN\\val_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c0fa50-26bb-4ef6-962b-ddaef27463cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8675\n",
      "1784\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "kspace_files_list_train = sorted(glob.glob(os.path.join(train_folder, \"*.h5\")))\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "\n",
    "# half_train = 20\n",
    "# half_val = 10\n",
    "half_train = len(kspace_files_list_train) \n",
    "half_val = len(kspace_files_list_val) \n",
    "# print(\"half_train\",half_train)\n",
    "# print(\"half_val\",half_val)\n",
    "kspace_files_list_train = kspace_files_list_train[:half_train]\n",
    "kspace_files_list_val = kspace_files_list_val[:half_val]\n",
    "\n",
    "# Create generators\n",
    "# train_gen = MRISliceGeneratorMag(kspace_files_list_train,batch_size=4, shuffle=True,mask=mask)\n",
    "# val_gen = MRISliceGeneratorMag(kspace_files_list_val, batch_size=4, shuffle=False,mask=mask)\n",
    "train_gen = MRISliceGenerator(kspace_files_list_train,batch_size=4, shuffle=True)\n",
    "val_gen = MRISliceGenerator(kspace_files_list_val, batch_size=4, shuffle=False)\n",
    "\n",
    "print(len(train_gen))  \n",
    "print(len(val_gen))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7ab52d-ea9c-44a0-a8e2-b434fde50c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DCRCNN.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95f7e68-86e6-4c31-8e1e-73ce6602e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß TRAINING CONFIGURATION\n",
      "============================================================\n",
      " Save Directory:       ./SavedModels_DCRCNN_full_2\n",
      " Model Dimensions:     320x320\n",
      " Epochs:               50\n",
      " Learning Rate:        0.0001\n",
      " Init Checkpoint:      ./SavedModels_DCRCNN_full_2\\init_ckpt\n",
      " Best Checkpoint:      ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      " Final Checkpoint:     ./SavedModels_DCRCNN_full_2\\final_ckpt\n",
      "============================================================\n",
      "Model: \"DCR_CNN_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " zf_input (InputLayer)          [(None, 320, 320, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_initial (Conv2D)          (None, 320, 320, 64  1216        ['zf_input[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_1 (DCRBlock)         (None, 320, 320, 64  119936      ['conv_initial[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_2 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_1[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_3 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_2[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_4 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_3[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_5 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_4[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_6 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_5[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_7 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_6[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_8 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_7[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_9 (DCRBlock)         (None, 320, 320, 64  119936      ['dcr_block_8[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dcr_block_10 (DCRBlock)        (None, 320, 320, 64  119936      ['dcr_block_9[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_final (Conv2D)            (None, 320, 320, 2)  1154        ['dcr_block_10[0][0]']           \n",
      "                                                                                                  \n",
      " global_residual (Add)          (None, 320, 320, 2)  0           ['zf_input[0][0]',               \n",
      "                                                                  'conv_final[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,201,730\n",
      "Trainable params: 1,201,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "‚ÑπÔ∏è No checkpoint found. Training from scratch.\n",
      "\n",
      "üöÄ STARTING TRAINING...\n",
      "============================================================\n",
      "Epoch 1/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 0.0010      \n",
      "Epoch 1: val_loss improved from inf to 0.00087, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4788s 551ms/step - loss: 0.0010 - val_loss: 8.7359e-04 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.8238e-04     \n",
      "Epoch 2: val_loss improved from 0.00087 to 0.00083, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4811s 555ms/step - loss: 7.8238e-04 - val_loss: 8.3032e-04 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.5296e-04     \n",
      "Epoch 3: val_loss improved from 0.00083 to 0.00081, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4815s 555ms/step - loss: 7.5296e-04 - val_loss: 8.0557e-04 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.3510e-04     \n",
      "Epoch 4: val_loss improved from 0.00081 to 0.00079, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4813s 555ms/step - loss: 7.3510e-04 - val_loss: 7.9090e-04 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.2437e-04     \n",
      "Epoch 5: val_loss did not improve from 0.00079\n",
      "8675/8675 [==============================] - 4804s 554ms/step - loss: 7.2437e-04 - val_loss: 8.1603e-04 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.1889e-04     \n",
      "Epoch 6: val_loss improved from 0.00079 to 0.00078, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4797s 553ms/step - loss: 7.1889e-04 - val_loss: 7.8053e-04 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.1293e-04     \n",
      "Epoch 7: val_loss improved from 0.00078 to 0.00077, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4783s 551ms/step - loss: 7.1293e-04 - val_loss: 7.7471e-04 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.0850e-04     \n",
      "Epoch 8: val_loss improved from 0.00077 to 0.00077, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4778s 551ms/step - loss: 7.0850e-04 - val_loss: 7.7314e-04 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.0631e-04     \n",
      "Epoch 9: val_loss improved from 0.00077 to 0.00077, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4772s 550ms/step - loss: 7.0631e-04 - val_loss: 7.6913e-04 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.0348e-04     \n",
      "Epoch 10: val_loss improved from 0.00077 to 0.00077, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4622s 533ms/step - loss: 7.0348e-04 - val_loss: 7.6634e-04 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 7.0093e-04     \n",
      "Epoch 11: val_loss improved from 0.00077 to 0.00077, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4646s 536ms/step - loss: 7.0093e-04 - val_loss: 7.6592e-04 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.9923e-04     \n",
      "Epoch 12: val_loss improved from 0.00077 to 0.00077, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4654s 537ms/step - loss: 6.9923e-04 - val_loss: 7.6521e-04 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.9804e-04     \n",
      "Epoch 13: val_loss improved from 0.00077 to 0.00076, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4668s 538ms/step - loss: 6.9804e-04 - val_loss: 7.6263e-04 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.9615e-04     \n",
      "Epoch 14: val_loss improved from 0.00076 to 0.00076, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4712s 543ms/step - loss: 6.9615e-04 - val_loss: 7.6035e-04 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.9486e-04     \n",
      "Epoch 15: val_loss improved from 0.00076 to 0.00076, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4790s 552ms/step - loss: 6.9486e-04 - val_loss: 7.6000e-04 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.9387e-04     \n",
      "Epoch 16: val_loss improved from 0.00076 to 0.00076, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4768s 550ms/step - loss: 6.9387e-04 - val_loss: 7.5899e-04 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.9269e-04     \n",
      "Epoch 17: val_loss did not improve from 0.00076\n",
      "8675/8675 [==============================] - 4802s 554ms/step - loss: 6.9269e-04 - val_loss: 7.5931e-04 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.9174e-04     \n",
      "Epoch 18: val_loss improved from 0.00076 to 0.00076, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8675/8675 [==============================] - 4875s 562ms/step - loss: 6.9174e-04 - val_loss: 7.5651e-04 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8811e-04     \n",
      "Epoch 19: val_loss improved from 0.00076 to 0.00075, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4878s 562ms/step - loss: 6.8811e-04 - val_loss: 7.5395e-04 - lr: 5.0000e-05\n",
      "Epoch 20/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8750e-04     \n",
      "Epoch 20: val_loss improved from 0.00075 to 0.00075, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4880s 563ms/step - loss: 6.8750e-04 - val_loss: 7.5382e-04 - lr: 5.0000e-05\n",
      "Epoch 21/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8707e-04     \n",
      "Epoch 21: val_loss improved from 0.00075 to 0.00075, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4878s 562ms/step - loss: 6.8707e-04 - val_loss: 7.5326e-04 - lr: 5.0000e-05\n",
      "Epoch 22/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8665e-04     \n",
      "Epoch 22: val_loss improved from 0.00075 to 0.00075, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4876s 562ms/step - loss: 6.8665e-04 - val_loss: 7.5313e-04 - lr: 5.0000e-05\n",
      "Epoch 23/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8625e-04     \n",
      "Epoch 23: val_loss improved from 0.00075 to 0.00075, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4871s 561ms/step - loss: 6.8625e-04 - val_loss: 7.5252e-04 - lr: 5.0000e-05\n",
      "Epoch 24/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8589e-04     \n",
      "Epoch 24: val_loss improved from 0.00075 to 0.00075, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4864s 561ms/step - loss: 6.8589e-04 - val_loss: 7.5165e-04 - lr: 5.0000e-05\n",
      "Epoch 25/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8558e-04     \n",
      "Epoch 25: val_loss did not improve from 0.00075\n",
      "8675/8675 [==============================] - 4847s 559ms/step - loss: 6.8558e-04 - val_loss: 7.5187e-04 - lr: 5.0000e-05\n",
      "Epoch 26/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8519e-04     \n",
      "Epoch 26: val_loss did not improve from 0.00075\n",
      "8675/8675 [==============================] - 4836s 557ms/step - loss: 6.8519e-04 - val_loss: 7.5374e-04 - lr: 5.0000e-05\n",
      "Epoch 27/50\n",
      "8675/8675 [==============================] - ETA: 0s - loss: 6.8494e-04     \n",
      "Epoch 27: val_loss improved from 0.00075 to 0.00075, saving model to ./SavedModels_DCRCNN_full_2\\best_ckpt\n",
      "8675/8675 [==============================] - 4746s 547ms/step - loss: 6.8494e-04 - val_loss: 7.5086e-04 - lr: 5.0000e-05\n",
      "Epoch 28/50\n",
      "6575/8675 [=====================>........] - ETA: 17:40 - loss: 6.8492e-04  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müöÄ STARTING TRAINING...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    105\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ TRAINING COMPLETED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Save Final Weights\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WNet\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ============================================================\n",
    "# Directory Setup\n",
    "# ============================================================\n",
    "save_dir = \"./SavedModels_DCRCNN_full_2\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "H, W = 320, 320\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# TensorFlow checkpoint paths (NO .h5)\n",
    "INIT_CKPT  = os.path.join(save_dir, \"init_ckpt\")\n",
    "BEST_CKPT  = os.path.join(save_dir, \"best_ckpt\")\n",
    "FINAL_CKPT = os.path.join(save_dir, \"final_ckpt\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîß TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\" Save Directory:       {save_dir}\")\n",
    "print(f\" Model Dimensions:     {H}x{W}\")\n",
    "print(f\" Epochs:               {EPOCHS}\")\n",
    "print(f\" Learning Rate:        {LEARNING_RATE}\")\n",
    "print(f\" Init Checkpoint:      {INIT_CKPT}\")\n",
    "print(f\" Best Checkpoint:      {BEST_CKPT}\")\n",
    "print(f\" Final Checkpoint:     {FINAL_CKPT}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# Model Setup\n",
    "# ============================================================\n",
    "model = build_dcr_cnn(\n",
    "    input_shape=(320, 320, 2),\n",
    "    num_dcr_blocks=10,   # or 3 / 8\n",
    "    num_features=64,\n",
    "    growth_rate=32\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Optimizer & Compile\n",
    "# ============================================================\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "model.summary()\n",
    "# ============================================================\n",
    "# Load Initial Weights (Optional Resume)\n",
    "# ============================================================\n",
    "if tf.train.latest_checkpoint(save_dir):\n",
    "    model.load_weights(tf.train.latest_checkpoint(save_dir))\n",
    "    print(\"‚úÖ Loaded latest checkpoint\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No checkpoint found. Training from scratch.\")\n",
    "\n",
    "# ============================================================\n",
    "# Callbacks\n",
    "# ============================================================\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=BEST_CKPT,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_cb, earlystop_cb, reduce_lr_cb]\n",
    "\n",
    "# ============================================================\n",
    "# Training\n",
    "# ============================================================\n",
    "print(\"\\nüöÄ STARTING TRAINING...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ TRAINING COMPLETED\")\n",
    "\n",
    "# ============================================================\n",
    "# Save Final Weights\n",
    "# ============================================================\n",
    "model.save_weights(FINAL_CKPT)\n",
    "print(f\"‚úÖ Final weights saved to {FINAL_CKPT}\")\n",
    "\n",
    "# ============================================================\n",
    "# Training Analysis\n",
    "# ============================================================\n",
    "if history:\n",
    "    print(\"\\nüìä TRAINING ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    best_epoch = np.argmin(history.history[\"val_loss\"]) + 1\n",
    "    print(f\" Best Epoch: {best_epoch}\")\n",
    "    print(f\" Best Val Loss: {np.min(history.history['val_loss']):.6f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Plot Training Curves\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63b9cb-8095-41e2-85ce-5112daca569a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
