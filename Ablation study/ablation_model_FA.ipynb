{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547fde1c-5b75-4c1e-8101-62d377a83ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe499da-e53d-40d9-b5da-69e72d83e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveGlobalFilter(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=10):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: [B, H, W, C, 2]\n",
    "        _, H, W, C, _ = input_shape\n",
    "        self.H, self.W, self.C = H, W, C\n",
    "\n",
    "        # initializer = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "        self.filter = self.add_weight(\n",
    "            shape=(C, H, W, 2),\n",
    "            # initializer=initializer,\n",
    "            trainable=True,\n",
    "            name='complex_filter'\n",
    "        )\n",
    "\n",
    "        self.mask_low = self._create_static_mask()\n",
    "        self.mask_high = 1.0 - self.mask_low\n",
    "\n",
    "    def _create_static_mask(self):\n",
    "        mask = tf.zeros((self.H, self.W), dtype=tf.float32)\n",
    "        crow, ccol = self.H // 2, self.W // 2\n",
    "        r = self.ratio\n",
    "\n",
    "        indices = tf.stack(tf.meshgrid(\n",
    "            tf.range(crow - r, crow + r),\n",
    "            tf.range(ccol - r, ccol + r),\n",
    "            indexing='ij'\n",
    "        ), axis=-1)\n",
    "        indices = tf.reshape(indices, [-1, 2])\n",
    "        updates = tf.ones((tf.shape(indices)[0],), dtype=tf.float32)\n",
    "\n",
    "        return tf.Variable(tf.tensor_scatter_nd_update(mask, indices, updates), trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        tf.debugging.check_numerics(x, \"Input to AGF has NaNs/Infs\")\n",
    "        # x: [B, H, W, C, 2]\n",
    "        x = tf.transpose(x, [0, 3, 1, 2, 4])  # [B, C, H, W, 2]\n",
    "        x_freq = fft2c_tf(x)                 # [B, C, H, W, 2]\n",
    "        tf.debugging.check_numerics(x_freq, \"FFT2 output has NaNs/Infs\")\n",
    "\n",
    "\n",
    "        # Convert learnable filter to complex\n",
    "        real_part = self.filter[..., 0]\n",
    "        imag_part = self.filter[..., 1]\n",
    "        weight = tf.complex(real_part, imag_part)  # [C, H, W]\n",
    "        weight = tf.expand_dims(weight, axis=0)    # [1, C, H, W]\n",
    "\n",
    "        # Cast masks\n",
    "        mask_low_c = tf.cast(tf.reshape(self.mask_low, [1, 1, self.H, self.W]), tf.complex64)\n",
    "        mask_high_c = tf.cast(tf.reshape(self.mask_high, [1, 1, self.H, self.W]), tf.complex64)\n",
    "\n",
    "        # Convert x_freq to complex\n",
    "        x_freq_c = tf.complex(x_freq[..., 0], x_freq[..., 1])  # [B, C, H, W]\n",
    "\n",
    "        x_low = x_freq_c * mask_low_c\n",
    "        x_high = x_freq_c * mask_high_c\n",
    "\n",
    "        x_high_filtered = x_high * weight\n",
    "        x_combined = x_low + x_high_filtered\n",
    "        # x_low_filtered = x_low * weight\n",
    "        # x_combined = x_low_filtered + x_high  # [B, C, H, W]\n",
    "\n",
    "        x_combined = tf.stack([tf.math.real(x_combined), tf.math.imag(x_combined)], axis=-1)  # [B, C, H, W, 2]\n",
    "        x_combined = tf.transpose(x_combined, [0, 2, 3, 1, 4])  # [B, H, W, C, 2]\n",
    "\n",
    "        # Apply IFFT\n",
    "        x_out = ifft2c_tf(x_combined)  # [B, H, W, C, 2]\n",
    "        tf.debugging.check_numerics(x_out, \"IFFT2 output has NaNs/Infs\")\n",
    "        return x_out\n",
    "\n",
    "# # # Example dummy input: [batch, height, width, channels]\n",
    "# dummy_input = tf.random.normal((2, 512, 512, 64,2))\n",
    "\n",
    "# # Instantiate layer\n",
    "# agf = AdaptiveGlobalFilter(ratio=10)\n",
    "\n",
    "# # Forward pass\n",
    "# output = agf(dummy_input)\n",
    "\n",
    "# print(\"Input shape: \", dummy_input.shape)\n",
    "# print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f616e04-5902-4c4a-9538-147730d50040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Lambda, Add, LeakyReLU,  \\\n",
    "                                    MaxPooling2D, concatenate, UpSampling2D,\\\n",
    "                                    Multiply, ZeroPadding2D, Cropping2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9eb834c-8153-4ede-9918-a5f1cd5e32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./layer.ipynb\n",
    "# %run ./activation.ipynb\n",
    "\n",
    "# %run ./fft.ipynb\n",
    "\n",
    "%run ./Modules/layer.ipynb\n",
    "%run ./Modules/activation.ipynb\n",
    "\n",
    "%run ./Modules/fft.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab4f92f-d6ee-4ecc-9c0f-84ed718cab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class ComplexEncoderTF(Model):\n",
    "    def __init__(self, input_shape=(320, 320, 2)):\n",
    "        super(ComplexEncoderTF, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.block1_conv1 = complex_Conv2D(64, kernel_size=3, padding='same')\n",
    "        self.block1_conv2 = complex_Conv2D(64, kernel_size=3, padding='same')\n",
    "        self.pool1 = ComplexMaxPool2D_mag(pool_size=(2, 2))\n",
    "\n",
    "        # Block 2\n",
    "        self.block2_conv1 = complex_Conv2D(128, kernel_size=3, padding='same')\n",
    "        self.block2_conv2 = complex_Conv2D(128, kernel_size=3, padding='same')\n",
    "        self.pool2 = ComplexMaxPool2D_mag(pool_size=(2, 2))\n",
    "\n",
    "        # Block 3\n",
    "        self.block3_conv1 = complex_Conv2D(256, kernel_size=3, padding='same')\n",
    "        self.block3_conv2 = complex_Conv2D(256, kernel_size=3, padding='same')\n",
    "        self.pool3 = ComplexMaxPool2D_mag(pool_size=(2, 2))\n",
    "\n",
    "        # Block 4\n",
    "        self.block4_conv1 = complex_Conv2D(512, kernel_size=3, padding='same')\n",
    "        self.block4_conv2 = complex_Conv2D(512, kernel_size=3, padding='same')\n",
    "        self.pool4 = ComplexMaxPool2D_mag(pool_size=(2, 2))\n",
    "\n",
    "        # Block 5 (no pooling)\n",
    "        self.block5_conv1 = complex_Conv2D(512, kernel_size=3, padding='same')\n",
    "        self.block5_conv2 = complex_Conv2D(512, kernel_size=3, padding='same')\n",
    "\n",
    "        self.build((None, *input_shape))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        real = tf.expand_dims(inputs[..., 0], axis=-1)\n",
    "        imag = tf.expand_dims(inputs[..., 1], axis=-1)\n",
    "\n",
    "        # Block 1\n",
    "        r, i = self.block1_conv1(real, imag)\n",
    "        r, i = CReLU(r, i)\n",
    "        r, i = self.block1_conv2(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        feat1 = (r, i)\n",
    "        r, i = self.pool1(r, i)\n",
    "\n",
    "        # Block 2\n",
    "        r, i = self.block2_conv1(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        r, i = self.block2_conv2(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        feat2 = (r, i)\n",
    "        r, i = self.pool2(r, i)\n",
    "\n",
    "        # Block 3\n",
    "        r, i = self.block3_conv1(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        r, i = self.block3_conv2(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        feat3 = (r, i)\n",
    "        r, i = self.pool3(r, i)\n",
    "\n",
    "        # Block 4\n",
    "        r, i = self.block4_conv1(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        r, i = self.block4_conv2(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        feat4 = (r, i)\n",
    "        r, i = self.pool4(r, i)\n",
    "\n",
    "        # Block 5 (no pooling)\n",
    "        r, i = self.block5_conv1(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        r, i = self.block5_conv2(r, i)\n",
    "        r, i = CReLU(r, i)\n",
    "        feat5 = (r, i)\n",
    "\n",
    "        return feat1, feat2, feat3, feat4, feat5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ffe79af-1ed1-4a7a-8ded-d53176853fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSA(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=10):\n",
    "        super().__init__()\n",
    "        self.agf = AdaptiveGlobalFilter(ratio=ratio)\n",
    "        #self.sa = SpatialAttention()\n",
    "\n",
    "    def call(self, x, return_attn=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, H, W, C, 2]\n",
    "        Returns:\n",
    "            Tensor of shape [B, H, W, C, 2]\n",
    "        \"\"\"\n",
    "        # tf.print(\"FSA input stats:\", tf.reduce_min(x), tf.reduce_max(x), tf.reduce_mean(x))\n",
    "\n",
    "        out1 = self.agf(x)  # Frequency attention\n",
    "        #out1 = self.agf(x)\n",
    "        # if return_attn:\n",
    "        #     out2, attn_map = self.sa(x, return_attn=True)\n",
    "        #     out = out2\n",
    "        #     return out, attn_map\n",
    "        # else:\n",
    "        #     out2 = self.sa(x)\n",
    "        #     out = out2\n",
    "        #     return out\n",
    "        return out1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa0f4e9-2ee4-4313-b602-1c947ee73c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnection(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio, input_channel1, size):\n",
    "        super().__init__()\n",
    "        self.fsa = FSA(ratio=ratio)\n",
    "     \n",
    "    def call(self, input1, return_attn=False):\n",
    "        real1, imag1 = input1\n",
    "     \n",
    "        fsa_input = tf.concat([real1[..., None], imag1[..., None]], axis=-1)\n",
    "     \n",
    "        if return_attn:\n",
    "            fsa_out, attn_map = self.fsa(fsa_input, return_attn=True)\n",
    "        else:\n",
    "            fsa_out = self.fsa(fsa_input)\n",
    "\n",
    "      \n",
    "        return fsa_out[..., 0], fsa_out[..., 1]\n",
    "# batch_size = 1\n",
    "# height, width = 64, 64\n",
    "# input_channel1 = 8\n",
    "# input_channel2 = 16\n",
    "# size = (64, 64)\n",
    "\n",
    "# real1 = tf.random.normal((batch_size, height, width, input_channel1))\n",
    "# imag1 = tf.random.normal((batch_size, height, width, input_channel1))\n",
    "# real2 = tf.random.normal((batch_size, 32, 32, input_channel2))\n",
    "# imag2 = tf.random.normal((batch_size, 32, 32, input_channel2))\n",
    "\n",
    "# # Create and run layer\n",
    "# skip = SkipConnection(ratio=4, input_channel1=input_channel1,  size=size)\n",
    "# out_real, out_imag = skip((real1, imag1), (real2, imag2))\n",
    "\n",
    "# print(\"✅ Output Real Shape:\", out_real.shape)\n",
    "# print(\"✅ Output Imag Shape:\", out_imag.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6925e9b6-12cf-4af5-b7bd-7d750f8542b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexUnetUpTF(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels):\n",
    "        super(ComplexUnetUpTF, self).__init__()\n",
    "        self.upsample = ComplexUpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = complex_Conv2D(out_channels, kernel_size=3, padding='same')\n",
    "        self.conv2 = complex_Conv2D(out_channels, kernel_size=3, padding='same')\n",
    "        \n",
    "        # self.dense_block = DensBlock(out_channels)\n",
    "\n",
    "    def call(self, real_input1, imag_input1, real_input2, imag_input2):\n",
    "        # Upsample\n",
    "        up_real, up_imag = self.upsample(real_input2, imag_input2)\n",
    "\n",
    "        # Concatenate with skip connection\n",
    "        concat_real, concat_imag = concatenate_with(real_input1, imag_input1, up_real, up_imag)\n",
    "\n",
    "        # Proper flow through both conv layers\n",
    "        out_real, out_imag = self.conv1(concat_real, concat_imag)\n",
    "        out_real, out_imag = CReLU(out_real, out_imag)\n",
    "        out_real, out_imag = self.conv2(out_real, out_imag)\n",
    "        out_real, out_imag = CReLU(out_real, out_imag)\n",
    "\n",
    "        return out_real, out_imag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431f0db2-b26e-4604-b144-650b68d2966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate  # Ensure this is imported\n",
    "\n",
    "class SF_UNet_TF(Model):\n",
    "    def __init__(self, input_shape=(320, 320, 2), num_classes=2):\n",
    "        super().__init__()\n",
    "        self.encoder = ComplexEncoderTF(input_shape=input_shape)\n",
    "\n",
    "        self.skip4 = SkipConnection(ratio=10, input_channel1=256,  size=40)\n",
    "        self.skip3 = SkipConnection(ratio=10, input_channel1=128,  size=80)\n",
    "        self.skip2 = SkipConnection(ratio=10, input_channel1=64,  size=160)\n",
    "        self.skip1 = SkipConnection(ratio=10, input_channel1=32,  size=320)\n",
    "\n",
    "        self.unet_up4 = ComplexUnetUpTF(512)\n",
    "        self.unet_up3 = ComplexUnetUpTF(256)\n",
    "        self.unet_up2 = ComplexUnetUpTF(128)\n",
    "        self.unet_up1 = ComplexUnetUpTF(64)\n",
    "\n",
    "        self.final_conv = complex_Conv2D(filters=num_classes, kernel_size=1, activation='linear')\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Encoder\n",
    "        feat1, feat2, feat3, feat4, feat5 = self.encoder(inputs)\n",
    "    \n",
    "        # Decoder stage 4\n",
    "        skip4_r, skip4_i = self.skip4(feat4)\n",
    "        decoder4 = self.unet_up4(skip4_r, skip4_i, feat5[0], feat5[1])\n",
    "    \n",
    "        # Decoder stage 3\n",
    "        skip3_r, skip3_i = self.skip3(feat3)\n",
    "        decoder3 = self.unet_up3(skip3_r, skip3_i, decoder4[0], decoder4[1])\n",
    "    \n",
    "        # Decoder stage 2\n",
    "        skip2_r, skip2_i = self.skip2(feat2)\n",
    "        decoder2 = self.unet_up2(skip2_r, skip2_i, decoder3[0], decoder3[1])\n",
    "    \n",
    "        # Decoder stage 1\n",
    "        skip1_r, skip1_i = self.skip1(feat1)\n",
    "        decoder1 = self.unet_up1(skip1_r, skip1_i, decoder2[0], decoder2[1])\n",
    "    \n",
    "        # Final 1x1 convolution\n",
    "        real_out, imag_out = self.final_conv(decoder1[0], decoder1[1])\n",
    "    \n",
    "        # Concatenate along last dimension: (B, H, W, C) -> (B, H, W, 2C)\n",
    "        output = concatenate([real_out, imag_out], axis=-1)\n",
    "    \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d193355-84ca-47ba-929f-9f60e21abdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 320, 320, 2)]     0         \n",
      "                                                                 \n",
      " sf_u_net_tf (SF_UNet_TF)    (None, 320, 320, 2)       22216898  \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 320, 320, 2)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,216,898\n",
      "Trainable params: 22,080,898\n",
      "Non-trainable params: 136,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def build_dual_output_model(kshape=(3, 3), H=320, W=320, channels=2):\n",
    "    input_img = Input(shape=(H, W, channels))\n",
    "\n",
    "    # Image-domain SF_UNet_TF only\n",
    "    unet = SF_UNet_TF()\n",
    "    output_img = unet(input_img)\n",
    "\n",
    "    # Assign a name to the output for use in loss dict\n",
    "    output_img = Lambda(lambda x: x)(output_img)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=input_img,\n",
    "        outputs=output_img\n",
    "    )\n",
    "\n",
    "    return model\n",
    "model = build_dual_output_model(H=320, W=320)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0757837-86d4-4471-93ef-6cc48d12bd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdc848-9483-4973-a9eb-9b1c91903626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
