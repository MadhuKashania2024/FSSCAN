{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1a001a-6efd-4a72-ab79-15dde44dfafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 320, 320, 2)]     0         \n",
      "                                                                 \n",
      " sf_u_net_tf_2 (SF_UNet_TF)  (None, 320, 320, 2)       11747754  \n",
      "                                                                 \n",
      " lambda_2 (Lambda)           (None, 320, 320, 2)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,747,754\n",
      "Trainable params: 11,747,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# %run ./Modules/cv_can_new.ipynb\n",
    "#%run sfanet_new-Copy2.ipynb\n",
    "#sfanet_new-Copy2.ipynb\n",
    "%run sfanet_new_mpca_fsa-Copy1.ipynb\n",
    "#%run \"C:\\\\Users\\\\user\\\\aman_fastmri\\\\sfanet_new_mpca_fsa.ipynb\"\n",
    "#sfanet_new_mpca_fsa-Copy1\n",
    "# %run sfanet_new_mpca_fsa.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "344b0973-bf63-48f2-9f68-5124962a6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_dual_output_model()\n",
    "# model.load_weights(\".\\SavedModels\\weight_sfu_fastmri_complex_perploss_mpca_fsa2.h5\")\n",
    "model.load_weights(\".\\weight_sfu_fastmri_complex_mse.h5\")\n",
    "\n",
    "#weight_sfu_fastmri_complex_perploss.h5\n",
    "# output = model(input_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77eda7ad-fb44-43ce-a2bf-d529ee9e601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD volumes: 100\n",
      "PDFS volumes: 99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# ----------------------\n",
    "# PATHS\n",
    "# ----------------------\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "file_paths = kspace_files_list_val\n",
    "pd_files = []\n",
    "pdfs_files = []\n",
    "\n",
    "for f in kspace_files_list_val:\n",
    "    if \"PDFS\" in f:\n",
    "        pdfs_files.append(f)\n",
    "    else:\n",
    "        pd_files.append(f)\n",
    "\n",
    "print(f\"PD volumes: {len(pd_files)}\")\n",
    "print(f\"PDFS volumes: {len(pdfs_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38c1ea3-e709-4259-bafd-591dfad2f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [01:54<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PSNR (volume): 31.78 Â± 2.84 dB\n",
      "NMSE (volume): 0.036769 Â± 0.018150\n",
      "SSIM (slice):  0.7360 Â± 0.0854\n",
      "==================================================\n",
      "\n",
      "Excel files saved:\n",
      " - volume_metrics.xlsx\n",
      " - slice_ssim.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# HELPERS\n",
    "# ----------------------\n",
    "def to_complex(x):\n",
    "    \"\"\"\n",
    "    Convert (..., H, W, 2) real-imag to complex\n",
    "    \"\"\"\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    \"\"\"\n",
    "    Normalized Mean Squared Error\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + 1e-10)\n",
    "\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    \"\"\"\n",
    "    SSIM for magnitude images (2D)\n",
    "    \"\"\"\n",
    "    return structural_similarity(\n",
    "        gt,\n",
    "        pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "\n",
    "# ----------------------\n",
    "# STORAGE\n",
    "# ----------------------\n",
    "volume_metrics = []   # volume-wise PSNR, NMSE, mean SSIM\n",
    "slice_metrics = []    # slice-wise SSIM\n",
    "\n",
    "# ----------------------\n",
    "# PROCESSING\n",
    "# ----------------------\n",
    "for vol_idx, file in enumerate(tqdm(pdfs_files, desc=\"Processing volumes\")):\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full = f[\"image_full\"][:]       # (slices, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]     # (slices, H, W, 2)\n",
    "        max_val = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "    # ----------------------\n",
    "    # MODEL PREDICTION\n",
    "    # ----------------------\n",
    "    # image_under is normalized input\n",
    "    pred = model.predict(image_under, verbose=0)  # (slices, H, W, 2)\n",
    "\n",
    "    # ----------------------\n",
    "    # RESCALE TO ORIGINAL RANGE\n",
    "    # ----------------------\n",
    "    image_full = image_full * max_val\n",
    "    pred = pred * max_val\n",
    "\n",
    "    # ----------------------\n",
    "    # MAGNITUDE IMAGES\n",
    "    # ----------------------\n",
    "    gt_mag = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # ----------------------\n",
    "    # VOLUME-WISE METRICS\n",
    "    # ----------------------\n",
    "    psnr_val = peak_signal_noise_ratio(\n",
    "        gt_mag, pred_mag, data_range=max_val\n",
    "    )\n",
    "\n",
    "    nmse_val = nmse(\n",
    "        gt_mag.flatten(),\n",
    "        pred_mag.flatten()\n",
    "    )\n",
    "\n",
    "    # ----------------------\n",
    "    # SLICE-WISE SSIM\n",
    "    # ----------------------\n",
    "    ssim_slices = []\n",
    "    for slice_idx in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(\n",
    "            gt_mag[slice_idx],\n",
    "            pred_mag[slice_idx],\n",
    "            max_val\n",
    "        )\n",
    "\n",
    "        ssim_slices.append(ssim_val)\n",
    "\n",
    "        slice_metrics.append({\n",
    "            \"volume_id\": os.path.basename(file),\n",
    "            \"slice_id\": slice_idx,\n",
    "            \"SSIM\": ssim_val\n",
    "        })\n",
    "\n",
    "    # ----------------------\n",
    "    # STORE VOLUME METRICS\n",
    "    # ----------------------\n",
    "    volume_metrics.append({\n",
    "        \"volume_id\": os.path.basename(file),\n",
    "        \"PSNR\": psnr_val,\n",
    "        \"NMSE\": nmse_val,\n",
    "        \"SSIM_mean\": np.mean(ssim_slices)\n",
    "    })\n",
    "\n",
    "# ----------------------\n",
    "# SAVE TO EXCEL\n",
    "# ----------------------\n",
    "volume_df = pd.DataFrame(volume_metrics)\n",
    "slice_df = pd.DataFrame(slice_metrics)\n",
    "\n",
    "# ----------------------\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"PSNR (volume): {volume_df['PSNR'].mean():.2f} Â± {volume_df['PSNR'].std():.2f} dB\")\n",
    "print(f\"NMSE (volume): {volume_df['NMSE'].mean():.6f} Â± {volume_df['NMSE'].std():.6f}\")\n",
    "print(f\"SSIM (slice):  {slice_df['SSIM'].mean():.4f} Â± {slice_df['SSIM'].std():.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nExcel files saved:\")\n",
    "print(\" - volume_metrics.xlsx\")\n",
    "print(\" - slice_ssim.xlsx\")\n",
    "#volume_df.to_excel(\"volume_metrics_check_rnlf.xlsx\", index=False)\n",
    "#slice_df.to_excel(\"slice_ssim_check_rnlf.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1ac34b-b667-4222-b4b7-59bd77660804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timing on /CPU:0:   1%|â–‹                                                              | 2/199 [01:34<2:34:45, 47.14s/it]\n",
      "Timing on /GPU:0:   1%|â–‹                                                                | 2/199 [00:09<15:47,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL EFFICIENCY REPORT (SLICE-WISE, BATCH SIZE = 1)\n",
      "======================================================================\n",
      "Parameters: 11.75 M\n",
      "FLOPs:      165.64 GFLOPs (per slice)\n",
      "\n",
      "--- CPU Inference ---\n",
      "Latency:     0.94 s / slice\n",
      "Throughput:  1.061 slices/sec\n",
      "Memory:      0.15 MB\n",
      "\n",
      "--- GPU Inference ---\n",
      "GPU:         NVIDIA RTX A5000\n",
      "Latency:     0.10 s / slice\n",
      "Throughput:  10.456 slices/sec\n",
      "Peak VRAM:   448.12 MB\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import psutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras_flops import get_flops\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "VAL_FOLDER = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "WARMUP_SLICES = 10\n",
    "NUM_TIMING_SLICES = 100   # fixed slice count for fair benchmarking\n",
    "\n",
    "# ============================================================\n",
    "# FILE LIST\n",
    "# ============================================================\n",
    "file_paths = sorted(glob.glob(os.path.join(VAL_FOLDER, \"*.h5\")))\n",
    "\n",
    "# ============================================================\n",
    "# MODEL MUST BE LOADED\n",
    "# ============================================================\n",
    "# model = ...\n",
    "assert model is not None, \"Model is not loaded.\"\n",
    "\n",
    "# ============================================================\n",
    "# PARAMETER COUNT\n",
    "# ============================================================\n",
    "num_params = model.count_params()\n",
    "\n",
    "# ============================================================\n",
    "# FLOPs (PER SLICE, BATCH SIZE = 1)\n",
    "# ============================================================\n",
    "flops = get_flops(model, batch_size=1)\n",
    "\n",
    "# ============================================================\n",
    "# MEMORY HELPERS\n",
    "# ============================================================\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "def cpu_memory_mb():\n",
    "    return process.memory_info().rss / (1024 ** 2)\n",
    "\n",
    "def gpu_memory_mb():\n",
    "    info = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "    return info[\"peak\"] / (1024 ** 2)\n",
    "\n",
    "# ============================================================\n",
    "# LATENCY / THROUGHPUT MEASUREMENT\n",
    "# ============================================================\n",
    "def measure_latency(device):\n",
    "\n",
    "    latencies = []\n",
    "\n",
    "    with tf.device(device):\n",
    "\n",
    "        # -----------------------------\n",
    "        # WARM-UP\n",
    "        # -----------------------------\n",
    "        for file in file_paths[:1]:\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(min(WARMUP_SLICES, image_under.shape[0])):\n",
    "                _ = model(image_under[s:s+1], training=False)\n",
    "\n",
    "        # -----------------------------\n",
    "        # TIMED INFERENCE\n",
    "        # -----------------------------\n",
    "        count = 0\n",
    "        for file in tqdm(file_paths, desc=f\"Timing on {device}\", ncols=120):\n",
    "\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                image_under = f[\"image_under\"][:]\n",
    "\n",
    "            for s in range(image_under.shape[0]):\n",
    "\n",
    "                if count >= NUM_TIMING_SLICES:\n",
    "                    break\n",
    "\n",
    "                slice_input = image_under[s:s+1]   # (1, H, W, 2)\n",
    "                assert slice_input.shape[0] == 1\n",
    "\n",
    "                start = time.perf_counter()\n",
    "                _ = model(slice_input, training=False)\n",
    "\n",
    "                # ðŸ”‘ GPU synchronization\n",
    "                if \"GPU\" in device:\n",
    "                    tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "\n",
    "                end = time.perf_counter()\n",
    "\n",
    "                latencies.append(end - start)\n",
    "                count += 1\n",
    "\n",
    "            if count >= NUM_TIMING_SLICES:\n",
    "                break\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "\n",
    "    mean_s = latencies.mean()\n",
    "    median_s = np.median(latencies)\n",
    "\n",
    "    return {\n",
    "        \"mean_s\": mean_s,\n",
    "        \"median_s\": median_s,\n",
    "        \"std_s\": latencies.std(),\n",
    "        \"slices_per_sec\": 1.0 / mean_s\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# CPU BENCHMARK\n",
    "# ============================================================\n",
    "cpu_mem_before = cpu_memory_mb()\n",
    "cpu_latency = measure_latency(\"/CPU:0\")\n",
    "cpu_mem_after = cpu_memory_mb()\n",
    "cpu_mem_peak = cpu_mem_after - cpu_mem_before\n",
    "\n",
    "# ============================================================\n",
    "# GPU BENCHMARK (IF AVAILABLE)\n",
    "# ============================================================\n",
    "gpu_latency = None\n",
    "gpu_mem_peak = None\n",
    "gpu_name = None\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "    gpu_name = tf.config.experimental.get_device_details(gpus[0])[\"device_name\"]\n",
    "    gpu_latency = measure_latency(\"/GPU:0\")\n",
    "    gpu_mem_peak = gpu_memory_mb()\n",
    "\n",
    "# ============================================================\n",
    "# FINAL REPORT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL EFFICIENCY REPORT (SLICE-WISE, BATCH SIZE = 1)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Parameters: {num_params / 1e6:.2f} M\")\n",
    "print(f\"FLOPs:      {flops / 1e9:.2f} GFLOPs (per slice)\")\n",
    "\n",
    "print(\"\\n--- CPU Inference ---\")\n",
    "print(f\"Latency:     {cpu_latency['mean_s']:.2f} s / slice\")\n",
    "print(f\"Throughput:  {cpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "print(f\"Memory:      {cpu_mem_peak:.2f} MB\")\n",
    "\n",
    "if gpu_latency:\n",
    "    print(\"\\n--- GPU Inference ---\")\n",
    "    print(f\"GPU:         {gpu_name}\")\n",
    "    print(f\"Latency:     {gpu_latency['mean_s']:.2f} s / slice\")\n",
    "    print(f\"Throughput:  {gpu_latency['slices_per_sec']:.3f} slices/sec\")\n",
    "    print(f\"Peak VRAM:   {gpu_mem_peak:.2f} MB\")\n",
    "else:\n",
    "    print(\"\\nGPU not available.\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae41bbd-34d2-4245-b1fc-32c61c5ad6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# ----------------------\n",
    "# PATHS\n",
    "# ----------------------\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "file_paths = kspace_files_list_val\n",
    "\n",
    "# ----------------------\n",
    "# HELPERS\n",
    "# ----------------------\n",
    "def to_complex(x):\n",
    "    \"\"\"\n",
    "    Convert (..., H, W, 2) real-imag to complex\n",
    "    \"\"\"\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    \"\"\"\n",
    "    Normalized Mean Squared Error\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + 1e-10)\n",
    "\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    \"\"\"\n",
    "    SSIM for magnitude images (2D)\n",
    "    \"\"\"\n",
    "    return structural_similarity(\n",
    "        gt,\n",
    "        pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "\n",
    "# ----------------------\n",
    "# STORAGE\n",
    "# ----------------------\n",
    "volume_metrics = []   # volume-wise PSNR, NMSE, mean SSIM\n",
    "slice_metrics = []    # slice-wise SSIM\n",
    "\n",
    "# ----------------------\n",
    "# PROCESSING\n",
    "# ----------------------\n",
    "for vol_idx, file in enumerate(tqdm(file_paths, desc=\"Processing volumes\")):\n",
    "\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full = f[\"image_full\"][:]       # (slices, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]     # (slices, H, W, 2)\n",
    "        max_val = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "    # ----------------------\n",
    "    # MODEL PREDICTION\n",
    "    # ----------------------\n",
    "    # image_under is normalized input\n",
    "    pred = model.predict(image_under, verbose=0)  # (slices, H, W, 2)\n",
    "\n",
    "    # ----------------------\n",
    "    # RESCALE TO ORIGINAL RANGE\n",
    "    # ----------------------\n",
    "    image_full = image_full * max_val\n",
    "    pred = pred * max_val\n",
    "\n",
    "    # ----------------------\n",
    "    # MAGNITUDE IMAGES\n",
    "    # ----------------------\n",
    "    gt_mag = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # ----------------------\n",
    "    # VOLUME-WISE METRICS\n",
    "    # ----------------------\n",
    "    psnr_val = peak_signal_noise_ratio(\n",
    "        gt_mag, pred_mag, data_range=max_val\n",
    "    )\n",
    "\n",
    "    nmse_val = nmse(\n",
    "        gt_mag.flatten(),\n",
    "        pred_mag.flatten()\n",
    "    )\n",
    "\n",
    "    # ----------------------\n",
    "    # SLICE-WISE SSIM\n",
    "    # ----------------------\n",
    "    ssim_slices = []\n",
    "    for slice_idx in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(\n",
    "            gt_mag[slice_idx],\n",
    "            pred_mag[slice_idx],\n",
    "            max_val\n",
    "        )\n",
    "\n",
    "        ssim_slices.append(ssim_val)\n",
    "\n",
    "        slice_metrics.append({\n",
    "            \"volume_id\": os.path.basename(file),\n",
    "            \"slice_id\": slice_idx,\n",
    "            \"SSIM\": ssim_val\n",
    "        })\n",
    "\n",
    "    # ----------------------\n",
    "    # STORE VOLUME METRICS\n",
    "    # ----------------------\n",
    "    volume_metrics.append({\n",
    "        \"volume_id\": os.path.basename(file),\n",
    "        \"PSNR\": psnr_val,\n",
    "        \"NMSE\": nmse_val,\n",
    "        \"SSIM_mean\": np.mean(ssim_slices)\n",
    "    })\n",
    "\n",
    "# ----------------------\n",
    "# SAVE TO EXCEL\n",
    "# ----------------------\n",
    "volume_df = pd.DataFrame(volume_metrics)\n",
    "slice_df = pd.DataFrame(slice_metrics)\n",
    "\n",
    "# ----------------------\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"PSNR (volume): {volume_df['PSNR'].mean():.2f} Â± {volume_df['PSNR'].std():.2f} dB\")\n",
    "print(f\"NMSE (volume): {volume_df['NMSE'].mean():.6f} Â± {volume_df['NMSE'].std():.6f}\")\n",
    "print(f\"SSIM (slice):  {slice_df['SSIM'].mean():.4f} Â± {slice_df['SSIM'].std():.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nExcel files saved:\")\n",
    "print(\" - volume_metrics.xlsx\")\n",
    "print(\" - slice_ssim.xlsx\")\n",
    "#volume_df.to_excel(\"volume_metrics_check_rnlf.xlsx\", index=False)\n",
    "#slice_df.to_excel(\"slice_ssim_check_rnlf.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0412cd-18c2-48f1-bf16-76235473066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PSNR (volume): 32.78 Â± 2.92 dB\n",
      "NMSE (volume): 0.026503 Â± 0.017357\n",
      "SSIM (slice):  0.7647 Â± 0.0846\n",
      "==================================================\n",
      "\n",
      "Excel files saved:\n",
      " - volume_metrics.xlsx\n",
      " - slice_ssim.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# REPORT SUMMARY\n",
    "# ----------------------\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"PSNR (volume): {volume_df['PSNR'].mean():.2f} Â± {volume_df['PSNR'].std():.2f} dB\")\n",
    "print(f\"NMSE (volume): {volume_df['NMSE'].mean():.6f} Â± {volume_df['NMSE'].std():.6f}\")\n",
    "print(f\"SSIM (slice):  {slice_df['SSIM'].mean():.4f} Â± {slice_df['SSIM'].std():.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nExcel files saved:\")\n",
    "print(\" - volume_metrics.xlsx\")\n",
    "print(\" - slice_ssim.xlsx\")\n",
    "volume_df.to_excel(\"volume_metrics_rnlf.xlsx\", index=False)\n",
    "slice_df.to_excel(\"slice_ssim_rnlf.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed07432-dc4a-48b4-a046-9045831e45a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0efa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [08:45<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PSNR (Mag, volume): 34.27 Â± 2.36 dB\n",
      "NMSE (Mag, volume): 0.016860 Â± 0.007025\n",
      "SSIM (Mag, slice):  0.8332 Â± 0.0754\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# Path to validation folder\n",
    "# val_folder = \"F:/denoised_preprocessed_h5_val\"\n",
    "\n",
    "# val_folder = r\"E:\\fastmri\\val_norm\"\n",
    "# val_folder = r\"D:\\val_norm\"\n",
    "# train_folder = r\"D:\\train_norm\"\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\"\n",
    "# files = sorted([os.path.join(val_folder, f) for f in os.listdir(val_folder) if f.endswith(\".h5\")])\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "# file_paths = kspace_files_list_val[0:5]\n",
    "\n",
    "file_paths = kspace_files_list_val\n",
    "\n",
    "# ----------------------\n",
    "# HELPERS\n",
    "# ----------------------\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def nmse(gt, pred):\n",
    "    return np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + 1e-10)\n",
    "\n",
    "def compute_ssim(gt, pred, max_val):\n",
    "    return structural_similarity(\n",
    "        gt, pred,\n",
    "        data_range=max_val,\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "\n",
    "# ----------------------\n",
    "# STORAGE\n",
    "# ----------------------\n",
    "ssim_list = []\n",
    "psnr_list = []\n",
    "nmse_list = []\n",
    "\n",
    "# ----------------------\n",
    "# PROCESSING\n",
    "# ----------------------\n",
    "for file in tqdm(file_paths, desc=\"Processing volumes\"):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full = f[\"image_full\"][:]       # (slices, H, W, 2)\n",
    "        image_under = f[\"image_under\"][:]     # (slices, H, W, 2)\n",
    "        max_val = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "#     mask_batch = np.tile(mask, (image_under.shape[0], 1, 1, 1)) \n",
    "    # Get model prediction (still in normalized form)\n",
    "    # pred = model.predict([image_under,mask_batch,image_under], verbose=0)  # shape (slices, H, W, 2)\n",
    "    pred = model.predict(image_under, verbose=0)  # shape (slices, H, W, 2)\n",
    "    \n",
    "    image_full *= max_val\n",
    "    \n",
    "    pred *= max_val  # Scale predicted output to original intensity range\n",
    "\n",
    "    # Convert to complex and get magnitude\n",
    "    gt_mag = np.abs(to_complex(image_full))\n",
    "    pred_mag = np.abs(to_complex(pred))\n",
    "\n",
    "    # Volume-wise PSNR and NMSE\n",
    "    psnr_val = peak_signal_noise_ratio(gt_mag, pred_mag, data_range=max_val)\n",
    "    nmse_val = nmse(image_full.flatten(), pred.flatten())\n",
    "\n",
    "    psnr_list.append(psnr_val)\n",
    "    nmse_list.append(nmse_val)\n",
    "\n",
    "    # Slice-wise SSIM\n",
    "    for i in range(gt_mag.shape[0]):\n",
    "        ssim_val = compute_ssim(gt_mag[i], pred_mag[i], max_val)\n",
    "        ssim_list.append(ssim_val)\n",
    "\n",
    "# ----------------------\n",
    "# REPORT\n",
    "# ----------------------\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(f\"PSNR (Mag, volume): {np.mean(psnr_list):.2f} Â± {np.std(psnr_list):.2f} dB\")\n",
    "print(f\"NMSE (Mag, volume): {np.mean(nmse_list):.6f} Â± {np.std(nmse_list):.6f}\")\n",
    "print(f\"SSIM (Mag, slice):  {np.mean(ssim_list):.4f} Â± {np.std(ssim_list):.4f}\")\n",
    "\n",
    "print(\"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c85c5f6-68fa-4c57-a651-3623d0506549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PDF saved at: volume_visualization_fsa_mse_cmap_hot.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    eps = 1e-10\n",
    "    nmse = np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + eps)\n",
    "    psnr = peak_signal_noise_ratio(np.abs(gt), np.abs(pred), data_range=np.abs(gt).max() - np.abs(gt).min())\n",
    "    ssim = structural_similarity(\n",
    "        np.abs(gt), np.abs(pred),\n",
    "        data_range=np.abs(gt).max() - np.abs(gt).min(),\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "    return nmse, psnr, ssim\n",
    "\n",
    "def overlay_stats(ax, text):\n",
    "    ax.text(\n",
    "        0.05, 0.95, text,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        color=\"yellow\", fontsize=20, fontweight=\"bold\",\n",
    "        bbox=dict(facecolor=\"black\", alpha=0.5, pad=2)\n",
    "    )\n",
    "\n",
    "def plot_slice(gt, under, pred, slice_idx, pdf, max_val):\n",
    "    domains = ['Real', 'Imag', 'Abs']\n",
    "    gt_split = [gt.real, gt.imag, np.abs(gt)]\n",
    "    under_split = [under.real, under.imag, np.abs(under)]\n",
    "    pred_split = [pred.real, pred.imag, np.abs(pred)]\n",
    "\n",
    "    # Compute error maps\n",
    "    error_abs_under = [np.abs(gt_split[i] - under_split[i]) for i in range(3)]\n",
    "    error_abs_pred = [np.abs(gt_split[i] - pred_split[i]) for i in range(3)]\n",
    "    error_signed_under = [gt_split[i] - under_split[i] for i in range(3)]\n",
    "    error_signed_pred = [gt_split[i] - pred_split[i] for i in range(3)]\n",
    "\n",
    "    \n",
    "    # fig, axs = plt.subplots(3, 5, figsize=(28, 20), constrained_layout=True)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(28, 18))  # 3 rows (domains) Ã— 5 columns (types)\n",
    "    plt.suptitle(f\"Slice {slice_idx}\", fontsize=28, fontweight=\"bold\")\n",
    "\n",
    "    for row, domain in enumerate(domains):\n",
    "        # Compute metrics\n",
    "        nmse_u = compute_metrics(gt_split[row], under_split[row])[0]\n",
    "        psnr_u = compute_metrics(gt_split[row], under_split[row])[1]\n",
    "        ssim_u = compute_metrics(gt_split[row], under_split[row])[2]\n",
    "\n",
    "        nmse_p = compute_metrics(gt_split[row], pred_split[row])[0]\n",
    "        psnr_p = compute_metrics(gt_split[row], pred_split[row])[1]\n",
    "        ssim_p = compute_metrics(gt_split[row], pred_split[row])[2]\n",
    "\n",
    "        metric_text_under = f\"NMSE: {nmse_u:.4f}\\nPSNR: {psnr_u:.2f} dB\\nSSIM: {ssim_u:.4f}\"\n",
    "        metric_text_pred = f\"NMSE: {nmse_p:.4f}\\nPSNR: {psnr_p:.2f} dB\\nSSIM: {ssim_p:.4f}\"\n",
    "\n",
    "        vmax_abs = max(np.max(error_abs_under[row]), np.max(error_abs_pred[row]))\n",
    "        # vmax_signed = max(np.max(np.abs(error_signed_under[i])), np.max(np.abs(error_signed_pred[i])))\n",
    "\n",
    "        axs[row, 0].imshow(gt_split[row], cmap=\"gray\")\n",
    "        # axs[row, 0].set_title(f\"GT {domain}\", fontsize=18)\n",
    "        axs[row, 0].axis(\"off\")\n",
    "\n",
    "        axs[row, 1].imshow(under_split[row], cmap=\"gray\")\n",
    "        # axs[row, 1].set_title(f\"Undersampled {domain}\", fontsize=18)\n",
    "        axs[row, 1].axis(\"off\")\n",
    "        overlay_stats(axs[row, 1], metric_text_under)\n",
    "\n",
    "        axs[row, 2].imshow(pred_split[row], cmap=\"gray\")\n",
    "        # axs[row, 2].set_title(f\"Reconstructed {domain}\", fontsize=18)\n",
    "        axs[row, 2].axis(\"off\")\n",
    "        overlay_stats(axs[row, 2], metric_text_pred)\n",
    "\n",
    "        axs[row, 3].imshow(error_abs_under[row], cmap=\"hot\", vmin=0, vmax=vmax_abs)\n",
    "        # axs[row, 3].set_title(f\"|GT âˆ’ Und| {domain}\", fontsize=18)\n",
    "        axs[row, 3].axis(\"off\")\n",
    "\n",
    "        axs[row, 4].imshow(error_abs_pred[row], cmap=\"hot\", vmin=0, vmax=vmax_abs)\n",
    "        # axs[row, 4].set_title(f\"|GT âˆ’ Pred| {domain}\", fontsize=18)\n",
    "        axs[row, 4].axis(\"off\")\n",
    "\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.subplots_adjust(hspace=0.1,wspace=0.1) \n",
    "    pdf.savefig(fig)\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "# file_path = \"your_file_path_here.h5\"  # â† Replace this path\n",
    "val_folder = r\"D:\\val_norm\"\n",
    "# files = sorted([os.path.join(val_folder, f) for f in os.listdir(val_folder) if f.endswith(\".h5\")])\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "file_path = kspace_files_list_val[0]\n",
    "\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    image_full = f[\"image_full\"][:]\n",
    "    image_under = f[\"image_under\"][:]\n",
    "    max_val = float(f[\"max_val_full_image\"][0])\n",
    "\n",
    "# -----------------------\n",
    "# CONVERT TO COMPLEX\n",
    "# -----------------------\n",
    "gt_complex = to_complex(image_full)\n",
    "under_complex = to_complex(image_under)\n",
    "\n",
    "# -----------------------\n",
    "# MODEL PREDICTION\n",
    "# -----------------------\n",
    "pred_slices = []\n",
    "for i in range(image_under.shape[0]):\n",
    "    input_slice = image_under[i:i+1]\n",
    "    pred_slice = model.predict(input_slice, verbose=0)[0]\n",
    "    pred_slices.append(pred_slice)\n",
    "\n",
    "pred_slices = np.array(pred_slices)\n",
    "pred_complex = to_complex(pred_slices)\n",
    "\n",
    "# -----------------------\n",
    "# PDF VISUALIZATION\n",
    "# -----------------------\n",
    "output_pdf_path = \"volume_visualization_fsa_mse_cmap_hot.pdf\"\n",
    "with PdfPages(output_pdf_path) as pdf:\n",
    "    # slice_indices = np.linspace(0, gt_complex.shape[0] - 1, 4, dtype=int)\n",
    "    slice_indices = range(gt_complex.shape[0])\n",
    "\n",
    "    for idx in slice_indices:\n",
    "        plot_slice(gt_complex[idx], under_complex[idx], pred_complex[idx], idx, pdf, max_val)\n",
    "        \n",
    "    # Summary\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_title(\"Volume Intensity Summary\", fontsize=18)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    text = (\n",
    "        f\"GT Abs:    min={np.abs(gt_complex).min():.4f}, max={np.abs(gt_complex).max():.4f}\\n\"\n",
    "        f\"Under Abs: min={np.abs(under_complex).min():.4f}, max={np.abs(under_complex).max():.4f}\\n\"\n",
    "        f\"Pred Abs:  min={np.abs(pred_complex).min():.4f}, max={np.abs(pred_complex).max():.4f}\\n\\n\"\n",
    "        f\"GT Real:   min={gt_complex.real.min():.4f}, max={gt_complex.real.max():.4f}\\n\"\n",
    "        f\"GT Imag:   min={gt_complex.imag.min():.4f}, max={gt_complex.imag.max():.4f}\"\n",
    "    )\n",
    "    ax.text(0.05, 0.5, text, fontsize=12, va=\"center\")\n",
    "    pdf.savefig(fig)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"âœ… PDF saved at: {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "40a04ff2-86fb-443d-9c9d-de6a05ee58fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in file: ['image_full', 'image_under', 'kspace_full', 'kspace_under', 'max_val_full_image']\n",
      "Saved slice_018.png to slice_pngs\n",
      "Saved slice_019.png to slice_pngs\n",
      "Saved slice_020.png to slice_pngs\n",
      "âœ… Saved summary: slice_pngs\\summary.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG (edit these)\n",
    "# -----------------------\n",
    "val_folder = r\"D:\\val_norm\"           # folder with .h5 files\n",
    "file_index = 0                         # which file in sorted list to use\n",
    "requested = [18, 19, 20]                # list of slice indices you want saved as PNG\n",
    "out_dir = \"slice_pngs\"                 # where PNGs will be saved\n",
    "dpi = 300                              # output dpi (300 recommended)\n",
    "# -----------------------\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "def to_complex(x):\n",
    "    return x[..., 0] + 1j * x[..., 1]\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    eps = 1e-10\n",
    "    nmse = np.linalg.norm(gt - pred) ** 2 / (np.linalg.norm(gt) ** 2 + eps)\n",
    "    psnr = peak_signal_noise_ratio(np.abs(gt), np.abs(pred), data_range=np.abs(gt).max() - np.abs(gt).min())\n",
    "    ssim = structural_similarity(\n",
    "        np.abs(gt), np.abs(pred),\n",
    "        data_range=np.abs(gt).max() - np.abs(gt).min(),\n",
    "        win_size=9,\n",
    "        gaussian_weights=False,\n",
    "        use_sample_covariance=False,\n",
    "        K1=0.01,\n",
    "        K2=0.03\n",
    "    )\n",
    "    return nmse, psnr, ssim\n",
    "\n",
    "def overlay_stats(ax, text):\n",
    "    ax.text(\n",
    "        0.05, 0.95, text,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        color=\"yellow\", fontsize=14, fontweight=\"bold\",\n",
    "        bbox=dict(facecolor=\"black\", alpha=0.5, pad=2)\n",
    "    )\n",
    "\n",
    "def plot_slice(gt, under, pred, slice_idx, pdf, max_val):\n",
    "    domains = ['Real', 'Imag', 'Abs']\n",
    "    gt_split = [gt.real, gt.imag, np.abs(gt)]\n",
    "    under_split = [under.real, under.imag, np.abs(under)]\n",
    "    pred_split = [pred.real, pred.imag, np.abs(pred)]\n",
    "\n",
    "    # Compute error maps\n",
    "    error_abs_under = [np.abs(gt_split[i] - under_split[i]) for i in range(3)]\n",
    "    error_abs_pred = [np.abs(gt_split[i] - pred_split[i]) for i in range(3)]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(28, 18))\n",
    "    plt.suptitle(f\"Slice {slice_idx}\", fontsize=28, fontweight=\"bold\")\n",
    "\n",
    "    for row, domain in enumerate(domains):\n",
    "        # Compute metrics\n",
    "        nmse_u = compute_metrics(gt_split[row], under_split[row])[0]\n",
    "        psnr_u = compute_metrics(gt_split[row], under_split[row])[1]\n",
    "        ssim_u = compute_metrics(gt_split[row], under_split[row])[2]\n",
    "\n",
    "        nmse_p = compute_metrics(gt_split[row], pred_split[row])[0]\n",
    "        psnr_p = compute_metrics(gt_split[row], pred_split[row])[1]\n",
    "        ssim_p = compute_metrics(gt_split[row], pred_split[row])[2]\n",
    "\n",
    "        metric_text_under = f\"NMSE: {nmse_u:.4f}\\nPSNR: {psnr_u:.2f} dB\\nSSIM: {ssim_u:.4f}\"\n",
    "        metric_text_pred = f\"NMSE: {nmse_p:.4f}\\nPSNR: {psnr_p:.2f} dB\\nSSIM: {ssim_p:.4f}\"\n",
    "\n",
    "        vmax_abs = max(np.max(error_abs_under[row]), np.max(error_abs_pred[row]))\n",
    "        if vmax_abs == 0:\n",
    "            vmax_abs = 1e-8  # avoid vmin==vmax\n",
    "\n",
    "        # Column 0: GT\n",
    "        axs[row, 0].imshow(gt_split[row], cmap=\"gray\", interpolation='nearest')\n",
    "        axs[row, 0].axis(\"off\")\n",
    "\n",
    "        # Column 1: Undersampled\n",
    "        axs[row, 1].imshow(under_split[row], cmap=\"gray\", interpolation='nearest')\n",
    "        axs[row, 1].axis(\"off\")\n",
    "        overlay_stats(axs[row, 1], metric_text_under)\n",
    "\n",
    "        # Column 2: Reconstructed\n",
    "        axs[row, 2].imshow(pred_split[row], cmap=\"gray\", interpolation='nearest')\n",
    "        axs[row, 2].axis(\"off\")\n",
    "        overlay_stats(axs[row, 2], metric_text_pred)\n",
    "\n",
    "        # Column 3: |GT - Und|\n",
    "        axs[row, 3].imshow(error_abs_under[row], cmap=\"hot\", vmin=0, vmax=vmax_abs, interpolation='nearest')\n",
    "        axs[row, 3].axis(\"off\")\n",
    "\n",
    "        # Column 4: |GT - Pred|\n",
    "        axs[row, 4].imshow(error_abs_pred[row], cmap=\"hot\", vmin=0, vmax=vmax_abs, interpolation='nearest')\n",
    "        axs[row, 4].axis(\"off\")\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    # Minimal change: either save into provided pdf, or save as PNG into out_dir\n",
    "    if pdf is not None:\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        out_path = os.path.join(out_dir, f\"slice_{slice_idx:03d}.png\")\n",
    "        fig.savefig(out_path, dpi=300, bbox_inches='tight', pad_inches=0.04)\n",
    "        plt.close(fig)\n",
    "\n",
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "h5_list = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "if len(h5_list) == 0:\n",
    "    raise FileNotFoundError(f\"No .h5 files found in {val_folder}\")\n",
    "if file_index < 0 or file_index >= len(h5_list):\n",
    "    raise IndexError(f\"file_index {file_index} out of range (0..{len(h5_list)-1})\")\n",
    "\n",
    "file_path = h5_list[file_index]\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Keys in file:\", list(f.keys()))\n",
    "    image_full = f[\"image_full\"][:]       # (slices, H, W, 2)\n",
    "    image_under = f[\"image_under\"][:]     # (slices, H, W, 2)\n",
    "    max_val = float(f[\"max_val_full_image\"][0]) if \"max_val_full_image\" in f else None\n",
    "\n",
    "# -----------------------\n",
    "# CONVERT TO COMPLEX\n",
    "# -----------------------\n",
    "gt_complex = to_complex(image_full)\n",
    "under_complex = to_complex(image_under)\n",
    "\n",
    "# -----------------------\n",
    "# MODEL PREDICTION (slice-by-slice to match your earlier approach)\n",
    "# -----------------------\n",
    "if \"model\" not in globals():\n",
    "    raise RuntimeError(\"No 'model' found in the session. Load your TF model into variable name `model` first.\")\n",
    "\n",
    "pred_slices = []\n",
    "for i in range(image_under.shape[0]):\n",
    "    input_slice = image_under[i:i+1].astype(np.float32)\n",
    "    pred_slice = model.predict(input_slice, verbose=0)[0]\n",
    "    pred_slices.append(pred_slice)\n",
    "pred_slices = np.array(pred_slices)\n",
    "pred_complex = to_complex(pred_slices)\n",
    "\n",
    "# -----------------------\n",
    "# SAVE SPECIFIC SLICES AS PNG\n",
    "# -----------------------\n",
    "num_slices = gt_complex.shape[0]\n",
    "slice_indices = [i for i in requested if 0 <= i < num_slices]\n",
    "if len(slice_indices) == 0:\n",
    "    raise ValueError(f\"No valid slices in requested={requested} for volume length {num_slices}\")\n",
    "\n",
    "for idx in slice_indices:\n",
    "    plot_slice(gt_complex[idx], under_complex[idx], pred_complex[idx], idx, None, max_val)\n",
    "    print(f\"Saved slice_{idx:03d}.png to {out_dir}\")\n",
    "\n",
    "# Optional: save a summary image\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_title(\"Volume Intensity Summary\", fontsize=18)\n",
    "ax.axis(\"off\")\n",
    "text = (\n",
    "    f\"GT Abs:    min={np.abs(gt_complex).min():.4f}, max={np.abs(gt_complex).max():.4f}\\n\"\n",
    "    f\"Under Abs: min={np.abs(under_complex).min():.4f}, max={np.abs(under_complex).max():.4f}\\n\"\n",
    "    f\"Pred Abs:  min={np.abs(pred_complex).min():.4f}, max={np.abs(pred_complex).max():.4f}\\n\\n\"\n",
    "    f\"GT Real:   min={gt_complex.real.min():.4f}, max={gt_complex.real.max():.4f}\\n\"\n",
    "    f\"GT Imag:   min={gt_complex.imag.min():.4f}, max={gt_complex.imag.max():.4f}\"\n",
    ")\n",
    "ax.text(0.05, 0.5, text, fontsize=12, va=\"center\")\n",
    "summary_out = os.path.join(out_dir, \"summary.png\")\n",
    "fig.savefig(summary_out, dpi=300, bbox_inches='tight', pad_inches=0.04)\n",
    "plt.close(fig)\n",
    "print(f\"âœ… Saved summary: {summary_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cad974-74f4-4a08-a86b-3b66642e4920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89b31c40-77ff-41ef-bdea-88f39194d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in file: ['image_full', 'image_under', 'kspace_full', 'kspace_under', 'max_val_full_image']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import glob, os\n",
    "\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "file_path = kspace_files_list_val[0]\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Keys in file:\", list(f.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8714067a-50ee-4911-93e2-52c38f6a1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_maps(model):\n",
    "    attn_maps = {}\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:\n",
    "                skip = getattr(layer, name)\n",
    "                attn = skip.fsa.sa.last_attn_map\n",
    "                if attn is not None:\n",
    "                    attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b46beeea-3d2b-468c-880e-e83f17620af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_attention_grid(attn_maps):\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    for i, (name, attn) in enumerate(attn_maps.items(), 1):\n",
    "        plt.subplot(1, len(attn_maps), i)\n",
    "        plt.imshow(attn, cmap='viridis')\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbd63e5a-b283-4a2b-a2ff-f55ba420f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "def save_attention_maps_to_pdf(attn_maps, save_path=\"attention_maps_new_fsa.pdf\"):\n",
    "    with PdfPages(save_path) as pdf:\n",
    "        for name, attn in attn_maps.items():\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(attn, cmap='viridis')\n",
    "            plt.title(f\"{name} Attention Map\")\n",
    "            plt.axis('off')\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "    print(f\"âœ… Saved attention maps to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bff8f80e-2ec3-4af2-9ff1-22e53ae51d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_maps = get_attention_maps(model)\n",
    "# plot_attention_grid(attn_maps)\n",
    "# save_attention_maps_to_pdf(attn_maps, \"attention_maps_from_volume000_mse_mpca_fsa.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b7939e7-e36a-41cc-bfe1-35bbb1df0fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved attention maps for all 40 slices to: attention_maps_fsa.pdf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# -- Extract attention maps from model, now including skip0 --\n",
    "def get_attention_maps(model):\n",
    "    attn_maps = {}\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:  # â¬…ï¸ added skip0\n",
    "                skip = getattr(layer, name)\n",
    "                if hasattr(skip.fsa.sa, 'last_attn_map') and skip.fsa.sa.last_attn_map is not None:\n",
    "                    attn = skip.fsa.sa.last_attn_map\n",
    "                    attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n",
    "\n",
    "# -- Plot one row of attention maps --\n",
    "def plot_attention_maps_for_slice(attn_maps, slice_idx):\n",
    "    fig, axs = plt.subplots(1, len(attn_maps), figsize=(4 * len(attn_maps), 4))\n",
    "    for i, (name, attn) in enumerate(attn_maps.items()):\n",
    "        axs[i].imshow(attn, cmap='viridis')\n",
    "        axs[i].set_title(name)\n",
    "        axs[i].axis('off')\n",
    "    fig.suptitle(f\"Slice {slice_idx}\", fontsize=14)\n",
    "    return fig\n",
    "\n",
    "# -- Run volume through model and save attention maps to PDF --\n",
    "def process_volume_and_save_attention_pdf(h5_path, model, save_path=\"attention_all_slices.pdf\", key='image_under'):\n",
    "    with h5py.File(h5_path, 'r') as f, PdfPages(save_path) as pdf:\n",
    "        volume = f[key][...]  # shape: [num_slices, H, W, 2] or [num_slices, H, W]\n",
    "        if volume.ndim == 3:\n",
    "            volume = np.stack([volume, np.zeros_like(volume)], axis=-1)  # Make complex\n",
    "\n",
    "        num_slices = volume.shape[0]\n",
    "        for i in range(num_slices):\n",
    "            input_slice = np.expand_dims(volume[i], axis=0).astype(np.float32)  # [1, H, W, 2]\n",
    "            _ = model(input_slice, training=False)\n",
    "\n",
    "            attn_maps = get_attention_maps(model)\n",
    "            fig = plot_attention_maps_for_slice(attn_maps, i)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"âœ… Saved attention maps for all {num_slices} slices to: {save_path}\")\n",
    "process_volume_and_save_attention_pdf(\n",
    "    h5_path=\"D:/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    save_path=\"attention_maps_fsa.pdf\",\n",
    "    key='image_under'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "899c3cb5-ff6d-4cdc-a8cb-632f2a6b4327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved attention maps + under + full for 40 slices to: attention_maps_with_under_full_mse_FSA.pdf\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def get_attention_maps(model):\n",
    "    \"\"\"Return dict of attention maps found on SF_UNet_TF skip layers.\"\"\"\n",
    "    attn_maps = {}\n",
    "    for layer in model.layers:\n",
    "        # If your model itself is the SF_UNet_TF instance, consider checking the model object directly\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:\n",
    "                skip = getattr(layer, name)\n",
    "                # safe attribute check\n",
    "                if hasattr(skip, 'fsa') and hasattr(skip.fsa, 'sa') and hasattr(skip.fsa.sa, 'last_attn_map'):\n",
    "                    attn = skip.fsa.sa.last_attn_map\n",
    "                    if attn is not None:\n",
    "                        # adapt indexing if your attn shape differs\n",
    "                        attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n",
    "\n",
    "def plot_attention_row(attn_maps, under_img, full_img, slice_idx, attn_cmap='viridis'):\n",
    "    \"\"\"\n",
    "    attn_maps: Ordered dict-like (name->2D array)\n",
    "    under_img: (H, W, 2) or (H, W) -> will be converted to magnitude for display\n",
    "    full_img:  same as under_img (ground truth)\n",
    "    \"\"\"\n",
    "    # Ensure magnitude images\n",
    "    if under_img.ndim == 3 and under_img.shape[-1] == 2:\n",
    "        under_disp = np.abs(under_img[...,0] + 1j * under_img[...,1])\n",
    "    else:\n",
    "        under_disp = np.abs(under_img)\n",
    "\n",
    "    if full_img.ndim == 3 and full_img.shape[-1] == 2:\n",
    "        full_disp = np.abs(full_img[...,0] + 1j * full_img[...,1])\n",
    "    else:\n",
    "        full_disp = np.abs(full_img)\n",
    "\n",
    "    # Number of columns: under + attention maps + full\n",
    "    n_attn = len(attn_maps)\n",
    "    n_cols = 1 + max(0, n_attn) + 1\n",
    "\n",
    "    fig, axs = plt.subplots(1, n_cols, figsize=(4 * n_cols, 4))\n",
    "    if n_cols == 1:\n",
    "        axs = np.array([axs])  # keep indexing consistent\n",
    "\n",
    "    # Leftmost = under-sampled magnitude\n",
    "    axs[0].imshow(under_disp, cmap='gray')\n",
    "    axs[0].set_title(\"Under-sampled (Abs)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Middle = attention maps in order\n",
    "    for i, (name, attn) in enumerate(attn_maps.items(), start=1):\n",
    "        ax = axs[i]\n",
    "        # optional: set vmin/vmax for cross-slice consistency outside this function\n",
    "        ax.imshow(attn, cmap=attn_cmap)\n",
    "        ax.set_title(name)\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Rightmost = full-sampled magnitude\n",
    "    axs[-1].imshow(full_disp, cmap='gray')\n",
    "    axs[-1].set_title(\"Full-sampled (Abs)\")\n",
    "    axs[-1].axis('off')\n",
    "\n",
    "    fig.suptitle(f\"Slice {slice_idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ---------- Main processing & PDF saving ----------\n",
    "def process_volume_and_save_attention_pdf(h5_path, model, save_path=\"attention_with_under_and_full.pdf\",\n",
    "                                         key_under='image_under', key_full='image_full'):\n",
    "    with h5py.File(h5_path, 'r') as f, PdfPages(save_path) as pdf:\n",
    "        # read volumes\n",
    "        under_vol = f[key_under][...]   # expected shape: [num_slices, H, W, 2] or [num_slices, H, W]\n",
    "        full_vol = f[key_full][...]     # same shape\n",
    "\n",
    "        # ensure complex-like shape (H, W, 2) if stored as 3D\n",
    "        if under_vol.ndim == 3:\n",
    "            under_vol = np.stack([under_vol, np.zeros_like(under_vol)], axis=-1)\n",
    "        if full_vol.ndim == 3:\n",
    "            full_vol = np.stack([full_vol, np.zeros_like(full_vol)], axis=-1)\n",
    "\n",
    "        num_slices = under_vol.shape[0]\n",
    "        for i in range(num_slices):\n",
    "            # prepare input for model: [1, H, W, 2], float32\n",
    "            input_slice = np.expand_dims(under_vol[i], axis=0).astype(np.float32)\n",
    "\n",
    "            # forward pass (this should populate last_attn_map inside the skip blocks)\n",
    "            _ = model(input_slice, training=False)\n",
    "\n",
    "            # extract attention maps\n",
    "            attn_maps = get_attention_maps(model)  # dict: name -> 2D\n",
    "\n",
    "            # plot row with under | attn maps... | full\n",
    "            fig = plot_attention_row(attn_maps, under_vol[i], full_vol[i], slice_idx=i)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"âœ… Saved attention maps + under + full for {num_slices} slices to: {save_path}\")\n",
    "\n",
    "# Example usage (update path & model as needed)\n",
    "process_volume_and_save_attention_pdf(\n",
    "    h5_path=\"D:/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    save_path=\"attention_maps_with_under_full_mse_FSA.pdf\",\n",
    "    key_under='image_under',\n",
    "    key_full='image_full'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a2249e69-f771-46bf-b5d4-b399d6230fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 3 images to: attention_pngs\n"
     ]
    }
   ],
   "source": [
    "import os   # <- small necessary addition\n",
    "\n",
    "# ---------- Main: process specific slices and save PNGs ----------\n",
    "def process_and_save_slices_png(h5_path, model, out_dir,\n",
    "                                slices=[0], key_under='image_under', key_full='image_full',\n",
    "                                dpi=300, figsize_per_col=4, attn_cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Minimal replacement to save specific slices as PNGs.\n",
    "    - slices: list of slice indices to process (e.g. [0,10,20]) or \"all\"\n",
    "    - out_dir: directory to save PNGs\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        under_vol = f[key_under][...]   # [S, H, W, 2] or [S, H, W]\n",
    "        full_vol = f[key_full][...]     # same\n",
    "\n",
    "    # make sure shape is (S, H, W, 2)\n",
    "    if under_vol.ndim == 3:\n",
    "        under_vol = np.stack([under_vol, np.zeros_like(under_vol)], axis=-1)\n",
    "    if full_vol.ndim == 3:\n",
    "        full_vol = np.stack([full_vol, np.zeros_like(full_vol)], axis=-1)\n",
    "\n",
    "    num_slices = under_vol.shape[0]\n",
    "    if slices == \"all\":\n",
    "        selected = list(range(num_slices))\n",
    "    else:\n",
    "        # filter valid indices\n",
    "        selected = [int(s) for s in slices if 0 <= int(s) < num_slices]\n",
    "\n",
    "    if len(selected) == 0:\n",
    "        raise ValueError(\"No valid slices selected.\")\n",
    "\n",
    "    for idx in selected:\n",
    "        inp = np.expand_dims(under_vol[idx], axis=0).astype(np.float32)\n",
    "        # forward pass to populate attention maps\n",
    "        _ = model(inp, training=False)\n",
    "\n",
    "        attn_maps = get_attention_maps(model)  # same helper you already have\n",
    "\n",
    "        # build figure (reuses your plot_attention_row which returns a fig)\n",
    "        fig = plot_attention_row(attn_maps, under_vol[idx], full_vol[idx], slice_idx=idx, attn_cmap=attn_cmap)\n",
    "\n",
    "        # Save PNG\n",
    "        out_name = f\"fsa_perp_slice_{idx:03d}.png\"\n",
    "        out_path = os.path.join(out_dir, out_name)\n",
    "        fig.savefig(out_path, dpi=dpi, bbox_inches='tight', pad_inches=0.05)\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"âœ… Saved {len(selected)} images to: {out_dir}\")\n",
    "\n",
    "# ---------- Example usage ----------\n",
    "process_and_save_slices_png(\n",
    "    h5_path=\"D:/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    out_dir=\"attention_pngs\",    # where PNGs will go\n",
    "    slices=[18, 19, 20],         # <-- specify slices you want\n",
    "    dpi=300,                    # change if you want higher/lower resolution\n",
    "    figsize_per_col=4,          # not used here directly (plot_attention_row uses fixed figsize), kept for compatibility\n",
    "    attn_cmap='viridis'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "949fc24b-13d3-4f9b-804e-601292107f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_maps(model):\n",
    "    attn_maps = {}\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, SF_UNet_TF):\n",
    "            for name in ['skip4', 'skip3', 'skip2', 'skip1']:\n",
    "                skip = getattr(layer, name)\n",
    "                attn = skip.fsa.sa.last_attn_map\n",
    "                if attn is not None:\n",
    "                    attn_maps[name] = attn[0, :, :, 0, 0].numpy()  # [H, W]\n",
    "    return attn_maps\n",
    "\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_attention_maps_for_slice(attn_maps, slice_idx):\n",
    "    fig, axs = plt.subplots(1, len(attn_maps), figsize=(16, 4))\n",
    "    for i, (name, attn) in enumerate(attn_maps.items()):\n",
    "        axs[i].imshow(attn, cmap='viridis')\n",
    "        axs[i].set_title(f\"{name}\")\n",
    "        axs[i].axis('off')\n",
    "    fig.suptitle(f\"Slice {slice_idx}\", fontsize=14)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8c35d06-2573-4564-8060-dc181daeef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def process_volume_and_save_attention_pdf(h5_path, model, save_path=\"attention_all_slices_mpca_fsa_mse.pdf\", key='image_under'):\n",
    "    with h5py.File(h5_path, 'r') as f, PdfPages(save_path) as pdf:\n",
    "        volume = f[key][...]  # shape: [num_slices, H, W, 2] or [num_slices, H, W]\n",
    "        if volume.ndim == 3:  # Real-only, no complex\n",
    "            volume = np.stack([volume, np.zeros_like(volume)], axis=-1)  # Add imaginary\n",
    "\n",
    "        num_slices = volume.shape[0]\n",
    "\n",
    "        for i in range(num_slices):\n",
    "            input_slice = np.expand_dims(volume[i], axis=0).astype(np.float32)  # [1, H, W, 2]\n",
    "\n",
    "            # Run forward pass\n",
    "            _ = model(input_slice)\n",
    "\n",
    "            # Extract attention maps\n",
    "            attn_maps = get_attention_maps(model)\n",
    "\n",
    "            # Plot and save figure\n",
    "            fig = plot_attention_maps_for_slice(attn_maps, i)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"âœ… Saved all {num_slices} slices' attention maps to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee25144f-6155-4b77-9e2f-6c9e474b2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved all 40 slices' attention maps to attention_maps_volume_000_mpca_fsa_perploss.pdf\n"
     ]
    }
   ],
   "source": [
    "# model = build_dual_output_model()\n",
    "# model.load_weights(\"weight_sfu_fastmri_complex_perploss_fsa.h5\")\n",
    "\n",
    "process_volume_and_save_attention_pdf(\n",
    "    h5_path=\"G:/val_norm/val_norm/volume_000.h5\",\n",
    "    model=model,\n",
    "    save_path=\"attention_maps_volume_000_mpca_fsa_perploss.pdf\",\n",
    "    key='image_under'  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2981da0-00bc-47a6-a65a-5079a2e31302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
