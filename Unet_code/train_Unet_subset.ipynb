{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f31836e-ee71-4b87-a94a-16b623996312",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "\n",
    "# Importing callbacks and data augmentation utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import  Adam\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f9d693-7d4e-4e48-90cc-547ad3ebe9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_sampling_mask (1, 1, 320, 1) float32 <class 'numpy.ndarray'>\n",
      "Sampling: 0.234375\n",
      "Number of 1s: 75 (23.43750000%)\n",
      "Number of 0s: 245 (76.56250000%)\n",
      "Min 0.0\n",
      "Max 1.0\n",
      "data range 1.0\n",
      "var_sampling_mask (1, 1, 320, 1) float32 <class 'numpy.ndarray'>\n",
      "var_sampling_mask[0] (1, 320, 1) float32 <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27c38f5bdc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hybrid_cascade/fastmri/Data/mask_4x_320_random.npy\n",
    "var_sampling_mask=np.load(r\"C:\\Users\\DU\\aman_fastmri\\Data\\mask_4x_320_random.npy\")\n",
    "print(\"var_sampling_mask\",var_sampling_mask.shape,var_sampling_mask.dtype,type(var_sampling_mask))\n",
    "\n",
    "\n",
    "print(\"Sampling:\", 1.0*var_sampling_mask.sum()/var_sampling_mask.size)\n",
    "num_zeros = np.sum(var_sampling_mask[0] == 0)\n",
    "num_ones = np.sum(var_sampling_mask[0] == 1)\n",
    "# Print results\n",
    "total_pixels = var_sampling_mask[0].size\n",
    "\n",
    "# Calculate percentages\n",
    "ones_percentage = (num_ones / total_pixels) * 100\n",
    "zeros_percentage = (num_zeros / total_pixels) * 100\n",
    "\n",
    "print(f\"Number of 1s: {num_ones} ({ones_percentage:.8f}%)\")\n",
    "print(f\"Number of 0s: {num_zeros} ({zeros_percentage:.8f}%)\")\n",
    "print(\"Min\",var_sampling_mask[0].min())\n",
    "print(\"Max\",var_sampling_mask[0].max())\n",
    "print(\"data range\",var_sampling_mask[0].max()-var_sampling_mask[0].min())\n",
    "print(\"var_sampling_mask\",var_sampling_mask.shape,var_sampling_mask.dtype,type(var_sampling_mask))\n",
    "print(\"var_sampling_mask[0]\",var_sampling_mask[0].shape,var_sampling_mask[0].dtype,type(var_sampling_mask[0]))\n",
    "plt.imshow(var_sampling_mask[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297f9d98-18e3-4e74-97f6-ad4501e91afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "class VolumeWiseNMSE(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_files, save_best_path):\n",
    "        self.val_files = val_files\n",
    "        self.best_nmse = float('inf')\n",
    "        self.save_best_path = save_best_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        total_nmse = 0\n",
    "        num_volumes = 0\n",
    "\n",
    "        for file_path in self.val_files:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                image_under = f['image_under'][:]  # [slices, H, W, 2]\n",
    "                gt = f['image_full'][:]\n",
    "\n",
    "            pred = []\n",
    "            for i in range(image_under.shape[0]):\n",
    "                input_slice = np.expand_dims(image_under[i], axis=0)\n",
    "                pred_slice = self.model.predict(input_slice, verbose=0)\n",
    "                pred.append(pred_slice[0])\n",
    "            pred = np.stack(pred)\n",
    "\n",
    "            nmse = np.sum((np.abs(gt - pred) ** 2)) / np.sum((np.abs(gt) ** 2))\n",
    "            total_nmse += nmse\n",
    "            num_volumes += 1\n",
    "\n",
    "        avg_nmse = total_nmse / num_volumes\n",
    "        print(f\"\\nEpoch {epoch + 1} - Avg NMSE: {avg_nmse:.6f}\")\n",
    "\n",
    "        if avg_nmse < self.best_nmse:\n",
    "            print(f\"New best model found! Saving model with NMSE {avg_nmse:.6f}\")\n",
    "            self.best_nmse = avg_nmse\n",
    "            self.model.save(self.save_best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab92fc1-786a-4dd4-be26-8b3c870808dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\train_sub_norm\"\n",
    "val_folder = r\"D:\\fastmri_singlecoil_FSSCAN\\val_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7bd245-5bb2-4064-b0ee-951351dbb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRISliceGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, file_list, batch_size=4, shuffle=True):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.slice_index_map = []  # list of (file_idx, slice_idx)\n",
    "        self._build_index()\n",
    "\n",
    "    def _build_index(self):\n",
    "        for file_idx, file_path in enumerate(self.file_list):\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                num_slices = f['image_under'].shape[0]\n",
    "                for slice_idx in range(num_slices):\n",
    "                    self.slice_index_map.append((file_idx, slice_idx))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.slice_index_map) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_map = self.slice_index_map[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x, batch_y = [], []\n",
    "\n",
    "        for file_idx, slice_idx in batch_map:\n",
    "            with h5py.File(self.file_list[file_idx], 'r') as f:\n",
    "                x = f['image_under'][slice_idx]  # [H, W, 2]\n",
    "                y = f['image_full'][slice_idx]   # [H, W, 2]\n",
    "\n",
    "                #y_norm = complex_zscore(y)\n",
    "\n",
    "                batch_x.append(x)\n",
    "                batch_y.append(y)\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.slice_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6142e5-dae8-4876-ae55-1cc321d2ca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086\n",
      "1784\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "kspace_files_list_train = sorted(glob.glob(os.path.join(train_folder, \"*.h5\")))\n",
    "kspace_files_list_val = sorted(glob.glob(os.path.join(val_folder, \"*.h5\")))\n",
    "\n",
    "# half_train = 20\n",
    "# half_val = 10\n",
    "half_train = len(kspace_files_list_train) \n",
    "half_val = len(kspace_files_list_val) \n",
    "# print(\"half_train\",half_train)\n",
    "# print(\"half_val\",half_val)\n",
    "kspace_files_list_train = kspace_files_list_train[:]\n",
    "kspace_files_list_val = kspace_files_list_val[:]\n",
    "\n",
    "# Create generators\n",
    "# train_gen = MRISliceGenerator(kspace_files_list_train,batch_size=16, shuffle=True,mask=mask)\n",
    "# val_gen = MRISliceGenerator(kspace_files_list_val, batch_size=4, shuffle=False,mask=mask)\n",
    "train_gen = MRISliceGenerator(kspace_files_list_train,batch_size=8, shuffle=True)\n",
    "val_gen = MRISliceGenerator(kspace_files_list_val, batch_size=4, shuffle=False)\n",
    "\n",
    "print(len(train_gen))  \n",
    "print(len(val_gen))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9dd550-fad5-4551-9f02-a7cf1ac11baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732d783b-ea19-45d3-aace-4695a3943de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model_unet.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752bff35-d8ec-4ad9-a03a-cabb6649b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define the log directory\n",
    "log_dir = \"./logs/fastmri_Unet_4x_mae_full_val_nmse\"\n",
    "\n",
    "# Create the TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c34c853-f0c9-4d78-84a0-cbde5887495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def nmse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred)) / K.mean(K.square(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec4eda2-42a1-4ef8-ac19-e198aea3b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "\n",
    "# Define learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 40:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001  # Multiply by 0.1 after 40 epochs\n",
    "epochs = 50\n",
    "batch_size=16\n",
    "\n",
    "model_name = \"./SavedModels/Unet_4x_320_mae_full_nmse.hdf5\"\n",
    "\n",
    "H, W = 320, 320\n",
    "model = unet(H=H, W=W, channels=2, kshape=(3, 3))\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='mae', optimizer=opt, metrics=[nmse])\n",
    "\n",
    "# Load weights if available\n",
    "if os.path.isfile(model_name):\n",
    "    model.load_weights(model_name)\n",
    "    print(\"Weights loaded\")\n",
    "\n",
    "# Define callbacks\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', save_best_only=True, mode='min')\n",
    "# Early stopping callback to shut down training after\n",
    "# 5 epochs with no improvement\n",
    "#earlyStopping = EarlyStopping(monitor='val_loss',patience=20, verbose=0, mode='min')\n",
    "\n",
    "\n",
    "if os.path.isfile(model_name):\n",
    "    model.load_weights(model_name)\n",
    "    print(\"weights loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce5ccd62-9be0-45d9-8137-782a4412aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded\n",
      "Epoch 1/5\n",
      "1086/1086 [==============================] - ETA: 0s - loss: 0.0186 - nmse: 0.0513     \n",
      "Epoch 1 - Avg NMSE: 0.065177\n",
      "New best model found! Saving model with NMSE 0.065177\n",
      "1086/1086 [==============================] - 1196s 1s/step - loss: 0.0186 - nmse: 0.0513 - val_loss: 0.0199 - val_nmse: 0.0834\n",
      "Epoch 2/5\n",
      "1086/1086 [==============================] - ETA: 0s - loss: 0.0185 - nmse: 0.0509  \n",
      "Epoch 2 - Avg NMSE: 0.068936\n",
      "1086/1086 [==============================] - 1214s 1s/step - loss: 0.0185 - nmse: 0.0509 - val_loss: 0.0208 - val_nmse: 0.0882\n",
      "Epoch 3/5\n",
      "1086/1086 [==============================] - ETA: 0s - loss: 0.0185 - nmse: 0.0512  \n",
      "Epoch 3 - Avg NMSE: 0.065881\n",
      "1086/1086 [==============================] - 1252s 1s/step - loss: 0.0185 - nmse: 0.0512 - val_loss: 0.0200 - val_nmse: 0.0845\n",
      "Epoch 4/5\n",
      "1086/1086 [==============================] - ETA: 0s - loss: 0.0185 - nmse: 0.0510  \n",
      "Epoch 4 - Avg NMSE: 0.066573\n",
      "1086/1086 [==============================] - 1393s 1s/step - loss: 0.0185 - nmse: 0.0510 - val_loss: 0.0203 - val_nmse: 0.0852\n",
      "Epoch 5/5\n",
      "1086/1086 [==============================] - ETA: 0s - loss: 0.0185 - nmse: 0.0510  \n",
      "Epoch 5 - Avg NMSE: 0.066486\n",
      "1086/1086 [==============================] - 1540s 1s/step - loss: 0.0185 - nmse: 0.0510 - val_loss: 0.0201 - val_nmse: 0.0850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27c44d04430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "H, W = 320, 320\n",
    "model = unet(H=H, W=W, channels=2, kshape=(3, 3))\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "\n",
    "model_name = \"./SavedModels/best_model_nmse_full_volume.h5\"\n",
    "model.compile(loss='mae', optimizer=opt, metrics=[nmse])\n",
    "\n",
    "# Load weights if available\n",
    "if os.path.isfile(model_name):\n",
    "    model.load_weights(model_name)\n",
    "    print(\"Weights loaded\")\n",
    "\n",
    "nmse_callback = VolumeWiseNMSE(kspace_files_list_val, save_best_path=model_name)\n",
    "\n",
    "class StepDecayLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch == 40:\n",
    "            old_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
    "            new_lr = old_lr * 0.1\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
    "            print(f\"\\nEpoch {epoch + 1}: Reducing learning rate from {old_lr} to {new_lr}\")\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5,\n",
    "    callbacks=[nmse_callback, StepDecayLR()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90021f66-c55e-4220-b362-ef64ac8983ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt  # <-- Required for plotting\n",
    "from typing import Optional\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from tqdm import tqdm\n",
    "def psnr(\n",
    "    gt: np.ndarray, pred: np.ndarray, maxval: Optional[float] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute Peak Signal to Noise Ratio metric (PSNR)\"\"\"\n",
    "    if maxval is None:\n",
    "        maxval = gt.max()\n",
    "    return peak_signal_noise_ratio(gt, pred, data_range=maxval)\n",
    "\n",
    "\n",
    "# Your preprocessed folder\n",
    "save_dir = r\"D:\\fastmri\\preprocessed_h5_val\"\n",
    "files = sorted([os.path.join(save_dir, f) for f in os.listdir(save_dir) if f.endswith('.h5')])\n",
    "psnr_all_volumes = []\n",
    "\n",
    "for file in files:\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        image_full = f['image_full'][:]   # shape: [slices, H, W, 2]\n",
    "        image_under = f['image_under'][:]\n",
    "        max_val=f['max_val_full'][:]\n",
    "\n",
    "    # Convert to complex\n",
    "    #image_full_complex = image_full[..., 0] + 1j * image_full[..., 1]\n",
    "    #image_under_complex = image_under[..., 0] + 1j * image_under[..., 1]\n",
    "\n",
    "    # Convert to magnitude\n",
    "    #mag_gt = np.abs(image_full_complex)\n",
    "    #mag_under = np.abs(image_under_complex)\n",
    "    psnrs = psnr(image_full,image_under,max_val)\n",
    "    #mean_psnr = np.mean(psnrs)\n",
    "\n",
    "    psnr_all_volumes.append(psnrs)\n",
    "    #print(f\"{os.path.basename(file)}: PSNR = {mean_psnr:.2f} dB\")\n",
    "# Overall average and standard deviation\n",
    "overall_avg_psnr = np.mean(psnr_all_volumes)\n",
    "overall_std_psnr = np.std(psnr_all_volumes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Overall Average PSNR: {overall_avg_psnr:.6f} ± {overall_std_psnr:.6f} dB\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ece3af-b596-41ca-95db-4395d5e32366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "\n",
    "import math\n",
    " # <-- Required for plotting\n",
    "from typing import Optional\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def psnr(\n",
    "    gt: np.ndarray, pred: np.ndarray, maxval: Optional[float] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute Peak Signal to Noise Ratio metric (PSNR)\"\"\"\n",
    "    if maxval is None:\n",
    "        maxval = gt.max()\n",
    "    return peak_signal_noise_ratio(gt, pred, data_range=maxval)\n",
    "\n",
    "def nmse(gt: np.ndarray, pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute Normalized Mean Squared Error (NMSE) over full volume.\"\"\"\n",
    "    return np.linalg.norm(gt - pred) ** 2 / np.linalg.norm(gt) ** 2\n",
    "\n",
    "#\n",
    "def visualize_and_save_all_slices(model, val_files):\n",
    "    #os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    all_volume_psnrs = []\n",
    "    nmse_all_volumes = []\n",
    "    ssim_all_volumes=[]\n",
    "\n",
    "    for file_path in val_files:\n",
    "        volume_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        #pdf_path = os.path.join(output_dir, f\"{volume_name}.pdf\")\n",
    "\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            image_under = f['image_under'][:]  # [slices, H, W, 2]\n",
    "            gt = f['image_full'][:]            # [slices, H, W, 2]\n",
    "\n",
    "        pred = []\n",
    "        for i in range(image_under.shape[0]):\n",
    "            input_slice = np.expand_dims(image_under[i], axis=0)  # [1, H, W, 2]\n",
    "            pred_slice = model.predict(input_slice, verbose=0)\n",
    "            pred.append(pred_slice[0])\n",
    "        pred = np.stack(pred)  # [slices, H, W, 2]\n",
    "\n",
    "        # Volume-wise PSNR using all channels\n",
    "        volume_psnr = psnr(gt, pred)\n",
    "        all_volume_psnrs.append(volume_psnr)\n",
    "\n",
    "        # Convert complex for visualization (abs)\n",
    "        gt_complex = gt[..., 0] + 1j * gt[..., 1]\n",
    "        pred_complex = pred[..., 0] + 1j * pred[..., 1]\n",
    "        under_complex = image_under[..., 0] + 1j * image_under[..., 1]\n",
    "\n",
    "        mag_gt = np.abs(gt_complex)\n",
    "        mag_pred = np.abs(pred_complex)\n",
    "        mag_under = np.abs(under_complex)\n",
    "                # Compute NMSE over full volume (flattened)\n",
    "        nmse_volume = nmse(mag_gt.flatten(), mag_pred.flatten())\n",
    "    \n",
    "        nmse_all_volumes.append(nmse_volume)\n",
    "\n",
    "        \n",
    "        max_val=np.max(mag_gt)\n",
    "    \n",
    "        ssim_slices = []\n",
    "        for i in range(mag_gt.shape[0]):\n",
    "            gt_mag = mag_gt[i]\n",
    "            pred_mag = mag_pred[i]\n",
    "    \n",
    "            ssim_slice= compare_ssim(\n",
    "                gt_mag, pred_mag,\n",
    "                data_range=max_val,\n",
    "                win_size=11,\n",
    "                gaussian_weights=False,\n",
    "                use_sample_covariance=False,      # <-- now correct per paper\n",
    "                K1=0.01,\n",
    "                K2=0.03,\n",
    "                full=False\n",
    "            )\n",
    "            ssim_slices.append(ssim_slice)\n",
    "    \n",
    "        ssim_volume = np.mean(ssim_slices)\n",
    "        ssim_all_volumes.append(ssim_volume)\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    overall_avg_psnr = np.mean(all_volume_psnrs)\n",
    "    overall_std_psnr = np.std(all_volume_psnrs)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Overall Average PSNR: {overall_avg_psnr:.6f} ± {overall_std_psnr:.6f} dB\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    \n",
    "    overall_avg_nmse = np.mean(nmse_all_volumes)\n",
    "    overall_std_nmse = np.std(nmse_all_volumes)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Overall Average NMSE: {overall_avg_nmse:.6f} ± {overall_std_nmse:.6f} dB\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    overall_avg_ssim = np.mean(ssim_all_volumes)\n",
    "    overall_std_ssim = np.std(ssim_all_volumes)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Overall Average SSIM: {overall_avg_ssim:.6f} ± {overall_std_ssim:.6f} dB\")\n",
    "    print(\"=\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b25c40-947f-46c6-9122-5f84389ab911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = \"./validation_results\"\n",
    "visualize_and_save_all_slices(model, kspace_files_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb859b21-f69c-4345-8e35-ca5eed9b2952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17c90a-d3b1-4fde-8ba2-ab14071d48a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
